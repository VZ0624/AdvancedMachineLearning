{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "48de53d81aa50d97046cca0ddb2f2d2d",
     "grade": false,
     "grade_id": "cell-cfc24d80c2cf2c24",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Adaboost\n",
    "For this exercise you will implement AdaBoost from scratch and applied it to a spam dataset. You will be classifying data into spam and not spam. You can call DecisionTreeClassifier from sklearn to learn your base classifiers.\n",
    "\n",
    "Here is how you train a decision tree classifier with weights.\n",
    "\n",
    "`\n",
    "h = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
    "h.fit(X, Y, sample_weight=w)\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "721eeb40a1514114e45b42ea010de91b",
     "grade": false,
     "grade_id": "cell-3478d607a536190b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1410ebe73ffc63306e4c15b6698a7188",
     "grade": false,
     "grade_id": "cell-c56cb727222d9503",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# accuracy computation\n",
    "def accuracy(y, pred):\n",
    "    return np.sum(y == pred) / float(len(y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "d133f796b3b7db028e1c1ed875771c65",
     "grade": false,
     "grade_id": "cell-1eaf818528c8d676",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_spambase_data(filename):\n",
    "    \"\"\" Given a filename return X and Y numpy arrays\n",
    "\n",
    "    X is of size number of rows x num_features\n",
    "    Y is an array of size the number of rows\n",
    "    Y is the last element of each row. (Convert 0 to -1)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    df = pd.read_csv(\"./\"+filename, header=None)\n",
    "    df.iloc[:,-1:] = df.iloc[:,-1:].replace(0,float(-1))\n",
    "    df.iloc[:,-1:] = df.iloc[:,-1:].replace(1,float(1))\n",
    "    X = np.array(df.iloc[:,0:-1])\n",
    "    Y = np.array(df.iloc[:,-1:])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "871278b33c2d3da9fb8d7cbf4f4dd23d",
     "grade": true,
     "grade_id": "cell-73926460e1f70f54",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y_test = np.array([1., -1., 1., 1., -1., -1., 1., 1., 1., -1.])\n",
    "X, Y = parse_spambase_data(\"tiny.spam.train\")\n",
    "for i in range(len(y_test)): assert(y_test[i] == Y[i])\n",
    "n, m = X.shape\n",
    "assert(n == 10)\n",
    "assert(m == 57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "3a188c77e59b3b431b59f03ddf7bbe7d",
     "grade": false,
     "grade_id": "cell-befcece7be9c6839",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def adaboost(X, y, num_iter):\n",
    "    \"\"\"Given an numpy matrix X, a array y and num_iter return trees and weights \n",
    "   \n",
    "    Input: X, y, num_iter\n",
    "    Outputs: array of trees from DecisionTreeClassifier\n",
    "             trees_weights array of floats\n",
    "    Assumes y is {-1, 1}\n",
    "    \"\"\"\n",
    "    trees = []\n",
    "    trees_weights = [] \n",
    "    N, _ = X.shape\n",
    "    d = np.ones(N) / N\n",
    "    # YOUR CODE HERE\n",
    "    epsilon = 0.000000000000001\n",
    "    for i in range(num_iter):\n",
    "        # Train a simple decision stump\n",
    "        tree = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
    "        tree.fit(X, y, sample_weight=d)\n",
    "        # Compute weighted error\n",
    "        compare = np.not_equal(np.array(tree.predict(X)).reshape((N,1)), y.reshape((N,1)))\n",
    "        weighted_error = np.dot(d.reshape((1,N)),compare)/np.sum(d)\n",
    "        # Compute tree weight\n",
    "        tree_weight = np.log((1-weighted_error+epsilon)/(weighted_error+epsilon))\n",
    "        trees.append(tree)\n",
    "        trees_weights.append(tree_weight[0][0])\n",
    "        # Update the weights\n",
    "        compare = compare.astype(float)\n",
    "        compare[compare == 1.] = np.exp(tree_weight[0][0])\n",
    "        compare[compare == 0.] = 1\n",
    "        d = np.multiply(d.reshape((N,1)), compare).reshape((N,))\n",
    "        i += 1\n",
    "    return trees, trees_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a6923d427eebd8af4c7ffa45586034e0",
     "grade": true,
     "grade_id": "cell-4dc8edbf0e11fab8",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X, Y = parse_spambase_data(\"tiny.spam.train\")\n",
    "trees, weights = adaboost(X, Y, 2)\n",
    "assert(len(trees) == 2)\n",
    "assert(len(weights) == 2)\n",
    "assert(isinstance(trees[0], DecisionTreeClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6ce0015d15c0c0df6be9c78e73bb0929",
     "grade": true,
     "grade_id": "cell-8702186fedbd58e1",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([[0, -1], [1, 0], [-1, 0]])\n",
    "y = np.array([-1, 1, 1])\n",
    "trees, weights = adaboost(x, y, 1)\n",
    "h = trees[0]\n",
    "pred = h.predict(x)\n",
    "for i in range(len(y)): assert(pred[i] == y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "57a2d749acc1d974f996162a4fb190fc",
     "grade": false,
     "grade_id": "cell-50ad4a5c81e7c016",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def adaboost_predict(X, trees, trees_weights):\n",
    "    \"\"\"Given X, trees and weights predict Y\n",
    "    \"\"\"\n",
    "    # X input, y output\n",
    "    N, _ =  X.shape\n",
    "    y = np.zeros(N)\n",
    "    # YOUR CODE HERE\n",
    "    for i in range(len(trees_weights)):\n",
    "        y += trees_weights[i] * trees[i].predict(X)\n",
    "    return np.sign(y).reshape((N,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f29500cb929b49fd0e3d7d7c2b528be",
     "grade": true,
     "grade_id": "cell-7f28f00061f7b5a5",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([[0, -1], [1, 0], [-1, 0]])\n",
    "y = np.array([-1, 1, 1])\n",
    "trees, weights = adaboost(x, y, 1)\n",
    "pred = adaboost_predict(x, trees, weights)\n",
    "for i in range(len(y)):\n",
    "    assert(pred[i] == y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f5022208d3fd8fb43a8847635cdb82f",
     "grade": true,
     "grade_id": "cell-89126a5a7f8f0e1b",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.9111\n",
      "Test Accuracy 0.9190\n"
     ]
    }
   ],
   "source": [
    "X, Y = parse_spambase_data(\"spambase.train\")\n",
    "X_test, Y_test = parse_spambase_data(\"spambase.test\")\n",
    "trees, trees_weights = adaboost(X, Y, 10)\n",
    "Yhat = adaboost_predict(X, trees, trees_weights)\n",
    "Yhat_test = adaboost_predict(X_test, trees, trees_weights)\n",
    "    \n",
    "acc_test = accuracy(Y_test, Yhat_test)\n",
    "acc_train = accuracy(Y, Yhat)\n",
    "print(\"Train Accuracy %.4f\" % acc_train)\n",
    "print(\"Test Accuracy %.4f\" % acc_test)\n",
    "assert(np.around(acc_train, decimals=4)==0.9111)\n",
    "assert(np.around(acc_test, decimals=4)==0.9190)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find best num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = parse_spambase_data(\"spambase.train\")\n",
    "X_test, Y_test = parse_spambase_data(\"spambase.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 57) (720, 57) (2880, 1) (720, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y, test_size=0.2)\n",
    "print(X_train.shape, X_valid.shape, Y_train.shape, Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "errors_vld = []\n",
    "errors_trn = []\n",
    "for i in range(1, 2001):\n",
    "    trees, trees_weights = adaboost(X_train, Y_train, i)\n",
    "    Yhat_train = adaboost_predict(X_train, trees, trees_weights)\n",
    "    Yhat_valid = adaboost_predict(X_valid, trees, trees_weights)\n",
    "    err_valid = 1-accuracy(Y_valid, Yhat_valid)\n",
    "    err_train = 1-accuracy(Y_train, Yhat_train)\n",
    "    errors_vld.append(err_valid)\n",
    "    errors_trn.append(err_train)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95416666666666672"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best validation accuracy\n",
    "1 - min(errors_vld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The best value of num_iter\n",
    "errors_vld_array = np.array(errors_vld)\n",
    "np.argmin(errors_vld_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_error_rate(er_train, er_test):\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    df_error = pd.DataFrame([er_train, er_test]).T\n",
    "    df_error.columns = ['Training', 'Validation']\n",
    "    plot1 = df_error.plot(linewidth = 3, figsize = (8,6),\n",
    "            color = ['lightblue', 'darkblue'], grid = True)\n",
    "    plot1.set_xlabel('Number of iterations', fontsize = 12)\n",
    "    plot1.set_xticklabels(range(0,2001,250))\n",
    "    plot1.set_ylabel('Error rate', fontsize = 12)\n",
    "    plot1.set_title('Error rate vs number of iterations', fontsize = 16)\n",
    "    plt.axhline(y=er_test[0], linewidth=1, color = 'red', ls = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAGICAYAAAApumhhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8sUP93pcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120f9ada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_error_rate(errors_trn, errors_vld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954166666667\n",
      "0.946527777778\n"
     ]
    }
   ],
   "source": [
    "print(1 - errors_vld[266])\n",
    "print(1 - errors_trn[266])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When numTrees = 266, validation accuracy is the highest and has a value of 0.9542. Corresponding train accuracy is 0.9465."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trees, trees_weights = adaboost(X, Y, 266)\n",
    "Yhat_test = adaboost_predict(X_test, trees, trees_weights)\n",
    "err_test = 1-accuracy(Y_test, Yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952\n"
     ]
    }
   ],
   "source": [
    "print(1-err_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the model above, test accuracy is 0.952."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y[Y==-1]=0\n",
    "dcv = xgb.DMatrix(X, label=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth':7,\n",
    "    'min_child_weight': 5,\n",
    "    'eta':.1,\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'error'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight, subsample, colsample, eta)\n",
    "    for max_depth in range(7,9)\n",
    "    for min_child_weight in range(5,7)\n",
    "    for subsample in [0.5, 0.7]\n",
    "    for colsample in [0.5, 0.7]\n",
    "    for eta in [.1, .05]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=7, min_child_weight=5, subsample=0.5, colsample=0.5, eta=0.1\n",
      "\terror 0.053611 for 94 rounds\n",
      "CV with max_depth=7, min_child_weight=5, subsample=0.5, colsample=0.5, eta=0.05\n",
      "\terror 0.0527778 for 199 rounds\n",
      "CV with max_depth=7, min_child_weight=5, subsample=0.5, colsample=0.7, eta=0.1\n",
      "\terror 0.0552778 for 81 rounds\n",
      "CV with max_depth=7, min_child_weight=5, subsample=0.5, colsample=0.7, eta=0.05\n",
      "\terror 0.0516668 for 176 rounds\n",
      "CV with max_depth=7, min_child_weight=5, subsample=0.7, colsample=0.5, eta=0.1\n",
      "\terror 0.0511112 for 78 rounds\n",
      "CV with max_depth=7, min_child_weight=5, subsample=0.7, colsample=0.5, eta=0.05\n",
      "\terror 0.0508332 for 174 rounds\n",
      "CV with max_depth=7, min_child_weight=5, subsample=0.7, colsample=0.7, eta=0.1\n",
      "\terror 0.052778000000000005 for 93 rounds\n",
      "CV with max_depth=7, min_child_weight=5, subsample=0.7, colsample=0.7, eta=0.05\n",
      "\terror 0.0502776 for 188 rounds\n",
      "CV with max_depth=7, min_child_weight=6, subsample=0.5, colsample=0.5, eta=0.1\n",
      "\terror 0.0547222 for 107 rounds\n",
      "CV with max_depth=7, min_child_weight=6, subsample=0.5, colsample=0.5, eta=0.05\n",
      "\terror 0.0549998 for 125 rounds\n",
      "CV with max_depth=7, min_child_weight=6, subsample=0.5, colsample=0.7, eta=0.1\n",
      "\terror 0.0552778 for 133 rounds\n",
      "CV with max_depth=7, min_child_weight=6, subsample=0.5, colsample=0.7, eta=0.05\n",
      "\terror 0.053055399999999996 for 191 rounds\n",
      "CV with max_depth=7, min_child_weight=6, subsample=0.7, colsample=0.5, eta=0.1\n",
      "\terror 0.05166659999999999 for 77 rounds\n",
      "CV with max_depth=7, min_child_weight=6, subsample=0.7, colsample=0.5, eta=0.05\n",
      "\terror 0.0505556 for 156 rounds\n",
      "CV with max_depth=7, min_child_weight=6, subsample=0.7, colsample=0.7, eta=0.1\n",
      "\terror 0.0530556 for 109 rounds\n",
      "CV with max_depth=7, min_child_weight=6, subsample=0.7, colsample=0.7, eta=0.05\n",
      "\terror 0.0505556 for 189 rounds\n",
      "CV with max_depth=8, min_child_weight=5, subsample=0.5, colsample=0.5, eta=0.1\n",
      "\terror 0.053888799999999994 for 114 rounds\n",
      "CV with max_depth=8, min_child_weight=5, subsample=0.5, colsample=0.5, eta=0.05\n",
      "\terror 0.052500000000000005 for 167 rounds\n",
      "CV with max_depth=8, min_child_weight=5, subsample=0.5, colsample=0.7, eta=0.1\n",
      "\terror 0.0541668 for 85 rounds\n",
      "CV with max_depth=8, min_child_weight=5, subsample=0.5, colsample=0.7, eta=0.05\n",
      "\terror 0.053611 for 199 rounds\n",
      "CV with max_depth=8, min_child_weight=5, subsample=0.7, colsample=0.5, eta=0.1\n",
      "\terror 0.05055539999999999 for 158 rounds\n",
      "CV with max_depth=8, min_child_weight=5, subsample=0.7, colsample=0.5, eta=0.05\n",
      "\terror 0.050278 for 141 rounds\n",
      "CV with max_depth=8, min_child_weight=5, subsample=0.7, colsample=0.7, eta=0.1\n",
      "\terror 0.051944599999999994 for 69 rounds\n",
      "CV with max_depth=8, min_child_weight=5, subsample=0.7, colsample=0.7, eta=0.05\n",
      "\terror 0.051389 for 134 rounds\n",
      "CV with max_depth=8, min_child_weight=6, subsample=0.5, colsample=0.5, eta=0.1\n",
      "\terror 0.051944599999999994 for 96 rounds\n",
      "CV with max_depth=8, min_child_weight=6, subsample=0.5, colsample=0.5, eta=0.05\n",
      "\terror 0.0519444 for 181 rounds\n",
      "CV with max_depth=8, min_child_weight=6, subsample=0.5, colsample=0.7, eta=0.1\n",
      "\terror 0.0558334 for 127 rounds\n",
      "CV with max_depth=8, min_child_weight=6, subsample=0.5, colsample=0.7, eta=0.05\n",
      "\terror 0.052500000000000005 for 192 rounds\n",
      "CV with max_depth=8, min_child_weight=6, subsample=0.7, colsample=0.5, eta=0.1\n",
      "\terror 0.05083340000000001 for 95 rounds\n",
      "CV with max_depth=8, min_child_weight=6, subsample=0.7, colsample=0.5, eta=0.05\n",
      "\terror 0.0505556 for 159 rounds\n",
      "CV with max_depth=8, min_child_weight=6, subsample=0.7, colsample=0.7, eta=0.1\n",
      "\terror 0.051944199999999996 for 108 rounds\n",
      "CV with max_depth=8, min_child_weight=6, subsample=0.7, colsample=0.7, eta=0.05\n",
      "\terror 0.051389 for 162 rounds\n"
     ]
    }
   ],
   "source": [
    "min_error = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight, subsample, colsample, eta in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}, subsample={}, colsample={}, eta={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight,\n",
    "                             subsample,\n",
    "                             colsample,\n",
    "                             eta))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    params['eta'] = eta\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dcv,\n",
    "        num_boost_round=200,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'error'},\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    # Update best error\n",
    "    mean_error = cv_results['test-error-mean'].min()\n",
    "    boost_rounds = cv_results['test-error-mean'].argmin()\n",
    "    print(\"\\terror {} for {} rounds\".format(mean_error, boost_rounds))\n",
    "    if mean_error < min_error:\n",
    "        min_error = mean_error\n",
    "        best_params = [max_depth,min_child_weight,subsample,colsample,eta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 5, 0.7, 0.7, 0.05] 0.0502776\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters\n",
    "print(best_params, min_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9497224\n"
     ]
    }
   ],
   "source": [
    "# Best cross-validation mean accuracy\n",
    "print(1-min_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model with optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth':7,\n",
    "    'min_child_weight': 5,\n",
    "    'eta':0.05,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'error'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test[Y_test==-1]=0\n",
    "dtest = xgb.DMatrix(X_test, label=Y_test)\n",
    "watchlist = [(dcv, 'train'), (dtest, 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.106667\ttest-error:0.112\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 50 rounds.\n",
      "[10]\ttrain-error:0.061944\ttest-error:0.073\n",
      "[20]\ttrain-error:0.054167\ttest-error:0.061\n",
      "[30]\ttrain-error:0.051667\ttest-error:0.056\n",
      "[40]\ttrain-error:0.049444\ttest-error:0.053\n",
      "[50]\ttrain-error:0.047778\ttest-error:0.05\n",
      "[60]\ttrain-error:0.046389\ttest-error:0.046\n",
      "[70]\ttrain-error:0.044444\ttest-error:0.046\n",
      "[80]\ttrain-error:0.038889\ttest-error:0.044\n",
      "[90]\ttrain-error:0.038333\ttest-error:0.043\n",
      "[100]\ttrain-error:0.036111\ttest-error:0.041\n",
      "[110]\ttrain-error:0.035278\ttest-error:0.041\n",
      "[120]\ttrain-error:0.033056\ttest-error:0.04\n",
      "[130]\ttrain-error:0.031944\ttest-error:0.04\n",
      "[140]\ttrain-error:0.031111\ttest-error:0.038\n",
      "[150]\ttrain-error:0.030278\ttest-error:0.038\n",
      "[160]\ttrain-error:0.028889\ttest-error:0.037\n",
      "[170]\ttrain-error:0.028889\ttest-error:0.037\n",
      "[180]\ttrain-error:0.026944\ttest-error:0.038\n",
      "[190]\ttrain-error:0.024722\ttest-error:0.037\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.train(params, dcv, 200, watchlist, early_stopping_rounds=50,\n",
    "                maximize=False, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975278 0.963\n"
     ]
    }
   ],
   "source": [
    "print(1-0.024722, 1-0.037)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the best hyperparameters, we retrain the model on the whole training set. The training accuracy is 0.9753, and the test accuracy is 0.963. So XGBoost has a better result than AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
