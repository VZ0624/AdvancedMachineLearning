{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ds = datasets.MNIST('./data', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "test_ds = datasets.MNIST('./data', train=False, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "#batch_size = 5 # for testing\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(M = 300):\n",
    "    net = nn.Sequential(nn.Linear(28*28, M),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M, 10))\n",
    "    return net.cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, num_epochs, model, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            batch = images.shape[0] # size of the batch\n",
    "            # Convert torch tensor to Variable, change shape of the input\n",
    "            images = Variable(images.view(-1, 28*28)).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "        \n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total += batch\n",
    "            sum_loss += batch * loss.data[0]\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, sum_loss/total))\n",
    "                \n",
    "        train_loss = sum_loss/total\n",
    "        print('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, train_loss))\n",
    "        val_acc, val_loss = model_accuracy_loss(model, test_loader)\n",
    "        print('Epoch [%d/%d], Valid Accuracy: %.4f, Valid Loss: %.4f' %(epoch+1, num_epochs, val_acc, val_loss))\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_accuracy_loss(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images.view(-1, 28*28)).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        sum_loss += labels.size(0)*loss.data[0]\n",
    "        total += labels.size(0)\n",
    "        correct += pred.eq(labels.data).cpu().sum()\n",
    "    return 100 * correct / total, sum_loss/ total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tuning learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1172.2778\n",
      "Epoch [1/10], Loss: 588.9818\n",
      "Epoch [1/10], Loss: 394.1114\n",
      "Epoch [1/10], Loss: 297.4443\n",
      "Epoch [1/10], Loss: 240.3124\n",
      "Epoch [1/10], Loss: 200.8506\n",
      "Epoch [1/10], Loss: 172.7901\n",
      "Epoch [1/10], Loss: 151.7264\n",
      "Epoch [1/10], Loss: 135.5990\n",
      "Epoch [1/10], Loss: 130.2964\n",
      "Epoch [1/10], Valid Accuracy: 10.6400, Valid Loss: 2.3993\n",
      "Epoch [2/10], Loss: 2.3449\n",
      "Epoch [2/10], Loss: 2.5594\n",
      "Epoch [2/10], Loss: 2.4900\n",
      "Epoch [2/10], Loss: 2.6642\n",
      "Epoch [2/10], Loss: 3.0661\n",
      "Epoch [2/10], Loss: 4.7069\n",
      "Epoch [2/10], Loss: 4.3755\n",
      "Epoch [2/10], Loss: 4.1224\n",
      "Epoch [2/10], Loss: 3.9256\n",
      "Epoch [2/10], Loss: 3.9242\n",
      "Epoch [2/10], Valid Accuracy: 10.5100, Valid Loss: 2.6064\n",
      "Epoch [3/10], Loss: 2.8913\n",
      "Epoch [3/10], Loss: 2.5845\n",
      "Epoch [3/10], Loss: 2.5628\n",
      "Epoch [3/10], Loss: 2.5244\n",
      "Epoch [3/10], Loss: 2.4963\n",
      "Epoch [3/10], Loss: 2.4762\n",
      "Epoch [3/10], Loss: 2.4601\n",
      "Epoch [3/10], Loss: 2.4481\n",
      "Epoch [3/10], Loss: 2.4387\n",
      "Epoch [3/10], Loss: 2.4362\n",
      "Epoch [3/10], Valid Accuracy: 10.1600, Valid Loss: 2.4763\n",
      "Epoch [4/10], Loss: 2.3764\n",
      "Epoch [4/10], Loss: 2.3704\n",
      "Epoch [4/10], Loss: 2.3700\n",
      "Epoch [4/10], Loss: 2.3734\n",
      "Epoch [4/10], Loss: 2.3723\n",
      "Epoch [4/10], Loss: 2.3698\n",
      "Epoch [4/10], Loss: 2.3668\n",
      "Epoch [4/10], Loss: 2.3670\n",
      "Epoch [4/10], Loss: 2.3681\n",
      "Epoch [4/10], Loss: 2.3686\n",
      "Epoch [4/10], Valid Accuracy: 11.4200, Valid Loss: 2.4136\n",
      "Epoch [5/10], Loss: 2.3578\n",
      "Epoch [5/10], Loss: 2.3688\n",
      "Epoch [5/10], Loss: 2.3767\n",
      "Epoch [5/10], Loss: 2.3794\n",
      "Epoch [5/10], Loss: 2.3794\n",
      "Epoch [5/10], Loss: 2.3789\n",
      "Epoch [5/10], Loss: 2.3770\n",
      "Epoch [5/10], Loss: 2.3746\n",
      "Epoch [5/10], Loss: 2.3751\n",
      "Epoch [5/10], Loss: 2.3741\n",
      "Epoch [5/10], Valid Accuracy: 10.1600, Valid Loss: 2.4768\n",
      "Epoch [6/10], Loss: 2.3736\n",
      "Epoch [6/10], Loss: 2.3685\n",
      "Epoch [6/10], Loss: 2.3695\n",
      "Epoch [6/10], Loss: 2.3751\n",
      "Epoch [6/10], Loss: 2.3728\n",
      "Epoch [6/10], Loss: 2.3746\n",
      "Epoch [6/10], Loss: 2.3738\n",
      "Epoch [6/10], Loss: 2.3723\n",
      "Epoch [6/10], Loss: 2.3740\n",
      "Epoch [6/10], Loss: 2.3734\n",
      "Epoch [6/10], Valid Accuracy: 9.8800, Valid Loss: 2.4342\n",
      "Epoch [7/10], Loss: 2.3547\n",
      "Epoch [7/10], Loss: 2.3633\n",
      "Epoch [7/10], Loss: 2.3653\n",
      "Epoch [7/10], Loss: 2.3646\n",
      "Epoch [7/10], Loss: 2.3665\n",
      "Epoch [7/10], Loss: 2.3673\n",
      "Epoch [7/10], Loss: 2.3661\n",
      "Epoch [7/10], Loss: 2.3653\n",
      "Epoch [7/10], Loss: 2.3671\n",
      "Epoch [7/10], Loss: 2.3670\n",
      "Epoch [7/10], Valid Accuracy: 9.6400, Valid Loss: 2.4311\n",
      "Epoch [8/10], Loss: 2.3857\n",
      "Epoch [8/10], Loss: 2.3827\n",
      "Epoch [8/10], Loss: 2.3819\n",
      "Epoch [8/10], Loss: 2.3770\n",
      "Epoch [8/10], Loss: 2.3722\n",
      "Epoch [8/10], Loss: 2.3758\n",
      "Epoch [8/10], Loss: 2.3763\n",
      "Epoch [8/10], Loss: 2.3745\n",
      "Epoch [8/10], Loss: 2.3764\n",
      "Epoch [8/10], Loss: 2.3769\n",
      "Epoch [8/10], Valid Accuracy: 10.1600, Valid Loss: 2.4883\n",
      "Epoch [9/10], Loss: 2.3607\n",
      "Epoch [9/10], Loss: 2.3650\n",
      "Epoch [9/10], Loss: 2.3647\n",
      "Epoch [9/10], Loss: 2.3636\n",
      "Epoch [9/10], Loss: 2.3619\n",
      "Epoch [9/10], Loss: 2.3615\n",
      "Epoch [9/10], Loss: 2.3631\n",
      "Epoch [9/10], Loss: 2.3646\n",
      "Epoch [9/10], Loss: 2.3642\n",
      "Epoch [9/10], Loss: 2.3636\n",
      "Epoch [9/10], Valid Accuracy: 9.8200, Valid Loss: 2.4076\n",
      "Epoch [10/10], Loss: 2.3689\n",
      "Epoch [10/10], Loss: 2.3675\n",
      "Epoch [10/10], Loss: 2.3654\n",
      "Epoch [10/10], Loss: 2.3678\n",
      "Epoch [10/10], Loss: 2.3683\n",
      "Epoch [10/10], Loss: 2.3697\n",
      "Epoch [10/10], Loss: 2.3705\n",
      "Epoch [10/10], Loss: 2.3717\n",
      "Epoch [10/10], Loss: 2.3719\n",
      "Epoch [10/10], Loss: 2.3739\n",
      "Epoch [10/10], Valid Accuracy: 10.3900, Valid Loss: 2.4750\n",
      "Epoch [1/10], Loss: 10.0572\n",
      "Epoch [1/10], Loss: 5.7883\n",
      "Epoch [1/10], Loss: 4.3368\n",
      "Epoch [1/10], Loss: 3.5975\n",
      "Epoch [1/10], Loss: 3.1517\n",
      "Epoch [1/10], Loss: 2.8806\n",
      "Epoch [1/10], Loss: 2.6981\n",
      "Epoch [1/10], Loss: 2.5859\n",
      "Epoch [1/10], Loss: 2.4872\n",
      "Epoch [1/10], Loss: 2.4559\n",
      "Epoch [1/10], Valid Accuracy: 45.8600, Valid Loss: 1.7402\n",
      "Epoch [2/10], Loss: 1.6144\n",
      "Epoch [2/10], Loss: 1.6442\n",
      "Epoch [2/10], Loss: 1.6750\n",
      "Epoch [2/10], Loss: 1.7002\n",
      "Epoch [2/10], Loss: 1.7370\n",
      "Epoch [2/10], Loss: 1.8007\n",
      "Epoch [2/10], Loss: 1.8364\n",
      "Epoch [2/10], Loss: 1.8487\n",
      "Epoch [2/10], Loss: 1.8752\n",
      "Epoch [2/10], Loss: 1.8816\n",
      "Epoch [2/10], Valid Accuracy: 22.4800, Valid Loss: 2.0182\n",
      "Epoch [3/10], Loss: 2.0028\n",
      "Epoch [3/10], Loss: 2.0633\n",
      "Epoch [3/10], Loss: 2.0745\n",
      "Epoch [3/10], Loss: 2.0440\n",
      "Epoch [3/10], Loss: 2.0595\n",
      "Epoch [3/10], Loss: 2.0860\n",
      "Epoch [3/10], Loss: 2.1113\n",
      "Epoch [3/10], Loss: 2.1227\n",
      "Epoch [3/10], Loss: 2.1191\n",
      "Epoch [3/10], Loss: 2.1181\n",
      "Epoch [3/10], Valid Accuracy: 20.9200, Valid Loss: 2.0707\n",
      "Epoch [4/10], Loss: 2.0854\n",
      "Epoch [4/10], Loss: 2.1853\n",
      "Epoch [4/10], Loss: 2.2068\n",
      "Epoch [4/10], Loss: 2.2020\n",
      "Epoch [4/10], Loss: 2.1966\n",
      "Epoch [4/10], Loss: 2.1951\n",
      "Epoch [4/10], Loss: 2.2026\n",
      "Epoch [4/10], Loss: 2.2130\n",
      "Epoch [4/10], Loss: 2.2311\n",
      "Epoch [4/10], Loss: 2.2268\n",
      "Epoch [4/10], Valid Accuracy: 16.1700, Valid Loss: 2.1396\n",
      "Epoch [5/10], Loss: 2.1536\n",
      "Epoch [5/10], Loss: 2.2103\n",
      "Epoch [5/10], Loss: 2.2181\n",
      "Epoch [5/10], Loss: 2.2042\n",
      "Epoch [5/10], Loss: 2.2293\n",
      "Epoch [5/10], Loss: 2.2200\n",
      "Epoch [5/10], Loss: 2.2087\n",
      "Epoch [5/10], Loss: 2.2143\n",
      "Epoch [5/10], Loss: 2.2250\n",
      "Epoch [5/10], Loss: 2.2282\n",
      "Epoch [5/10], Valid Accuracy: 10.1700, Valid Loss: 2.3734\n",
      "Epoch [6/10], Loss: 2.2970\n",
      "Epoch [6/10], Loss: 2.3039\n",
      "Epoch [6/10], Loss: 2.3014\n",
      "Epoch [6/10], Loss: 2.2977\n",
      "Epoch [6/10], Loss: 2.2904\n",
      "Epoch [6/10], Loss: 2.2659\n",
      "Epoch [6/10], Loss: 2.2624\n",
      "Epoch [6/10], Loss: 2.2604\n",
      "Epoch [6/10], Loss: 2.2602\n",
      "Epoch [6/10], Loss: 2.2604\n",
      "Epoch [6/10], Valid Accuracy: 11.4200, Valid Loss: 2.2702\n",
      "Epoch [7/10], Loss: 2.2169\n",
      "Epoch [7/10], Loss: 2.5080\n",
      "Epoch [7/10], Loss: 2.4427\n",
      "Epoch [7/10], Loss: 2.4069\n",
      "Epoch [7/10], Loss: 2.3856\n",
      "Epoch [7/10], Loss: 2.3701\n",
      "Epoch [7/10], Loss: 2.3601\n",
      "Epoch [7/10], Loss: 2.3529\n",
      "Epoch [7/10], Loss: 2.3471\n",
      "Epoch [7/10], Loss: 2.3456\n",
      "Epoch [7/10], Valid Accuracy: 10.4300, Valid Loss: 2.3105\n",
      "Epoch [8/10], Loss: 2.3215\n",
      "Epoch [8/10], Loss: 2.3105\n",
      "Epoch [8/10], Loss: 2.3070\n",
      "Epoch [8/10], Loss: 2.3049\n",
      "Epoch [8/10], Loss: 2.3046\n",
      "Epoch [8/10], Loss: 2.3040\n",
      "Epoch [8/10], Loss: 2.3034\n",
      "Epoch [8/10], Loss: 2.3033\n",
      "Epoch [8/10], Loss: 2.3026\n",
      "Epoch [8/10], Loss: 2.3024\n",
      "Epoch [8/10], Valid Accuracy: 10.3500, Valid Loss: 2.2985\n",
      "Epoch [9/10], Loss: 2.2987\n",
      "Epoch [9/10], Loss: 2.2961\n",
      "Epoch [9/10], Loss: 2.2879\n",
      "Epoch [9/10], Loss: 2.2653\n",
      "Epoch [9/10], Loss: 2.2740\n",
      "Epoch [9/10], Loss: 2.2730\n",
      "Epoch [9/10], Loss: 2.2724\n",
      "Epoch [9/10], Loss: 2.2720\n",
      "Epoch [9/10], Loss: 2.2700\n",
      "Epoch [9/10], Loss: 2.2689\n",
      "Epoch [9/10], Valid Accuracy: 11.7900, Valid Loss: 2.2652\n",
      "Epoch [10/10], Loss: 2.2538\n",
      "Epoch [10/10], Loss: 2.2537\n",
      "Epoch [10/10], Loss: 2.2487\n",
      "Epoch [10/10], Loss: 2.2510\n",
      "Epoch [10/10], Loss: 2.2498\n",
      "Epoch [10/10], Loss: 2.2483\n",
      "Epoch [10/10], Loss: 2.2554\n",
      "Epoch [10/10], Loss: 2.2609\n",
      "Epoch [10/10], Loss: 2.2656\n",
      "Epoch [10/10], Loss: 2.2670\n",
      "Epoch [10/10], Valid Accuracy: 9.8500, Valid Loss: 2.3058\n",
      "Epoch [1/10], Loss: 0.5952\n",
      "Epoch [1/10], Loss: 0.4421\n",
      "Epoch [1/10], Loss: 0.3830\n",
      "Epoch [1/10], Loss: 0.3493\n",
      "Epoch [1/10], Loss: 0.3274\n",
      "Epoch [1/10], Loss: 0.3113\n",
      "Epoch [1/10], Loss: 0.2984\n",
      "Epoch [1/10], Loss: 0.2896\n",
      "Epoch [1/10], Loss: 0.2877\n",
      "Epoch [1/10], Loss: 0.2866\n",
      "Epoch [1/10], Valid Accuracy: 94.4600, Valid Loss: 0.1932\n",
      "Epoch [2/10], Loss: 0.1993\n",
      "Epoch [2/10], Loss: 0.2018\n",
      "Epoch [2/10], Loss: 0.2143\n",
      "Epoch [2/10], Loss: 0.2114\n",
      "Epoch [2/10], Loss: 0.2081\n",
      "Epoch [2/10], Loss: 0.2060\n",
      "Epoch [2/10], Loss: 0.2064\n",
      "Epoch [2/10], Loss: 0.2056\n",
      "Epoch [2/10], Loss: 0.2028\n",
      "Epoch [2/10], Loss: 0.2027\n",
      "Epoch [2/10], Valid Accuracy: 93.8000, Valid Loss: 0.2450\n",
      "Epoch [3/10], Loss: 0.1619\n",
      "Epoch [3/10], Loss: 0.1812\n",
      "Epoch [3/10], Loss: 0.1891\n",
      "Epoch [3/10], Loss: 0.1969\n",
      "Epoch [3/10], Loss: 0.1989\n",
      "Epoch [3/10], Loss: 0.2009\n",
      "Epoch [3/10], Loss: 0.1991\n",
      "Epoch [3/10], Loss: 0.1961\n",
      "Epoch [3/10], Loss: 0.1959\n",
      "Epoch [3/10], Loss: 0.1954\n",
      "Epoch [3/10], Valid Accuracy: 94.4000, Valid Loss: 0.2319\n",
      "Epoch [4/10], Loss: 0.1498\n",
      "Epoch [4/10], Loss: 0.1559\n",
      "Epoch [4/10], Loss: 0.1694\n",
      "Epoch [4/10], Loss: 0.1716\n",
      "Epoch [4/10], Loss: 0.1774\n",
      "Epoch [4/10], Loss: 0.1817\n",
      "Epoch [4/10], Loss: 0.1807\n",
      "Epoch [4/10], Loss: 0.1811\n",
      "Epoch [4/10], Loss: 0.1847\n",
      "Epoch [4/10], Loss: 0.1859\n",
      "Epoch [4/10], Valid Accuracy: 94.0900, Valid Loss: 0.2318\n",
      "Epoch [5/10], Loss: 0.1576\n",
      "Epoch [5/10], Loss: 0.1547\n",
      "Epoch [5/10], Loss: 0.1574\n",
      "Epoch [5/10], Loss: 0.1562\n",
      "Epoch [5/10], Loss: 0.1625\n",
      "Epoch [5/10], Loss: 0.1649\n",
      "Epoch [5/10], Loss: 0.1687\n",
      "Epoch [5/10], Loss: 0.1728\n",
      "Epoch [5/10], Loss: 0.1749\n",
      "Epoch [5/10], Loss: 0.1756\n",
      "Epoch [5/10], Valid Accuracy: 94.4200, Valid Loss: 0.2430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.1551\n",
      "Epoch [6/10], Loss: 0.1533\n",
      "Epoch [6/10], Loss: 0.1627\n",
      "Epoch [6/10], Loss: 0.1598\n",
      "Epoch [6/10], Loss: 0.1642\n",
      "Epoch [6/10], Loss: 0.1661\n",
      "Epoch [6/10], Loss: 0.1679\n",
      "Epoch [6/10], Loss: 0.1681\n",
      "Epoch [6/10], Loss: 0.1675\n",
      "Epoch [6/10], Loss: 0.1689\n",
      "Epoch [6/10], Valid Accuracy: 95.1000, Valid Loss: 0.2060\n",
      "Epoch [7/10], Loss: 0.1666\n",
      "Epoch [7/10], Loss: 0.1536\n",
      "Epoch [7/10], Loss: 0.1574\n",
      "Epoch [7/10], Loss: 0.1615\n",
      "Epoch [7/10], Loss: 0.1604\n",
      "Epoch [7/10], Loss: 0.1662\n",
      "Epoch [7/10], Loss: 0.1712\n",
      "Epoch [7/10], Loss: 0.1709\n",
      "Epoch [7/10], Loss: 0.1726\n",
      "Epoch [7/10], Loss: 0.1730\n",
      "Epoch [7/10], Valid Accuracy: 95.3500, Valid Loss: 0.2338\n",
      "Epoch [8/10], Loss: 0.1468\n",
      "Epoch [8/10], Loss: 0.1395\n",
      "Epoch [8/10], Loss: 0.1440\n",
      "Epoch [8/10], Loss: 0.1540\n",
      "Epoch [8/10], Loss: 0.1557\n",
      "Epoch [8/10], Loss: 0.1589\n",
      "Epoch [8/10], Loss: 0.1565\n",
      "Epoch [8/10], Loss: 0.1579\n",
      "Epoch [8/10], Loss: 0.1583\n",
      "Epoch [8/10], Loss: 0.1593\n",
      "Epoch [8/10], Valid Accuracy: 94.9800, Valid Loss: 0.2854\n",
      "Epoch [9/10], Loss: 0.1647\n",
      "Epoch [9/10], Loss: 0.1612\n",
      "Epoch [9/10], Loss: 0.1515\n",
      "Epoch [9/10], Loss: 0.1558\n",
      "Epoch [9/10], Loss: 0.1581\n",
      "Epoch [9/10], Loss: 0.1598\n",
      "Epoch [9/10], Loss: 0.1575\n",
      "Epoch [9/10], Loss: 0.1543\n",
      "Epoch [9/10], Loss: 0.1564\n",
      "Epoch [9/10], Loss: 0.1573\n",
      "Epoch [9/10], Valid Accuracy: 94.9900, Valid Loss: 0.2524\n",
      "Epoch [10/10], Loss: 0.1686\n",
      "Epoch [10/10], Loss: 0.1606\n",
      "Epoch [10/10], Loss: 0.1591\n",
      "Epoch [10/10], Loss: 0.1546\n",
      "Epoch [10/10], Loss: 0.1583\n",
      "Epoch [10/10], Loss: 0.1540\n",
      "Epoch [10/10], Loss: 0.1537\n",
      "Epoch [10/10], Loss: 0.1558\n",
      "Epoch [10/10], Loss: 0.1563\n",
      "Epoch [10/10], Loss: 0.1549\n",
      "Epoch [10/10], Valid Accuracy: 95.3500, Valid Loss: 0.2876\n",
      "Epoch [1/10], Loss: 0.5510\n",
      "Epoch [1/10], Loss: 0.4216\n",
      "Epoch [1/10], Loss: 0.3614\n",
      "Epoch [1/10], Loss: 0.3226\n",
      "Epoch [1/10], Loss: 0.2914\n",
      "Epoch [1/10], Loss: 0.2711\n",
      "Epoch [1/10], Loss: 0.2534\n",
      "Epoch [1/10], Loss: 0.2374\n",
      "Epoch [1/10], Loss: 0.2244\n",
      "Epoch [1/10], Loss: 0.2201\n",
      "Epoch [1/10], Valid Accuracy: 96.7100, Valid Loss: 0.1163\n",
      "Epoch [2/10], Loss: 0.0961\n",
      "Epoch [2/10], Loss: 0.0965\n",
      "Epoch [2/10], Loss: 0.0975\n",
      "Epoch [2/10], Loss: 0.0966\n",
      "Epoch [2/10], Loss: 0.0960\n",
      "Epoch [2/10], Loss: 0.0933\n",
      "Epoch [2/10], Loss: 0.0940\n",
      "Epoch [2/10], Loss: 0.0934\n",
      "Epoch [2/10], Loss: 0.0917\n",
      "Epoch [2/10], Loss: 0.0911\n",
      "Epoch [2/10], Valid Accuracy: 97.0100, Valid Loss: 0.0968\n",
      "Epoch [3/10], Loss: 0.0638\n",
      "Epoch [3/10], Loss: 0.0603\n",
      "Epoch [3/10], Loss: 0.0594\n",
      "Epoch [3/10], Loss: 0.0597\n",
      "Epoch [3/10], Loss: 0.0611\n",
      "Epoch [3/10], Loss: 0.0610\n",
      "Epoch [3/10], Loss: 0.0609\n",
      "Epoch [3/10], Loss: 0.0609\n",
      "Epoch [3/10], Loss: 0.0607\n",
      "Epoch [3/10], Loss: 0.0609\n",
      "Epoch [3/10], Valid Accuracy: 97.5400, Valid Loss: 0.0833\n",
      "Epoch [4/10], Loss: 0.0387\n",
      "Epoch [4/10], Loss: 0.0395\n",
      "Epoch [4/10], Loss: 0.0402\n",
      "Epoch [4/10], Loss: 0.0433\n",
      "Epoch [4/10], Loss: 0.0434\n",
      "Epoch [4/10], Loss: 0.0440\n",
      "Epoch [4/10], Loss: 0.0446\n",
      "Epoch [4/10], Loss: 0.0452\n",
      "Epoch [4/10], Loss: 0.0451\n",
      "Epoch [4/10], Loss: 0.0450\n",
      "Epoch [4/10], Valid Accuracy: 97.5300, Valid Loss: 0.0837\n",
      "Epoch [5/10], Loss: 0.0263\n",
      "Epoch [5/10], Loss: 0.0279\n",
      "Epoch [5/10], Loss: 0.0294\n",
      "Epoch [5/10], Loss: 0.0292\n",
      "Epoch [5/10], Loss: 0.0290\n",
      "Epoch [5/10], Loss: 0.0313\n",
      "Epoch [5/10], Loss: 0.0342\n",
      "Epoch [5/10], Loss: 0.0350\n",
      "Epoch [5/10], Loss: 0.0363\n",
      "Epoch [5/10], Loss: 0.0366\n",
      "Epoch [5/10], Valid Accuracy: 97.9300, Valid Loss: 0.0696\n",
      "Epoch [6/10], Loss: 0.0217\n",
      "Epoch [6/10], Loss: 0.0215\n",
      "Epoch [6/10], Loss: 0.0221\n",
      "Epoch [6/10], Loss: 0.0230\n",
      "Epoch [6/10], Loss: 0.0237\n",
      "Epoch [6/10], Loss: 0.0261\n",
      "Epoch [6/10], Loss: 0.0269\n",
      "Epoch [6/10], Loss: 0.0288\n",
      "Epoch [6/10], Loss: 0.0284\n",
      "Epoch [6/10], Loss: 0.0285\n",
      "Epoch [6/10], Valid Accuracy: 98.0800, Valid Loss: 0.0674\n",
      "Epoch [7/10], Loss: 0.0161\n",
      "Epoch [7/10], Loss: 0.0160\n",
      "Epoch [7/10], Loss: 0.0173\n",
      "Epoch [7/10], Loss: 0.0188\n",
      "Epoch [7/10], Loss: 0.0189\n",
      "Epoch [7/10], Loss: 0.0189\n",
      "Epoch [7/10], Loss: 0.0196\n",
      "Epoch [7/10], Loss: 0.0206\n",
      "Epoch [7/10], Loss: 0.0214\n",
      "Epoch [7/10], Loss: 0.0213\n",
      "Epoch [7/10], Valid Accuracy: 98.1200, Valid Loss: 0.0677\n",
      "Epoch [8/10], Loss: 0.0135\n",
      "Epoch [8/10], Loss: 0.0144\n",
      "Epoch [8/10], Loss: 0.0143\n",
      "Epoch [8/10], Loss: 0.0142\n",
      "Epoch [8/10], Loss: 0.0163\n",
      "Epoch [8/10], Loss: 0.0174\n",
      "Epoch [8/10], Loss: 0.0186\n",
      "Epoch [8/10], Loss: 0.0201\n",
      "Epoch [8/10], Loss: 0.0213\n",
      "Epoch [8/10], Loss: 0.0214\n",
      "Epoch [8/10], Valid Accuracy: 97.3900, Valid Loss: 0.1005\n",
      "Epoch [9/10], Loss: 0.0201\n",
      "Epoch [9/10], Loss: 0.0163\n",
      "Epoch [9/10], Loss: 0.0150\n",
      "Epoch [9/10], Loss: 0.0136\n",
      "Epoch [9/10], Loss: 0.0138\n",
      "Epoch [9/10], Loss: 0.0146\n",
      "Epoch [9/10], Loss: 0.0144\n",
      "Epoch [9/10], Loss: 0.0146\n",
      "Epoch [9/10], Loss: 0.0156\n",
      "Epoch [9/10], Loss: 0.0161\n",
      "Epoch [9/10], Valid Accuracy: 97.9800, Valid Loss: 0.0849\n",
      "Epoch [10/10], Loss: 0.0141\n",
      "Epoch [10/10], Loss: 0.0164\n",
      "Epoch [10/10], Loss: 0.0141\n",
      "Epoch [10/10], Loss: 0.0142\n",
      "Epoch [10/10], Loss: 0.0138\n",
      "Epoch [10/10], Loss: 0.0148\n",
      "Epoch [10/10], Loss: 0.0149\n",
      "Epoch [10/10], Loss: 0.0151\n",
      "Epoch [10/10], Loss: 0.0153\n",
      "Epoch [10/10], Loss: 0.0155\n",
      "Epoch [10/10], Valid Accuracy: 98.0500, Valid Loss: 0.0809\n",
      "Epoch [1/10], Loss: 1.3998\n",
      "Epoch [1/10], Loss: 1.0074\n",
      "Epoch [1/10], Loss: 0.8257\n",
      "Epoch [1/10], Loss: 0.7198\n",
      "Epoch [1/10], Loss: 0.6473\n",
      "Epoch [1/10], Loss: 0.5973\n",
      "Epoch [1/10], Loss: 0.5569\n",
      "Epoch [1/10], Loss: 0.5251\n",
      "Epoch [1/10], Loss: 0.4990\n",
      "Epoch [1/10], Loss: 0.4911\n",
      "Epoch [1/10], Valid Accuracy: 92.4900, Valid Loss: 0.2662\n",
      "Epoch [2/10], Loss: 0.2684\n",
      "Epoch [2/10], Loss: 0.2579\n",
      "Epoch [2/10], Loss: 0.2575\n",
      "Epoch [2/10], Loss: 0.2555\n",
      "Epoch [2/10], Loss: 0.2507\n",
      "Epoch [2/10], Loss: 0.2452\n",
      "Epoch [2/10], Loss: 0.2462\n",
      "Epoch [2/10], Loss: 0.2428\n",
      "Epoch [2/10], Loss: 0.2392\n",
      "Epoch [2/10], Loss: 0.2389\n",
      "Epoch [2/10], Valid Accuracy: 94.2200, Valid Loss: 0.2012\n",
      "Epoch [3/10], Loss: 0.1872\n",
      "Epoch [3/10], Loss: 0.1883\n",
      "Epoch [3/10], Loss: 0.1906\n",
      "Epoch [3/10], Loss: 0.1913\n",
      "Epoch [3/10], Loss: 0.1887\n",
      "Epoch [3/10], Loss: 0.1903\n",
      "Epoch [3/10], Loss: 0.1884\n",
      "Epoch [3/10], Loss: 0.1863\n",
      "Epoch [3/10], Loss: 0.1851\n",
      "Epoch [3/10], Loss: 0.1844\n",
      "Epoch [3/10], Valid Accuracy: 95.3100, Valid Loss: 0.1637\n",
      "Epoch [4/10], Loss: 0.1556\n",
      "Epoch [4/10], Loss: 0.1560\n",
      "Epoch [4/10], Loss: 0.1571\n",
      "Epoch [4/10], Loss: 0.1563\n",
      "Epoch [4/10], Loss: 0.1554\n",
      "Epoch [4/10], Loss: 0.1543\n",
      "Epoch [4/10], Loss: 0.1511\n",
      "Epoch [4/10], Loss: 0.1501\n",
      "Epoch [4/10], Loss: 0.1497\n",
      "Epoch [4/10], Loss: 0.1494\n",
      "Epoch [4/10], Valid Accuracy: 95.9100, Valid Loss: 0.1435\n",
      "Epoch [5/10], Loss: 0.1338\n",
      "Epoch [5/10], Loss: 0.1311\n",
      "Epoch [5/10], Loss: 0.1311\n",
      "Epoch [5/10], Loss: 0.1303\n",
      "Epoch [5/10], Loss: 0.1281\n",
      "Epoch [5/10], Loss: 0.1278\n",
      "Epoch [5/10], Loss: 0.1262\n",
      "Epoch [5/10], Loss: 0.1251\n",
      "Epoch [5/10], Loss: 0.1254\n",
      "Epoch [5/10], Loss: 0.1249\n",
      "Epoch [5/10], Valid Accuracy: 96.4700, Valid Loss: 0.1210\n",
      "Epoch [6/10], Loss: 0.1120\n",
      "Epoch [6/10], Loss: 0.1095\n",
      "Epoch [6/10], Loss: 0.1124\n",
      "Epoch [6/10], Loss: 0.1104\n",
      "Epoch [6/10], Loss: 0.1117\n",
      "Epoch [6/10], Loss: 0.1106\n",
      "Epoch [6/10], Loss: 0.1097\n",
      "Epoch [6/10], Loss: 0.1082\n",
      "Epoch [6/10], Loss: 0.1072\n",
      "Epoch [6/10], Loss: 0.1066\n",
      "Epoch [6/10], Valid Accuracy: 96.7400, Valid Loss: 0.1095\n",
      "Epoch [7/10], Loss: 0.0955\n",
      "Epoch [7/10], Loss: 0.0950\n",
      "Epoch [7/10], Loss: 0.0950\n",
      "Epoch [7/10], Loss: 0.0935\n",
      "Epoch [7/10], Loss: 0.0955\n",
      "Epoch [7/10], Loss: 0.0949\n",
      "Epoch [7/10], Loss: 0.0935\n",
      "Epoch [7/10], Loss: 0.0933\n",
      "Epoch [7/10], Loss: 0.0924\n",
      "Epoch [7/10], Loss: 0.0919\n",
      "Epoch [7/10], Valid Accuracy: 97.1800, Valid Loss: 0.0994\n",
      "Epoch [8/10], Loss: 0.0878\n",
      "Epoch [8/10], Loss: 0.0877\n",
      "Epoch [8/10], Loss: 0.0836\n",
      "Epoch [8/10], Loss: 0.0840\n",
      "Epoch [8/10], Loss: 0.0821\n",
      "Epoch [8/10], Loss: 0.0817\n",
      "Epoch [8/10], Loss: 0.0809\n",
      "Epoch [8/10], Loss: 0.0809\n",
      "Epoch [8/10], Loss: 0.0811\n",
      "Epoch [8/10], Loss: 0.0805\n",
      "Epoch [8/10], Valid Accuracy: 97.3300, Valid Loss: 0.0903\n",
      "Epoch [9/10], Loss: 0.0744\n",
      "Epoch [9/10], Loss: 0.0707\n",
      "Epoch [9/10], Loss: 0.0713\n",
      "Epoch [9/10], Loss: 0.0711\n",
      "Epoch [9/10], Loss: 0.0705\n",
      "Epoch [9/10], Loss: 0.0696\n",
      "Epoch [9/10], Loss: 0.0700\n",
      "Epoch [9/10], Loss: 0.0699\n",
      "Epoch [9/10], Loss: 0.0710\n",
      "Epoch [9/10], Loss: 0.0707\n",
      "Epoch [9/10], Valid Accuracy: 97.5100, Valid Loss: 0.0869\n",
      "Epoch [10/10], Loss: 0.0667\n",
      "Epoch [10/10], Loss: 0.0653\n",
      "Epoch [10/10], Loss: 0.0621\n",
      "Epoch [10/10], Loss: 0.0613\n",
      "Epoch [10/10], Loss: 0.0618\n",
      "Epoch [10/10], Loss: 0.0615\n",
      "Epoch [10/10], Loss: 0.0619\n",
      "Epoch [10/10], Loss: 0.0626\n",
      "Epoch [10/10], Loss: 0.0630\n",
      "Epoch [10/10], Loss: 0.0629\n",
      "Epoch [10/10], Valid Accuracy: 97.6200, Valid Loss: 0.0795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.1694\n",
      "Epoch [1/10], Loss: 2.0579\n",
      "Epoch [1/10], Loss: 1.9499\n",
      "Epoch [1/10], Loss: 1.8397\n",
      "Epoch [1/10], Loss: 1.7378\n",
      "Epoch [1/10], Loss: 1.6444\n",
      "Epoch [1/10], Loss: 1.5597\n",
      "Epoch [1/10], Loss: 1.4874\n",
      "Epoch [1/10], Loss: 1.4202\n",
      "Epoch [1/10], Loss: 1.3966\n",
      "Epoch [1/10], Valid Accuracy: 84.4400, Valid Loss: 0.7997\n",
      "Epoch [2/10], Loss: 0.7852\n",
      "Epoch [2/10], Loss: 0.7646\n",
      "Epoch [2/10], Loss: 0.7414\n",
      "Epoch [2/10], Loss: 0.7197\n",
      "Epoch [2/10], Loss: 0.6997\n",
      "Epoch [2/10], Loss: 0.6847\n",
      "Epoch [2/10], Loss: 0.6694\n",
      "Epoch [2/10], Loss: 0.6544\n",
      "Epoch [2/10], Loss: 0.6417\n",
      "Epoch [2/10], Loss: 0.6373\n",
      "Epoch [2/10], Valid Accuracy: 88.5300, Valid Loss: 0.5006\n",
      "Epoch [3/10], Loss: 0.5115\n",
      "Epoch [3/10], Loss: 0.5016\n",
      "Epoch [3/10], Loss: 0.4976\n",
      "Epoch [3/10], Loss: 0.4925\n",
      "Epoch [3/10], Loss: 0.4858\n",
      "Epoch [3/10], Loss: 0.4792\n",
      "Epoch [3/10], Loss: 0.4733\n",
      "Epoch [3/10], Loss: 0.4681\n",
      "Epoch [3/10], Loss: 0.4637\n",
      "Epoch [3/10], Loss: 0.4623\n",
      "Epoch [3/10], Valid Accuracy: 89.9000, Valid Loss: 0.4032\n",
      "Epoch [4/10], Loss: 0.4098\n",
      "Epoch [4/10], Loss: 0.4116\n",
      "Epoch [4/10], Loss: 0.4050\n",
      "Epoch [4/10], Loss: 0.4019\n",
      "Epoch [4/10], Loss: 0.4013\n",
      "Epoch [4/10], Loss: 0.3989\n",
      "Epoch [4/10], Loss: 0.3949\n",
      "Epoch [4/10], Loss: 0.3943\n",
      "Epoch [4/10], Loss: 0.3926\n",
      "Epoch [4/10], Loss: 0.3918\n",
      "Epoch [4/10], Valid Accuracy: 90.7800, Valid Loss: 0.3548\n",
      "Epoch [5/10], Loss: 0.3682\n",
      "Epoch [5/10], Loss: 0.3662\n",
      "Epoch [5/10], Loss: 0.3630\n",
      "Epoch [5/10], Loss: 0.3650\n",
      "Epoch [5/10], Loss: 0.3591\n",
      "Epoch [5/10], Loss: 0.3569\n",
      "Epoch [5/10], Loss: 0.3550\n",
      "Epoch [5/10], Loss: 0.3534\n",
      "Epoch [5/10], Loss: 0.3536\n",
      "Epoch [5/10], Loss: 0.3525\n",
      "Epoch [5/10], Valid Accuracy: 91.2600, Valid Loss: 0.3253\n",
      "Epoch [6/10], Loss: 0.3350\n",
      "Epoch [6/10], Loss: 0.3371\n",
      "Epoch [6/10], Loss: 0.3355\n",
      "Epoch [6/10], Loss: 0.3303\n",
      "Epoch [6/10], Loss: 0.3300\n",
      "Epoch [6/10], Loss: 0.3288\n",
      "Epoch [6/10], Loss: 0.3254\n",
      "Epoch [6/10], Loss: 0.3262\n",
      "Epoch [6/10], Loss: 0.3270\n",
      "Epoch [6/10], Loss: 0.3264\n",
      "Epoch [6/10], Valid Accuracy: 91.8400, Valid Loss: 0.3045\n",
      "Epoch [7/10], Loss: 0.3093\n",
      "Epoch [7/10], Loss: 0.3127\n",
      "Epoch [7/10], Loss: 0.3173\n",
      "Epoch [7/10], Loss: 0.3167\n",
      "Epoch [7/10], Loss: 0.3130\n",
      "Epoch [7/10], Loss: 0.3132\n",
      "Epoch [7/10], Loss: 0.3117\n",
      "Epoch [7/10], Loss: 0.3103\n",
      "Epoch [7/10], Loss: 0.3086\n",
      "Epoch [7/10], Loss: 0.3072\n",
      "Epoch [7/10], Valid Accuracy: 92.0700, Valid Loss: 0.2888\n",
      "Epoch [8/10], Loss: 0.3111\n",
      "Epoch [8/10], Loss: 0.3024\n",
      "Epoch [8/10], Loss: 0.2995\n",
      "Epoch [8/10], Loss: 0.2985\n",
      "Epoch [8/10], Loss: 0.2977\n",
      "Epoch [8/10], Loss: 0.2970\n",
      "Epoch [8/10], Loss: 0.2968\n",
      "Epoch [8/10], Loss: 0.2953\n",
      "Epoch [8/10], Loss: 0.2935\n",
      "Epoch [8/10], Loss: 0.2917\n",
      "Epoch [8/10], Valid Accuracy: 92.2800, Valid Loss: 0.2761\n",
      "Epoch [9/10], Loss: 0.2733\n",
      "Epoch [9/10], Loss: 0.2812\n",
      "Epoch [9/10], Loss: 0.2780\n",
      "Epoch [9/10], Loss: 0.2782\n",
      "Epoch [9/10], Loss: 0.2796\n",
      "Epoch [9/10], Loss: 0.2808\n",
      "Epoch [9/10], Loss: 0.2803\n",
      "Epoch [9/10], Loss: 0.2803\n",
      "Epoch [9/10], Loss: 0.2790\n",
      "Epoch [9/10], Loss: 0.2787\n",
      "Epoch [9/10], Valid Accuracy: 92.6100, Valid Loss: 0.2652\n",
      "Epoch [10/10], Loss: 0.2867\n",
      "Epoch [10/10], Loss: 0.2758\n",
      "Epoch [10/10], Loss: 0.2718\n",
      "Epoch [10/10], Loss: 0.2712\n",
      "Epoch [10/10], Loss: 0.2720\n",
      "Epoch [10/10], Loss: 0.2687\n",
      "Epoch [10/10], Loss: 0.2688\n",
      "Epoch [10/10], Loss: 0.2679\n",
      "Epoch [10/10], Loss: 0.2675\n",
      "Epoch [10/10], Loss: 0.2675\n",
      "Epoch [10/10], Valid Accuracy: 92.7300, Valid Loss: 0.2554\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [1., 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "lst_val_acc = []\n",
    "lst_val_loss = []\n",
    "lst_train_loss = []\n",
    "for l_r in learning_rate:\n",
    "    net = get_model()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=l_r)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, num_epochs=10, model=net, optimizer=optimizer)\n",
    "    lst_val_acc.append(val_acc)\n",
    "    lst_val_loss.append(val_loss)\n",
    "    lst_train_loss.append(train_loss)           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>10.39</td>\n",
       "      <td>2.474983</td>\n",
       "      <td>2.373883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>9.85</td>\n",
       "      <td>2.305760</td>\n",
       "      <td>2.267042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>95.35</td>\n",
       "      <td>0.287612</td>\n",
       "      <td>0.154881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>98.05</td>\n",
       "      <td>0.080931</td>\n",
       "      <td>0.015496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>97.62</td>\n",
       "      <td>0.079462</td>\n",
       "      <td>0.062864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>92.73</td>\n",
       "      <td>0.255433</td>\n",
       "      <td>0.267469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate  Validation Accuracy  Validation Loss  Training Loss\n",
       "0        1.00000                10.39         2.474983       2.373883\n",
       "1        0.10000                 9.85         2.305760       2.267042\n",
       "2        0.01000                95.35         0.287612       0.154881\n",
       "3        0.00100                98.05         0.080931       0.015496\n",
       "4        0.00010                97.62         0.079462       0.062864\n",
       "5        0.00001                92.73         0.255433       0.267469"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'Learning Rate': learning_rate,\n",
    "        'Validation Accuracy': lst_val_acc,\n",
    "        'Validation Loss': lst_val_loss,\n",
    "        'Training Loss': lst_train_loss\n",
    "    },\n",
    "    columns = ['Learning Rate', 'Validation Accuracy','Validation Loss', 'Training Loss']\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Fining tuning with Interpolation between 0.0001 and 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.0179\n",
      "Epoch [1/10], Loss: 0.7316\n",
      "Epoch [1/10], Loss: 0.6070\n",
      "Epoch [1/10], Loss: 0.5340\n",
      "Epoch [1/10], Loss: 0.4872\n",
      "Epoch [1/10], Loss: 0.4488\n",
      "Epoch [1/10], Loss: 0.4208\n",
      "Epoch [1/10], Loss: 0.3975\n",
      "Epoch [1/10], Loss: 0.3796\n",
      "Epoch [1/10], Loss: 0.3734\n",
      "Epoch [1/10], Valid Accuracy: 94.1500, Valid Loss: 0.2042\n",
      "Epoch [2/10], Loss: 0.1958\n",
      "Epoch [2/10], Loss: 0.2040\n",
      "Epoch [2/10], Loss: 0.1988\n",
      "Epoch [2/10], Loss: 0.1931\n",
      "Epoch [2/10], Loss: 0.1895\n",
      "Epoch [2/10], Loss: 0.1841\n",
      "Epoch [2/10], Loss: 0.1818\n",
      "Epoch [2/10], Loss: 0.1796\n",
      "Epoch [2/10], Loss: 0.1770\n",
      "Epoch [2/10], Loss: 0.1761\n",
      "Epoch [2/10], Valid Accuracy: 95.8600, Valid Loss: 0.1421\n",
      "Epoch [3/10], Loss: 0.1341\n",
      "Epoch [3/10], Loss: 0.1325\n",
      "Epoch [3/10], Loss: 0.1303\n",
      "Epoch [3/10], Loss: 0.1305\n",
      "Epoch [3/10], Loss: 0.1298\n",
      "Epoch [3/10], Loss: 0.1281\n",
      "Epoch [3/10], Loss: 0.1269\n",
      "Epoch [3/10], Loss: 0.1246\n",
      "Epoch [3/10], Loss: 0.1239\n",
      "Epoch [3/10], Loss: 0.1237\n",
      "Epoch [3/10], Valid Accuracy: 96.7600, Valid Loss: 0.1113\n",
      "Epoch [4/10], Loss: 0.1067\n",
      "Epoch [4/10], Loss: 0.1039\n",
      "Epoch [4/10], Loss: 0.1011\n",
      "Epoch [4/10], Loss: 0.0993\n",
      "Epoch [4/10], Loss: 0.0972\n",
      "Epoch [4/10], Loss: 0.0962\n",
      "Epoch [4/10], Loss: 0.0964\n",
      "Epoch [4/10], Loss: 0.0959\n",
      "Epoch [4/10], Loss: 0.0958\n",
      "Epoch [4/10], Loss: 0.0950\n",
      "Epoch [4/10], Valid Accuracy: 97.1800, Valid Loss: 0.0929\n",
      "Epoch [5/10], Loss: 0.0800\n",
      "Epoch [5/10], Loss: 0.0756\n",
      "Epoch [5/10], Loss: 0.0750\n",
      "Epoch [5/10], Loss: 0.0757\n",
      "Epoch [5/10], Loss: 0.0767\n",
      "Epoch [5/10], Loss: 0.0760\n",
      "Epoch [5/10], Loss: 0.0758\n",
      "Epoch [5/10], Loss: 0.0756\n",
      "Epoch [5/10], Loss: 0.0757\n",
      "Epoch [5/10], Loss: 0.0756\n",
      "Epoch [5/10], Valid Accuracy: 97.3500, Valid Loss: 0.0851\n",
      "Epoch [6/10], Loss: 0.0620\n",
      "Epoch [6/10], Loss: 0.0596\n",
      "Epoch [6/10], Loss: 0.0591\n",
      "Epoch [6/10], Loss: 0.0629\n",
      "Epoch [6/10], Loss: 0.0620\n",
      "Epoch [6/10], Loss: 0.0614\n",
      "Epoch [6/10], Loss: 0.0608\n",
      "Epoch [6/10], Loss: 0.0607\n",
      "Epoch [6/10], Loss: 0.0616\n",
      "Epoch [6/10], Loss: 0.0616\n",
      "Epoch [6/10], Valid Accuracy: 97.5500, Valid Loss: 0.0789\n",
      "Epoch [7/10], Loss: 0.0510\n",
      "Epoch [7/10], Loss: 0.0486\n",
      "Epoch [7/10], Loss: 0.0496\n",
      "Epoch [7/10], Loss: 0.0510\n",
      "Epoch [7/10], Loss: 0.0518\n",
      "Epoch [7/10], Loss: 0.0508\n",
      "Epoch [7/10], Loss: 0.0499\n",
      "Epoch [7/10], Loss: 0.0502\n",
      "Epoch [7/10], Loss: 0.0510\n",
      "Epoch [7/10], Loss: 0.0514\n",
      "Epoch [7/10], Valid Accuracy: 97.6600, Valid Loss: 0.0742\n",
      "Epoch [8/10], Loss: 0.0418\n",
      "Epoch [8/10], Loss: 0.0414\n",
      "Epoch [8/10], Loss: 0.0417\n",
      "Epoch [8/10], Loss: 0.0411\n",
      "Epoch [8/10], Loss: 0.0424\n",
      "Epoch [8/10], Loss: 0.0424\n",
      "Epoch [8/10], Loss: 0.0422\n",
      "Epoch [8/10], Loss: 0.0424\n",
      "Epoch [8/10], Loss: 0.0427\n",
      "Epoch [8/10], Loss: 0.0425\n",
      "Epoch [8/10], Valid Accuracy: 97.6800, Valid Loss: 0.0716\n",
      "Epoch [9/10], Loss: 0.0347\n",
      "Epoch [9/10], Loss: 0.0321\n",
      "Epoch [9/10], Loss: 0.0337\n",
      "Epoch [9/10], Loss: 0.0332\n",
      "Epoch [9/10], Loss: 0.0346\n",
      "Epoch [9/10], Loss: 0.0343\n",
      "Epoch [9/10], Loss: 0.0344\n",
      "Epoch [9/10], Loss: 0.0347\n",
      "Epoch [9/10], Loss: 0.0355\n",
      "Epoch [9/10], Loss: 0.0357\n",
      "Epoch [9/10], Valid Accuracy: 97.7500, Valid Loss: 0.0692\n",
      "Epoch [10/10], Loss: 0.0282\n",
      "Epoch [10/10], Loss: 0.0293\n",
      "Epoch [10/10], Loss: 0.0310\n",
      "Epoch [10/10], Loss: 0.0302\n",
      "Epoch [10/10], Loss: 0.0306\n",
      "Epoch [10/10], Loss: 0.0303\n",
      "Epoch [10/10], Loss: 0.0303\n",
      "Epoch [10/10], Loss: 0.0303\n",
      "Epoch [10/10], Loss: 0.0297\n",
      "Epoch [10/10], Loss: 0.0297\n",
      "Epoch [10/10], Valid Accuracy: 97.9900, Valid Loss: 0.0630\n",
      "Epoch [1/10], Loss: 0.7492\n",
      "Epoch [1/10], Loss: 0.5514\n",
      "Epoch [1/10], Loss: 0.4705\n",
      "Epoch [1/10], Loss: 0.4177\n",
      "Epoch [1/10], Loss: 0.3799\n",
      "Epoch [1/10], Loss: 0.3530\n",
      "Epoch [1/10], Loss: 0.3300\n",
      "Epoch [1/10], Loss: 0.3118\n",
      "Epoch [1/10], Loss: 0.2961\n",
      "Epoch [1/10], Loss: 0.2920\n",
      "Epoch [1/10], Valid Accuracy: 95.5000, Valid Loss: 0.1517\n",
      "Epoch [2/10], Loss: 0.1476\n",
      "Epoch [2/10], Loss: 0.1385\n",
      "Epoch [2/10], Loss: 0.1393\n",
      "Epoch [2/10], Loss: 0.1392\n",
      "Epoch [2/10], Loss: 0.1345\n",
      "Epoch [2/10], Loss: 0.1301\n",
      "Epoch [2/10], Loss: 0.1289\n",
      "Epoch [2/10], Loss: 0.1270\n",
      "Epoch [2/10], Loss: 0.1259\n",
      "Epoch [2/10], Loss: 0.1249\n",
      "Epoch [2/10], Valid Accuracy: 96.9500, Valid Loss: 0.1047\n",
      "Epoch [3/10], Loss: 0.0913\n",
      "Epoch [3/10], Loss: 0.0892\n",
      "Epoch [3/10], Loss: 0.0878\n",
      "Epoch [3/10], Loss: 0.0852\n",
      "Epoch [3/10], Loss: 0.0854\n",
      "Epoch [3/10], Loss: 0.0840\n",
      "Epoch [3/10], Loss: 0.0844\n",
      "Epoch [3/10], Loss: 0.0842\n",
      "Epoch [3/10], Loss: 0.0837\n",
      "Epoch [3/10], Loss: 0.0833\n",
      "Epoch [3/10], Valid Accuracy: 97.4600, Valid Loss: 0.0879\n",
      "Epoch [4/10], Loss: 0.0548\n",
      "Epoch [4/10], Loss: 0.0563\n",
      "Epoch [4/10], Loss: 0.0584\n",
      "Epoch [4/10], Loss: 0.0576\n",
      "Epoch [4/10], Loss: 0.0613\n",
      "Epoch [4/10], Loss: 0.0618\n",
      "Epoch [4/10], Loss: 0.0617\n",
      "Epoch [4/10], Loss: 0.0610\n",
      "Epoch [4/10], Loss: 0.0608\n",
      "Epoch [4/10], Loss: 0.0609\n",
      "Epoch [4/10], Valid Accuracy: 97.7100, Valid Loss: 0.0766\n",
      "Epoch [5/10], Loss: 0.0441\n",
      "Epoch [5/10], Loss: 0.0444\n",
      "Epoch [5/10], Loss: 0.0468\n",
      "Epoch [5/10], Loss: 0.0461\n",
      "Epoch [5/10], Loss: 0.0451\n",
      "Epoch [5/10], Loss: 0.0458\n",
      "Epoch [5/10], Loss: 0.0461\n",
      "Epoch [5/10], Loss: 0.0460\n",
      "Epoch [5/10], Loss: 0.0462\n",
      "Epoch [5/10], Loss: 0.0466\n",
      "Epoch [5/10], Valid Accuracy: 98.0100, Valid Loss: 0.0685\n",
      "Epoch [6/10], Loss: 0.0313\n",
      "Epoch [6/10], Loss: 0.0318\n",
      "Epoch [6/10], Loss: 0.0321\n",
      "Epoch [6/10], Loss: 0.0341\n",
      "Epoch [6/10], Loss: 0.0357\n",
      "Epoch [6/10], Loss: 0.0346\n",
      "Epoch [6/10], Loss: 0.0349\n",
      "Epoch [6/10], Loss: 0.0347\n",
      "Epoch [6/10], Loss: 0.0351\n",
      "Epoch [6/10], Loss: 0.0351\n",
      "Epoch [6/10], Valid Accuracy: 97.9500, Valid Loss: 0.0649\n",
      "Epoch [7/10], Loss: 0.0242\n",
      "Epoch [7/10], Loss: 0.0234\n",
      "Epoch [7/10], Loss: 0.0244\n",
      "Epoch [7/10], Loss: 0.0253\n",
      "Epoch [7/10], Loss: 0.0267\n",
      "Epoch [7/10], Loss: 0.0277\n",
      "Epoch [7/10], Loss: 0.0271\n",
      "Epoch [7/10], Loss: 0.0265\n",
      "Epoch [7/10], Loss: 0.0271\n",
      "Epoch [7/10], Loss: 0.0275\n",
      "Epoch [7/10], Valid Accuracy: 97.8100, Valid Loss: 0.0707\n",
      "Epoch [8/10], Loss: 0.0191\n",
      "Epoch [8/10], Loss: 0.0195\n",
      "Epoch [8/10], Loss: 0.0191\n",
      "Epoch [8/10], Loss: 0.0192\n",
      "Epoch [8/10], Loss: 0.0187\n",
      "Epoch [8/10], Loss: 0.0191\n",
      "Epoch [8/10], Loss: 0.0195\n",
      "Epoch [8/10], Loss: 0.0205\n",
      "Epoch [8/10], Loss: 0.0222\n",
      "Epoch [8/10], Loss: 0.0224\n",
      "Epoch [8/10], Valid Accuracy: 98.1000, Valid Loss: 0.0646\n",
      "Epoch [9/10], Loss: 0.0179\n",
      "Epoch [9/10], Loss: 0.0170\n",
      "Epoch [9/10], Loss: 0.0157\n",
      "Epoch [9/10], Loss: 0.0158\n",
      "Epoch [9/10], Loss: 0.0163\n",
      "Epoch [9/10], Loss: 0.0163\n",
      "Epoch [9/10], Loss: 0.0164\n",
      "Epoch [9/10], Loss: 0.0169\n",
      "Epoch [9/10], Loss: 0.0173\n",
      "Epoch [9/10], Loss: 0.0174\n",
      "Epoch [9/10], Valid Accuracy: 98.0200, Valid Loss: 0.0682\n",
      "Epoch [10/10], Loss: 0.0126\n",
      "Epoch [10/10], Loss: 0.0114\n",
      "Epoch [10/10], Loss: 0.0121\n",
      "Epoch [10/10], Loss: 0.0118\n",
      "Epoch [10/10], Loss: 0.0122\n",
      "Epoch [10/10], Loss: 0.0128\n",
      "Epoch [10/10], Loss: 0.0130\n",
      "Epoch [10/10], Loss: 0.0132\n",
      "Epoch [10/10], Loss: 0.0133\n",
      "Epoch [10/10], Loss: 0.0139\n",
      "Epoch [10/10], Valid Accuracy: 97.4600, Valid Loss: 0.0825\n",
      "Epoch [1/10], Loss: 0.6511\n",
      "Epoch [1/10], Loss: 0.4766\n",
      "Epoch [1/10], Loss: 0.4084\n",
      "Epoch [1/10], Loss: 0.3634\n",
      "Epoch [1/10], Loss: 0.3300\n",
      "Epoch [1/10], Loss: 0.3069\n",
      "Epoch [1/10], Loss: 0.2875\n",
      "Epoch [1/10], Loss: 0.2722\n",
      "Epoch [1/10], Loss: 0.2608\n",
      "Epoch [1/10], Loss: 0.2552\n",
      "Epoch [1/10], Valid Accuracy: 95.9500, Valid Loss: 0.1301\n",
      "Epoch [2/10], Loss: 0.1203\n",
      "Epoch [2/10], Loss: 0.1166\n",
      "Epoch [2/10], Loss: 0.1170\n",
      "Epoch [2/10], Loss: 0.1121\n",
      "Epoch [2/10], Loss: 0.1086\n",
      "Epoch [2/10], Loss: 0.1091\n",
      "Epoch [2/10], Loss: 0.1088\n",
      "Epoch [2/10], Loss: 0.1075\n",
      "Epoch [2/10], Loss: 0.1054\n",
      "Epoch [2/10], Loss: 0.1049\n",
      "Epoch [2/10], Valid Accuracy: 97.2500, Valid Loss: 0.0940\n",
      "Epoch [3/10], Loss: 0.0760\n",
      "Epoch [3/10], Loss: 0.0724\n",
      "Epoch [3/10], Loss: 0.0715\n",
      "Epoch [3/10], Loss: 0.0723\n",
      "Epoch [3/10], Loss: 0.0720\n",
      "Epoch [3/10], Loss: 0.0709\n",
      "Epoch [3/10], Loss: 0.0721\n",
      "Epoch [3/10], Loss: 0.0717\n",
      "Epoch [3/10], Loss: 0.0709\n",
      "Epoch [3/10], Loss: 0.0703\n",
      "Epoch [3/10], Valid Accuracy: 97.6700, Valid Loss: 0.0770\n",
      "Epoch [4/10], Loss: 0.0454\n",
      "Epoch [4/10], Loss: 0.0456\n",
      "Epoch [4/10], Loss: 0.0465\n",
      "Epoch [4/10], Loss: 0.0476\n",
      "Epoch [4/10], Loss: 0.0487\n",
      "Epoch [4/10], Loss: 0.0498\n",
      "Epoch [4/10], Loss: 0.0497\n",
      "Epoch [4/10], Loss: 0.0501\n",
      "Epoch [4/10], Loss: 0.0506\n",
      "Epoch [4/10], Loss: 0.0506\n",
      "Epoch [4/10], Valid Accuracy: 97.4400, Valid Loss: 0.0821\n",
      "Epoch [5/10], Loss: 0.0343\n",
      "Epoch [5/10], Loss: 0.0333\n",
      "Epoch [5/10], Loss: 0.0352\n",
      "Epoch [5/10], Loss: 0.0354\n",
      "Epoch [5/10], Loss: 0.0356\n",
      "Epoch [5/10], Loss: 0.0361\n",
      "Epoch [5/10], Loss: 0.0366\n",
      "Epoch [5/10], Loss: 0.0372\n",
      "Epoch [5/10], Loss: 0.0378\n",
      "Epoch [5/10], Loss: 0.0381\n",
      "Epoch [5/10], Valid Accuracy: 97.8400, Valid Loss: 0.0714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.0238\n",
      "Epoch [6/10], Loss: 0.0237\n",
      "Epoch [6/10], Loss: 0.0248\n",
      "Epoch [6/10], Loss: 0.0248\n",
      "Epoch [6/10], Loss: 0.0267\n",
      "Epoch [6/10], Loss: 0.0274\n",
      "Epoch [6/10], Loss: 0.0276\n",
      "Epoch [6/10], Loss: 0.0285\n",
      "Epoch [6/10], Loss: 0.0292\n",
      "Epoch [6/10], Loss: 0.0292\n",
      "Epoch [6/10], Valid Accuracy: 97.9700, Valid Loss: 0.0648\n",
      "Epoch [7/10], Loss: 0.0201\n",
      "Epoch [7/10], Loss: 0.0201\n",
      "Epoch [7/10], Loss: 0.0206\n",
      "Epoch [7/10], Loss: 0.0204\n",
      "Epoch [7/10], Loss: 0.0210\n",
      "Epoch [7/10], Loss: 0.0213\n",
      "Epoch [7/10], Loss: 0.0215\n",
      "Epoch [7/10], Loss: 0.0216\n",
      "Epoch [7/10], Loss: 0.0221\n",
      "Epoch [7/10], Loss: 0.0224\n",
      "Epoch [7/10], Valid Accuracy: 98.0200, Valid Loss: 0.0706\n",
      "Epoch [8/10], Loss: 0.0144\n",
      "Epoch [8/10], Loss: 0.0153\n",
      "Epoch [8/10], Loss: 0.0165\n",
      "Epoch [8/10], Loss: 0.0170\n",
      "Epoch [8/10], Loss: 0.0180\n",
      "Epoch [8/10], Loss: 0.0179\n",
      "Epoch [8/10], Loss: 0.0181\n",
      "Epoch [8/10], Loss: 0.0185\n",
      "Epoch [8/10], Loss: 0.0188\n",
      "Epoch [8/10], Loss: 0.0188\n",
      "Epoch [8/10], Valid Accuracy: 98.0000, Valid Loss: 0.0664\n",
      "Epoch [9/10], Loss: 0.0177\n",
      "Epoch [9/10], Loss: 0.0141\n",
      "Epoch [9/10], Loss: 0.0141\n",
      "Epoch [9/10], Loss: 0.0137\n",
      "Epoch [9/10], Loss: 0.0138\n",
      "Epoch [9/10], Loss: 0.0142\n",
      "Epoch [9/10], Loss: 0.0147\n",
      "Epoch [9/10], Loss: 0.0154\n",
      "Epoch [9/10], Loss: 0.0159\n",
      "Epoch [9/10], Loss: 0.0160\n",
      "Epoch [9/10], Valid Accuracy: 97.6500, Valid Loss: 0.0798\n",
      "Epoch [10/10], Loss: 0.0124\n",
      "Epoch [10/10], Loss: 0.0128\n",
      "Epoch [10/10], Loss: 0.0122\n",
      "Epoch [10/10], Loss: 0.0119\n",
      "Epoch [10/10], Loss: 0.0113\n",
      "Epoch [10/10], Loss: 0.0108\n",
      "Epoch [10/10], Loss: 0.0109\n",
      "Epoch [10/10], Loss: 0.0118\n",
      "Epoch [10/10], Loss: 0.0125\n",
      "Epoch [10/10], Loss: 0.0125\n",
      "Epoch [10/10], Valid Accuracy: 97.8500, Valid Loss: 0.0796\n",
      "Epoch [1/10], Loss: 0.6074\n",
      "Epoch [1/10], Loss: 0.4466\n",
      "Epoch [1/10], Loss: 0.3825\n",
      "Epoch [1/10], Loss: 0.3408\n",
      "Epoch [1/10], Loss: 0.3113\n",
      "Epoch [1/10], Loss: 0.2879\n",
      "Epoch [1/10], Loss: 0.2676\n",
      "Epoch [1/10], Loss: 0.2524\n",
      "Epoch [1/10], Loss: 0.2408\n",
      "Epoch [1/10], Loss: 0.2370\n",
      "Epoch [1/10], Valid Accuracy: 96.5000, Valid Loss: 0.1148\n",
      "Epoch [2/10], Loss: 0.1036\n",
      "Epoch [2/10], Loss: 0.1010\n",
      "Epoch [2/10], Loss: 0.1022\n",
      "Epoch [2/10], Loss: 0.1035\n",
      "Epoch [2/10], Loss: 0.1001\n",
      "Epoch [2/10], Loss: 0.0988\n",
      "Epoch [2/10], Loss: 0.0973\n",
      "Epoch [2/10], Loss: 0.0960\n",
      "Epoch [2/10], Loss: 0.0948\n",
      "Epoch [2/10], Loss: 0.0941\n",
      "Epoch [2/10], Valid Accuracy: 97.4300, Valid Loss: 0.0801\n",
      "Epoch [3/10], Loss: 0.0573\n",
      "Epoch [3/10], Loss: 0.0595\n",
      "Epoch [3/10], Loss: 0.0622\n",
      "Epoch [3/10], Loss: 0.0641\n",
      "Epoch [3/10], Loss: 0.0644\n",
      "Epoch [3/10], Loss: 0.0643\n",
      "Epoch [3/10], Loss: 0.0637\n",
      "Epoch [3/10], Loss: 0.0629\n",
      "Epoch [3/10], Loss: 0.0643\n",
      "Epoch [3/10], Loss: 0.0638\n",
      "Epoch [3/10], Valid Accuracy: 97.8000, Valid Loss: 0.0761\n",
      "Epoch [4/10], Loss: 0.0390\n",
      "Epoch [4/10], Loss: 0.0425\n",
      "Epoch [4/10], Loss: 0.0434\n",
      "Epoch [4/10], Loss: 0.0436\n",
      "Epoch [4/10], Loss: 0.0429\n",
      "Epoch [4/10], Loss: 0.0437\n",
      "Epoch [4/10], Loss: 0.0453\n",
      "Epoch [4/10], Loss: 0.0453\n",
      "Epoch [4/10], Loss: 0.0457\n",
      "Epoch [4/10], Loss: 0.0461\n",
      "Epoch [4/10], Valid Accuracy: 97.8900, Valid Loss: 0.0683\n",
      "Epoch [5/10], Loss: 0.0303\n",
      "Epoch [5/10], Loss: 0.0315\n",
      "Epoch [5/10], Loss: 0.0318\n",
      "Epoch [5/10], Loss: 0.0312\n",
      "Epoch [5/10], Loss: 0.0312\n",
      "Epoch [5/10], Loss: 0.0324\n",
      "Epoch [5/10], Loss: 0.0325\n",
      "Epoch [5/10], Loss: 0.0329\n",
      "Epoch [5/10], Loss: 0.0342\n",
      "Epoch [5/10], Loss: 0.0345\n",
      "Epoch [5/10], Valid Accuracy: 97.6800, Valid Loss: 0.0746\n",
      "Epoch [6/10], Loss: 0.0251\n",
      "Epoch [6/10], Loss: 0.0223\n",
      "Epoch [6/10], Loss: 0.0234\n",
      "Epoch [6/10], Loss: 0.0255\n",
      "Epoch [6/10], Loss: 0.0254\n",
      "Epoch [6/10], Loss: 0.0255\n",
      "Epoch [6/10], Loss: 0.0257\n",
      "Epoch [6/10], Loss: 0.0268\n",
      "Epoch [6/10], Loss: 0.0269\n",
      "Epoch [6/10], Loss: 0.0271\n",
      "Epoch [6/10], Valid Accuracy: 97.9400, Valid Loss: 0.0731\n",
      "Epoch [7/10], Loss: 0.0200\n",
      "Epoch [7/10], Loss: 0.0185\n",
      "Epoch [7/10], Loss: 0.0180\n",
      "Epoch [7/10], Loss: 0.0188\n",
      "Epoch [7/10], Loss: 0.0196\n",
      "Epoch [7/10], Loss: 0.0206\n",
      "Epoch [7/10], Loss: 0.0219\n",
      "Epoch [7/10], Loss: 0.0221\n",
      "Epoch [7/10], Loss: 0.0230\n",
      "Epoch [7/10], Loss: 0.0232\n",
      "Epoch [7/10], Valid Accuracy: 97.8900, Valid Loss: 0.0784\n",
      "Epoch [8/10], Loss: 0.0165\n",
      "Epoch [8/10], Loss: 0.0166\n",
      "Epoch [8/10], Loss: 0.0162\n",
      "Epoch [8/10], Loss: 0.0171\n",
      "Epoch [8/10], Loss: 0.0164\n",
      "Epoch [8/10], Loss: 0.0169\n",
      "Epoch [8/10], Loss: 0.0164\n",
      "Epoch [8/10], Loss: 0.0170\n",
      "Epoch [8/10], Loss: 0.0177\n",
      "Epoch [8/10], Loss: 0.0186\n",
      "Epoch [8/10], Valid Accuracy: 97.7400, Valid Loss: 0.0792\n",
      "Epoch [9/10], Loss: 0.0157\n",
      "Epoch [9/10], Loss: 0.0149\n",
      "Epoch [9/10], Loss: 0.0136\n",
      "Epoch [9/10], Loss: 0.0142\n",
      "Epoch [9/10], Loss: 0.0144\n",
      "Epoch [9/10], Loss: 0.0156\n",
      "Epoch [9/10], Loss: 0.0164\n",
      "Epoch [9/10], Loss: 0.0165\n",
      "Epoch [9/10], Loss: 0.0175\n",
      "Epoch [9/10], Loss: 0.0177\n",
      "Epoch [9/10], Valid Accuracy: 97.6300, Valid Loss: 0.0878\n",
      "Epoch [10/10], Loss: 0.0143\n",
      "Epoch [10/10], Loss: 0.0116\n",
      "Epoch [10/10], Loss: 0.0107\n",
      "Epoch [10/10], Loss: 0.0101\n",
      "Epoch [10/10], Loss: 0.0100\n",
      "Epoch [10/10], Loss: 0.0106\n",
      "Epoch [10/10], Loss: 0.0109\n",
      "Epoch [10/10], Loss: 0.0113\n",
      "Epoch [10/10], Loss: 0.0120\n",
      "Epoch [10/10], Loss: 0.0123\n",
      "Epoch [10/10], Valid Accuracy: 98.0600, Valid Loss: 0.0764\n"
     ]
    }
   ],
   "source": [
    "interpolate_lr = [0.0002, 0.0004, 0.0006, 0.0008]\n",
    "lst_val_acc1 = []\n",
    "lst_val_loss1 = []\n",
    "lst_train_loss1 = []\n",
    "for l_r in interpolate_lr:\n",
    "    net = get_model()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=l_r)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, num_epochs=10, model=net, optimizer=optimizer)\n",
    "    lst_val_acc1.append(val_acc)\n",
    "    lst_val_loss1.append(val_loss)\n",
    "    lst_train_loss1.append(train_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>97.99</td>\n",
       "      <td>0.062995</td>\n",
       "      <td>0.029697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>97.46</td>\n",
       "      <td>0.082466</td>\n",
       "      <td>0.013917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0006</td>\n",
       "      <td>97.85</td>\n",
       "      <td>0.079644</td>\n",
       "      <td>0.012495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>98.06</td>\n",
       "      <td>0.076439</td>\n",
       "      <td>0.012294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate  Validation Accuracy  Validation Loss  Training Loss\n",
       "0         0.0002                97.99         0.062995       0.029697\n",
       "1         0.0004                97.46         0.082466       0.013917\n",
       "2         0.0006                97.85         0.079644       0.012495\n",
       "3         0.0008                98.06         0.076439       0.012294"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        'Learning Rate': interpolate_lr,\n",
    "        'Validation Accuracy': lst_val_acc1,\n",
    "        'Validation Loss': lst_val_loss1,\n",
    "        'Training Loss': lst_train_loss1\n",
    "    },\n",
    "    columns = ['Learning Rate', 'Validation Accuracy','Validation Loss', 'Training Loss']\n",
    ")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Loss')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLFkYY4wJypKFMcaYoCxZGGOMCer/A28F4oZaym5/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f804c778160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_lr = pd.concat([df.iloc[3:5,:],df1]).sort_values(by = 'Learning Rate')\n",
    "plt.plot(df_lr['Learning Rate'], df_lr['Training Loss'])\n",
    "plt.plot(df_lr['Learning Rate'], df_lr['Validation Loss'])\n",
    "plt.xticks(df_lr['Learning Rate'])\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='center right', bbox_to_anchor=(1.0, 0.3), ncol=1)\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When learning rate = 0.0008, the neural network has best validation accuracy 98.06%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tuning size of a hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.9243\n",
      "Epoch [1/10], Loss: 0.7119\n",
      "Epoch [1/10], Loss: 0.6370\n",
      "Epoch [1/10], Loss: 0.5926\n",
      "Epoch [1/10], Loss: 0.5646\n",
      "Epoch [1/10], Loss: 0.5412\n",
      "Epoch [1/10], Loss: 0.5237\n",
      "Epoch [1/10], Loss: 0.5081\n",
      "Epoch [1/10], Loss: 0.4962\n",
      "Epoch [1/10], Loss: 0.4922\n",
      "Epoch [1/10], Valid Accuracy: 89.2400, Valid Loss: 0.3624\n",
      "Epoch [2/10], Loss: 0.3853\n",
      "Epoch [2/10], Loss: 0.3829\n",
      "Epoch [2/10], Loss: 0.3753\n",
      "Epoch [2/10], Loss: 0.3781\n",
      "Epoch [2/10], Loss: 0.3802\n",
      "Epoch [2/10], Loss: 0.3756\n",
      "Epoch [2/10], Loss: 0.3775\n",
      "Epoch [2/10], Loss: 0.3793\n",
      "Epoch [2/10], Loss: 0.3804\n",
      "Epoch [2/10], Loss: 0.3802\n",
      "Epoch [2/10], Valid Accuracy: 88.9300, Valid Loss: 0.3645\n",
      "Epoch [3/10], Loss: 0.3603\n",
      "Epoch [3/10], Loss: 0.3571\n",
      "Epoch [3/10], Loss: 0.3563\n",
      "Epoch [3/10], Loss: 0.3555\n",
      "Epoch [3/10], Loss: 0.3611\n",
      "Epoch [3/10], Loss: 0.3628\n",
      "Epoch [3/10], Loss: 0.3654\n",
      "Epoch [3/10], Loss: 0.3655\n",
      "Epoch [3/10], Loss: 0.3664\n",
      "Epoch [3/10], Loss: 0.3676\n",
      "Epoch [3/10], Valid Accuracy: 87.4100, Valid Loss: 0.4304\n",
      "Epoch [4/10], Loss: 0.3700\n",
      "Epoch [4/10], Loss: 0.3564\n",
      "Epoch [4/10], Loss: 0.3588\n",
      "Epoch [4/10], Loss: 0.3600\n",
      "Epoch [4/10], Loss: 0.3613\n",
      "Epoch [4/10], Loss: 0.3610\n",
      "Epoch [4/10], Loss: 0.3634\n",
      "Epoch [4/10], Loss: 0.3641\n",
      "Epoch [4/10], Loss: 0.3639\n",
      "Epoch [4/10], Loss: 0.3631\n",
      "Epoch [4/10], Valid Accuracy: 89.3000, Valid Loss: 0.3816\n",
      "Epoch [5/10], Loss: 0.3619\n",
      "Epoch [5/10], Loss: 0.3584\n",
      "Epoch [5/10], Loss: 0.3569\n",
      "Epoch [5/10], Loss: 0.3625\n",
      "Epoch [5/10], Loss: 0.3627\n",
      "Epoch [5/10], Loss: 0.3624\n",
      "Epoch [5/10], Loss: 0.3600\n",
      "Epoch [5/10], Loss: 0.3631\n",
      "Epoch [5/10], Loss: 0.3632\n",
      "Epoch [5/10], Loss: 0.3622\n",
      "Epoch [5/10], Valid Accuracy: 89.9200, Valid Loss: 0.3566\n",
      "Epoch [6/10], Loss: 0.3472\n",
      "Epoch [6/10], Loss: 0.3398\n",
      "Epoch [6/10], Loss: 0.3545\n",
      "Epoch [6/10], Loss: 0.3538\n",
      "Epoch [6/10], Loss: 0.3546\n",
      "Epoch [6/10], Loss: 0.3526\n",
      "Epoch [6/10], Loss: 0.3542\n",
      "Epoch [6/10], Loss: 0.3540\n",
      "Epoch [6/10], Loss: 0.3552\n",
      "Epoch [6/10], Loss: 0.3543\n",
      "Epoch [6/10], Valid Accuracy: 89.8600, Valid Loss: 0.3530\n",
      "Epoch [7/10], Loss: 0.3447\n",
      "Epoch [7/10], Loss: 0.3541\n",
      "Epoch [7/10], Loss: 0.3435\n",
      "Epoch [7/10], Loss: 0.3492\n",
      "Epoch [7/10], Loss: 0.3496\n",
      "Epoch [7/10], Loss: 0.3495\n",
      "Epoch [7/10], Loss: 0.3527\n",
      "Epoch [7/10], Loss: 0.3522\n",
      "Epoch [7/10], Loss: 0.3511\n",
      "Epoch [7/10], Loss: 0.3509\n",
      "Epoch [7/10], Valid Accuracy: 89.0700, Valid Loss: 0.3712\n",
      "Epoch [8/10], Loss: 0.3333\n",
      "Epoch [8/10], Loss: 0.3367\n",
      "Epoch [8/10], Loss: 0.3380\n",
      "Epoch [8/10], Loss: 0.3417\n",
      "Epoch [8/10], Loss: 0.3506\n",
      "Epoch [8/10], Loss: 0.3505\n",
      "Epoch [8/10], Loss: 0.3529\n",
      "Epoch [8/10], Loss: 0.3530\n",
      "Epoch [8/10], Loss: 0.3507\n",
      "Epoch [8/10], Loss: 0.3536\n",
      "Epoch [8/10], Valid Accuracy: 88.3800, Valid Loss: 0.4046\n",
      "Epoch [9/10], Loss: 0.3656\n",
      "Epoch [9/10], Loss: 0.3639\n",
      "Epoch [9/10], Loss: 0.3579\n",
      "Epoch [9/10], Loss: 0.3517\n",
      "Epoch [9/10], Loss: 0.3510\n",
      "Epoch [9/10], Loss: 0.3499\n",
      "Epoch [9/10], Loss: 0.3499\n",
      "Epoch [9/10], Loss: 0.3502\n",
      "Epoch [9/10], Loss: 0.3522\n",
      "Epoch [9/10], Loss: 0.3531\n",
      "Epoch [9/10], Valid Accuracy: 89.6800, Valid Loss: 0.3531\n",
      "Epoch [10/10], Loss: 0.3542\n",
      "Epoch [10/10], Loss: 0.3519\n",
      "Epoch [10/10], Loss: 0.3502\n",
      "Epoch [10/10], Loss: 0.3465\n",
      "Epoch [10/10], Loss: 0.3497\n",
      "Epoch [10/10], Loss: 0.3490\n",
      "Epoch [10/10], Loss: 0.3463\n",
      "Epoch [10/10], Loss: 0.3488\n",
      "Epoch [10/10], Loss: 0.3509\n",
      "Epoch [10/10], Loss: 0.3512\n",
      "Epoch [10/10], Valid Accuracy: 89.5200, Valid Loss: 0.3610\n",
      "Epoch [1/10], Loss: 0.5236\n",
      "Epoch [1/10], Loss: 0.4300\n",
      "Epoch [1/10], Loss: 0.3747\n",
      "Epoch [1/10], Loss: 0.3405\n",
      "Epoch [1/10], Loss: 0.3243\n",
      "Epoch [1/10], Loss: 0.3110\n",
      "Epoch [1/10], Loss: 0.2972\n",
      "Epoch [1/10], Loss: 0.2858\n",
      "Epoch [1/10], Loss: 0.2812\n",
      "Epoch [1/10], Loss: 0.2809\n",
      "Epoch [1/10], Valid Accuracy: 94.5800, Valid Loss: 0.2010\n",
      "Epoch [2/10], Loss: 0.1994\n",
      "Epoch [2/10], Loss: 0.1951\n",
      "Epoch [2/10], Loss: 0.2014\n",
      "Epoch [2/10], Loss: 0.2019\n",
      "Epoch [2/10], Loss: 0.2017\n",
      "Epoch [2/10], Loss: 0.2012\n",
      "Epoch [2/10], Loss: 0.1995\n",
      "Epoch [2/10], Loss: 0.1996\n",
      "Epoch [2/10], Loss: 0.2025\n",
      "Epoch [2/10], Loss: 0.2027\n",
      "Epoch [2/10], Valid Accuracy: 94.3000, Valid Loss: 0.1911\n",
      "Epoch [3/10], Loss: 0.1781\n",
      "Epoch [3/10], Loss: 0.1920\n",
      "Epoch [3/10], Loss: 0.1954\n",
      "Epoch [3/10], Loss: 0.1896\n",
      "Epoch [3/10], Loss: 0.1901\n",
      "Epoch [3/10], Loss: 0.1962\n",
      "Epoch [3/10], Loss: 0.1911\n",
      "Epoch [3/10], Loss: 0.1918\n",
      "Epoch [3/10], Loss: 0.1886\n",
      "Epoch [3/10], Loss: 0.1890\n",
      "Epoch [3/10], Valid Accuracy: 93.9000, Valid Loss: 0.2312\n",
      "Epoch [4/10], Loss: 0.1869\n",
      "Epoch [4/10], Loss: 0.1803\n",
      "Epoch [4/10], Loss: 0.1818\n",
      "Epoch [4/10], Loss: 0.1785\n",
      "Epoch [4/10], Loss: 0.1776\n",
      "Epoch [4/10], Loss: 0.1782\n",
      "Epoch [4/10], Loss: 0.1768\n",
      "Epoch [4/10], Loss: 0.1788\n",
      "Epoch [4/10], Loss: 0.1815\n",
      "Epoch [4/10], Loss: 0.1805\n",
      "Epoch [4/10], Valid Accuracy: 94.5300, Valid Loss: 0.2118\n",
      "Epoch [5/10], Loss: 0.1550\n",
      "Epoch [5/10], Loss: 0.1577\n",
      "Epoch [5/10], Loss: 0.1616\n",
      "Epoch [5/10], Loss: 0.1657\n",
      "Epoch [5/10], Loss: 0.1678\n",
      "Epoch [5/10], Loss: 0.1688\n",
      "Epoch [5/10], Loss: 0.1698\n",
      "Epoch [5/10], Loss: 0.1735\n",
      "Epoch [5/10], Loss: 0.1777\n",
      "Epoch [5/10], Loss: 0.1779\n",
      "Epoch [5/10], Valid Accuracy: 95.0100, Valid Loss: 0.2103\n",
      "Epoch [6/10], Loss: 0.1468\n",
      "Epoch [6/10], Loss: 0.1589\n",
      "Epoch [6/10], Loss: 0.1628\n",
      "Epoch [6/10], Loss: 0.1663\n",
      "Epoch [6/10], Loss: 0.1702\n",
      "Epoch [6/10], Loss: 0.1666\n",
      "Epoch [6/10], Loss: 0.1679\n",
      "Epoch [6/10], Loss: 0.1676\n",
      "Epoch [6/10], Loss: 0.1699\n",
      "Epoch [6/10], Loss: 0.1699\n",
      "Epoch [6/10], Valid Accuracy: 95.5300, Valid Loss: 0.2126\n",
      "Epoch [7/10], Loss: 0.1524\n",
      "Epoch [7/10], Loss: 0.1392\n",
      "Epoch [7/10], Loss: 0.1420\n",
      "Epoch [7/10], Loss: 0.1536\n",
      "Epoch [7/10], Loss: 0.1533\n",
      "Epoch [7/10], Loss: 0.1552\n",
      "Epoch [7/10], Loss: 0.1622\n",
      "Epoch [7/10], Loss: 0.1663\n",
      "Epoch [7/10], Loss: 0.1689\n",
      "Epoch [7/10], Loss: 0.1683\n",
      "Epoch [7/10], Valid Accuracy: 95.3400, Valid Loss: 0.2194\n",
      "Epoch [8/10], Loss: 0.1457\n",
      "Epoch [8/10], Loss: 0.1523\n",
      "Epoch [8/10], Loss: 0.1560\n",
      "Epoch [8/10], Loss: 0.1510\n",
      "Epoch [8/10], Loss: 0.1505\n",
      "Epoch [8/10], Loss: 0.1531\n",
      "Epoch [8/10], Loss: 0.1548\n",
      "Epoch [8/10], Loss: 0.1572\n",
      "Epoch [8/10], Loss: 0.1575\n",
      "Epoch [8/10], Loss: 0.1562\n",
      "Epoch [8/10], Valid Accuracy: 95.2200, Valid Loss: 0.2045\n",
      "Epoch [9/10], Loss: 0.1561\n",
      "Epoch [9/10], Loss: 0.1438\n",
      "Epoch [9/10], Loss: 0.1418\n",
      "Epoch [9/10], Loss: 0.1431\n",
      "Epoch [9/10], Loss: 0.1434\n",
      "Epoch [9/10], Loss: 0.1481\n",
      "Epoch [9/10], Loss: 0.1529\n",
      "Epoch [9/10], Loss: 0.1520\n",
      "Epoch [9/10], Loss: 0.1537\n",
      "Epoch [9/10], Loss: 0.1541\n",
      "Epoch [9/10], Valid Accuracy: 95.2000, Valid Loss: 0.2335\n",
      "Epoch [10/10], Loss: 0.1403\n",
      "Epoch [10/10], Loss: 0.1484\n",
      "Epoch [10/10], Loss: 0.1463\n",
      "Epoch [10/10], Loss: 0.1502\n",
      "Epoch [10/10], Loss: 0.1576\n",
      "Epoch [10/10], Loss: 0.1558\n",
      "Epoch [10/10], Loss: 0.1570\n",
      "Epoch [10/10], Loss: 0.1557\n",
      "Epoch [10/10], Loss: 0.1570\n",
      "Epoch [10/10], Loss: 0.1575\n",
      "Epoch [10/10], Valid Accuracy: 94.6600, Valid Loss: 0.2892\n",
      "Epoch [1/10], Loss: 0.5236\n",
      "Epoch [1/10], Loss: 0.4106\n",
      "Epoch [1/10], Loss: 0.3689\n",
      "Epoch [1/10], Loss: 0.3427\n",
      "Epoch [1/10], Loss: 0.3220\n",
      "Epoch [1/10], Loss: 0.3158\n",
      "Epoch [1/10], Loss: 0.3083\n",
      "Epoch [1/10], Loss: 0.2942\n",
      "Epoch [1/10], Loss: 0.2885\n",
      "Epoch [1/10], Loss: 0.2870\n",
      "Epoch [1/10], Valid Accuracy: 92.2700, Valid Loss: 0.2921\n",
      "Epoch [2/10], Loss: 0.2094\n",
      "Epoch [2/10], Loss: 0.2054\n",
      "Epoch [2/10], Loss: 0.2007\n",
      "Epoch [2/10], Loss: 0.1939\n",
      "Epoch [2/10], Loss: 0.1959\n",
      "Epoch [2/10], Loss: 0.1995\n",
      "Epoch [2/10], Loss: 0.2032\n",
      "Epoch [2/10], Loss: 0.2025\n",
      "Epoch [2/10], Loss: 0.2019\n",
      "Epoch [2/10], Loss: 0.2023\n",
      "Epoch [2/10], Valid Accuracy: 94.4700, Valid Loss: 0.2188\n",
      "Epoch [3/10], Loss: 0.1825\n",
      "Epoch [3/10], Loss: 0.1758\n",
      "Epoch [3/10], Loss: 0.1826\n",
      "Epoch [3/10], Loss: 0.1814\n",
      "Epoch [3/10], Loss: 0.1814\n",
      "Epoch [3/10], Loss: 0.1829\n",
      "Epoch [3/10], Loss: 0.1809\n",
      "Epoch [3/10], Loss: 0.1837\n",
      "Epoch [3/10], Loss: 0.1847\n",
      "Epoch [3/10], Loss: 0.1858\n",
      "Epoch [3/10], Valid Accuracy: 94.4200, Valid Loss: 0.2275\n",
      "Epoch [4/10], Loss: 0.1769\n",
      "Epoch [4/10], Loss: 0.1751\n",
      "Epoch [4/10], Loss: 0.1805\n",
      "Epoch [4/10], Loss: 0.1899\n",
      "Epoch [4/10], Loss: 0.1839\n",
      "Epoch [4/10], Loss: 0.1812\n",
      "Epoch [4/10], Loss: 0.1857\n",
      "Epoch [4/10], Loss: 0.1853\n",
      "Epoch [4/10], Loss: 0.1866\n",
      "Epoch [4/10], Loss: 0.1859\n",
      "Epoch [4/10], Valid Accuracy: 95.6600, Valid Loss: 0.1803\n",
      "Epoch [5/10], Loss: 0.1397\n",
      "Epoch [5/10], Loss: 0.1363\n",
      "Epoch [5/10], Loss: 0.1458\n",
      "Epoch [5/10], Loss: 0.1496\n",
      "Epoch [5/10], Loss: 0.1596\n",
      "Epoch [5/10], Loss: 0.1662\n",
      "Epoch [5/10], Loss: 0.1670\n",
      "Epoch [5/10], Loss: 0.1680\n",
      "Epoch [5/10], Loss: 0.1702\n",
      "Epoch [5/10], Loss: 0.1718\n",
      "Epoch [5/10], Valid Accuracy: 94.7800, Valid Loss: 0.2265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.1557\n",
      "Epoch [6/10], Loss: 0.1586\n",
      "Epoch [6/10], Loss: 0.1596\n",
      "Epoch [6/10], Loss: 0.1575\n",
      "Epoch [6/10], Loss: 0.1587\n",
      "Epoch [6/10], Loss: 0.1629\n",
      "Epoch [6/10], Loss: 0.1630\n",
      "Epoch [6/10], Loss: 0.1690\n",
      "Epoch [6/10], Loss: 0.1701\n",
      "Epoch [6/10], Loss: 0.1703\n",
      "Epoch [6/10], Valid Accuracy: 95.3400, Valid Loss: 0.2014\n",
      "Epoch [7/10], Loss: 0.1404\n",
      "Epoch [7/10], Loss: 0.1430\n",
      "Epoch [7/10], Loss: 0.1436\n",
      "Epoch [7/10], Loss: 0.1511\n",
      "Epoch [7/10], Loss: 0.1475\n",
      "Epoch [7/10], Loss: 0.1497\n",
      "Epoch [7/10], Loss: 0.1492\n",
      "Epoch [7/10], Loss: 0.1522\n",
      "Epoch [7/10], Loss: 0.1543\n",
      "Epoch [7/10], Loss: 0.1568\n",
      "Epoch [7/10], Valid Accuracy: 94.8800, Valid Loss: 0.2435\n",
      "Epoch [8/10], Loss: 0.1636\n",
      "Epoch [8/10], Loss: 0.1531\n",
      "Epoch [8/10], Loss: 0.1604\n",
      "Epoch [8/10], Loss: 0.1615\n",
      "Epoch [8/10], Loss: 0.1611\n",
      "Epoch [8/10], Loss: 0.1594\n",
      "Epoch [8/10], Loss: 0.1585\n",
      "Epoch [8/10], Loss: 0.1613\n",
      "Epoch [8/10], Loss: 0.1623\n",
      "Epoch [8/10], Loss: 0.1615\n",
      "Epoch [8/10], Valid Accuracy: 94.9500, Valid Loss: 0.2409\n",
      "Epoch [9/10], Loss: 0.1197\n",
      "Epoch [9/10], Loss: 0.1418\n",
      "Epoch [9/10], Loss: 0.1456\n",
      "Epoch [9/10], Loss: 0.1433\n",
      "Epoch [9/10], Loss: 0.1438\n",
      "Epoch [9/10], Loss: 0.1459\n",
      "Epoch [9/10], Loss: 0.1464\n",
      "Epoch [9/10], Loss: 0.1536\n",
      "Epoch [9/10], Loss: 0.1532\n",
      "Epoch [9/10], Loss: 0.1539\n",
      "Epoch [9/10], Valid Accuracy: 95.1100, Valid Loss: 0.2720\n",
      "Epoch [10/10], Loss: 0.1239\n",
      "Epoch [10/10], Loss: 0.1238\n",
      "Epoch [10/10], Loss: 0.1340\n",
      "Epoch [10/10], Loss: 0.1298\n",
      "Epoch [10/10], Loss: 0.1351\n",
      "Epoch [10/10], Loss: 0.1407\n",
      "Epoch [10/10], Loss: 0.1463\n",
      "Epoch [10/10], Loss: 0.1466\n",
      "Epoch [10/10], Loss: 0.1466\n",
      "Epoch [10/10], Loss: 0.1475\n",
      "Epoch [10/10], Valid Accuracy: 93.9200, Valid Loss: 0.3151\n",
      "Epoch [1/10], Loss: 0.5778\n",
      "Epoch [1/10], Loss: 0.4267\n",
      "Epoch [1/10], Loss: 0.3823\n",
      "Epoch [1/10], Loss: 0.3467\n",
      "Epoch [1/10], Loss: 0.3273\n",
      "Epoch [1/10], Loss: 0.3149\n",
      "Epoch [1/10], Loss: 0.3014\n",
      "Epoch [1/10], Loss: 0.2943\n",
      "Epoch [1/10], Loss: 0.2857\n",
      "Epoch [1/10], Loss: 0.2851\n",
      "Epoch [1/10], Valid Accuracy: 94.3800, Valid Loss: 0.1974\n",
      "Epoch [2/10], Loss: 0.1996\n",
      "Epoch [2/10], Loss: 0.1943\n",
      "Epoch [2/10], Loss: 0.1997\n",
      "Epoch [2/10], Loss: 0.2013\n",
      "Epoch [2/10], Loss: 0.2055\n",
      "Epoch [2/10], Loss: 0.2048\n",
      "Epoch [2/10], Loss: 0.2058\n",
      "Epoch [2/10], Loss: 0.2067\n",
      "Epoch [2/10], Loss: 0.2089\n",
      "Epoch [2/10], Loss: 0.2088\n",
      "Epoch [2/10], Valid Accuracy: 94.2000, Valid Loss: 0.2322\n",
      "Epoch [3/10], Loss: 0.1871\n",
      "Epoch [3/10], Loss: 0.1857\n",
      "Epoch [3/10], Loss: 0.1783\n",
      "Epoch [3/10], Loss: 0.1837\n",
      "Epoch [3/10], Loss: 0.1865\n",
      "Epoch [3/10], Loss: 0.1881\n",
      "Epoch [3/10], Loss: 0.1905\n",
      "Epoch [3/10], Loss: 0.1883\n",
      "Epoch [3/10], Loss: 0.1872\n",
      "Epoch [3/10], Loss: 0.1868\n",
      "Epoch [3/10], Valid Accuracy: 95.7200, Valid Loss: 0.1692\n",
      "Epoch [4/10], Loss: 0.1474\n",
      "Epoch [4/10], Loss: 0.1497\n",
      "Epoch [4/10], Loss: 0.1613\n",
      "Epoch [4/10], Loss: 0.1654\n",
      "Epoch [4/10], Loss: 0.1684\n",
      "Epoch [4/10], Loss: 0.1659\n",
      "Epoch [4/10], Loss: 0.1701\n",
      "Epoch [4/10], Loss: 0.1692\n",
      "Epoch [4/10], Loss: 0.1731\n",
      "Epoch [4/10], Loss: 0.1745\n",
      "Epoch [4/10], Valid Accuracy: 95.0100, Valid Loss: 0.2108\n",
      "Epoch [5/10], Loss: 0.1421\n",
      "Epoch [5/10], Loss: 0.1488\n",
      "Epoch [5/10], Loss: 0.1523\n",
      "Epoch [5/10], Loss: 0.1552\n",
      "Epoch [5/10], Loss: 0.1603\n",
      "Epoch [5/10], Loss: 0.1615\n",
      "Epoch [5/10], Loss: 0.1641\n",
      "Epoch [5/10], Loss: 0.1670\n",
      "Epoch [5/10], Loss: 0.1712\n",
      "Epoch [5/10], Loss: 0.1726\n",
      "Epoch [5/10], Valid Accuracy: 95.4500, Valid Loss: 0.2261\n",
      "Epoch [6/10], Loss: 0.1514\n",
      "Epoch [6/10], Loss: 0.1682\n",
      "Epoch [6/10], Loss: 0.1613\n",
      "Epoch [6/10], Loss: 0.1598\n",
      "Epoch [6/10], Loss: 0.1588\n",
      "Epoch [6/10], Loss: 0.1635\n",
      "Epoch [6/10], Loss: 0.1659\n",
      "Epoch [6/10], Loss: 0.1658\n",
      "Epoch [6/10], Loss: 0.1697\n",
      "Epoch [6/10], Loss: 0.1693\n",
      "Epoch [6/10], Valid Accuracy: 95.6000, Valid Loss: 0.2177\n",
      "Epoch [7/10], Loss: 0.1394\n",
      "Epoch [7/10], Loss: 0.1440\n",
      "Epoch [7/10], Loss: 0.1397\n",
      "Epoch [7/10], Loss: 0.1437\n",
      "Epoch [7/10], Loss: 0.1455\n",
      "Epoch [7/10], Loss: 0.1505\n",
      "Epoch [7/10], Loss: 0.1507\n",
      "Epoch [7/10], Loss: 0.1531\n",
      "Epoch [7/10], Loss: 0.1605\n",
      "Epoch [7/10], Loss: 0.1609\n",
      "Epoch [7/10], Valid Accuracy: 95.1700, Valid Loss: 0.2593\n",
      "Epoch [8/10], Loss: 0.1496\n",
      "Epoch [8/10], Loss: 0.1493\n",
      "Epoch [8/10], Loss: 0.1520\n",
      "Epoch [8/10], Loss: 0.1529\n",
      "Epoch [8/10], Loss: 0.1528\n",
      "Epoch [8/10], Loss: 0.1567\n",
      "Epoch [8/10], Loss: 0.1590\n",
      "Epoch [8/10], Loss: 0.1559\n",
      "Epoch [8/10], Loss: 0.1555\n",
      "Epoch [8/10], Loss: 0.1579\n",
      "Epoch [8/10], Valid Accuracy: 95.0600, Valid Loss: 0.2662\n",
      "Epoch [9/10], Loss: 0.1523\n",
      "Epoch [9/10], Loss: 0.1634\n",
      "Epoch [9/10], Loss: 0.1634\n",
      "Epoch [9/10], Loss: 0.1586\n",
      "Epoch [9/10], Loss: 0.1589\n",
      "Epoch [9/10], Loss: 0.1616\n",
      "Epoch [9/10], Loss: 0.1605\n",
      "Epoch [9/10], Loss: 0.1588\n",
      "Epoch [9/10], Loss: 0.1573\n",
      "Epoch [9/10], Loss: 0.1586\n",
      "Epoch [9/10], Valid Accuracy: 94.6300, Valid Loss: 0.2659\n",
      "Epoch [10/10], Loss: 0.1237\n",
      "Epoch [10/10], Loss: 0.1235\n",
      "Epoch [10/10], Loss: 0.1189\n",
      "Epoch [10/10], Loss: 0.1267\n",
      "Epoch [10/10], Loss: 0.1252\n",
      "Epoch [10/10], Loss: 0.1266\n",
      "Epoch [10/10], Loss: 0.1317\n",
      "Epoch [10/10], Loss: 0.1318\n",
      "Epoch [10/10], Loss: 0.1352\n",
      "Epoch [10/10], Loss: 0.1374\n",
      "Epoch [10/10], Valid Accuracy: 95.2800, Valid Loss: 0.2810\n",
      "Epoch [1/10], Loss: 0.7756\n",
      "Epoch [1/10], Loss: 0.5453\n",
      "Epoch [1/10], Loss: 0.4601\n",
      "Epoch [1/10], Loss: 0.4121\n",
      "Epoch [1/10], Loss: 0.3799\n",
      "Epoch [1/10], Loss: 0.3607\n",
      "Epoch [1/10], Loss: 0.3456\n",
      "Epoch [1/10], Loss: 0.3348\n",
      "Epoch [1/10], Loss: 0.3259\n",
      "Epoch [1/10], Loss: 0.3242\n",
      "Epoch [1/10], Valid Accuracy: 91.2700, Valid Loss: 0.3123\n",
      "Epoch [2/10], Loss: 0.2073\n",
      "Epoch [2/10], Loss: 0.2151\n",
      "Epoch [2/10], Loss: 0.2131\n",
      "Epoch [2/10], Loss: 0.2178\n",
      "Epoch [2/10], Loss: 0.2197\n",
      "Epoch [2/10], Loss: 0.2186\n",
      "Epoch [2/10], Loss: 0.2183\n",
      "Epoch [2/10], Loss: 0.2172\n",
      "Epoch [2/10], Loss: 0.2184\n",
      "Epoch [2/10], Loss: 0.2179\n",
      "Epoch [2/10], Valid Accuracy: 94.2600, Valid Loss: 0.2179\n",
      "Epoch [3/10], Loss: 0.1675\n",
      "Epoch [3/10], Loss: 0.1738\n",
      "Epoch [3/10], Loss: 0.1844\n",
      "Epoch [3/10], Loss: 0.1823\n",
      "Epoch [3/10], Loss: 0.1875\n",
      "Epoch [3/10], Loss: 0.1925\n",
      "Epoch [3/10], Loss: 0.1935\n",
      "Epoch [3/10], Loss: 0.1932\n",
      "Epoch [3/10], Loss: 0.1957\n",
      "Epoch [3/10], Loss: 0.1974\n",
      "Epoch [3/10], Valid Accuracy: 94.8100, Valid Loss: 0.2123\n",
      "Epoch [4/10], Loss: 0.1835\n",
      "Epoch [4/10], Loss: 0.1850\n",
      "Epoch [4/10], Loss: 0.1864\n",
      "Epoch [4/10], Loss: 0.1823\n",
      "Epoch [4/10], Loss: 0.1780\n",
      "Epoch [4/10], Loss: 0.1792\n",
      "Epoch [4/10], Loss: 0.1805\n",
      "Epoch [4/10], Loss: 0.1800\n",
      "Epoch [4/10], Loss: 0.1826\n",
      "Epoch [4/10], Loss: 0.1822\n",
      "Epoch [4/10], Valid Accuracy: 94.7200, Valid Loss: 0.2286\n",
      "Epoch [5/10], Loss: 0.1605\n",
      "Epoch [5/10], Loss: 0.1587\n",
      "Epoch [5/10], Loss: 0.1625\n",
      "Epoch [5/10], Loss: 0.1676\n",
      "Epoch [5/10], Loss: 0.1645\n",
      "Epoch [5/10], Loss: 0.1649\n",
      "Epoch [5/10], Loss: 0.1668\n",
      "Epoch [5/10], Loss: 0.1658\n",
      "Epoch [5/10], Loss: 0.1684\n",
      "Epoch [5/10], Loss: 0.1693\n",
      "Epoch [5/10], Valid Accuracy: 95.5500, Valid Loss: 0.2066\n",
      "Epoch [6/10], Loss: 0.1311\n",
      "Epoch [6/10], Loss: 0.1326\n",
      "Epoch [6/10], Loss: 0.1433\n",
      "Epoch [6/10], Loss: 0.1491\n",
      "Epoch [6/10], Loss: 0.1520\n",
      "Epoch [6/10], Loss: 0.1573\n",
      "Epoch [6/10], Loss: 0.1584\n",
      "Epoch [6/10], Loss: 0.1609\n",
      "Epoch [6/10], Loss: 0.1636\n",
      "Epoch [6/10], Loss: 0.1635\n",
      "Epoch [6/10], Valid Accuracy: 95.1100, Valid Loss: 0.2362\n",
      "Epoch [7/10], Loss: 0.1565\n",
      "Epoch [7/10], Loss: 0.1556\n",
      "Epoch [7/10], Loss: 0.1596\n",
      "Epoch [7/10], Loss: 0.1586\n",
      "Epoch [7/10], Loss: 0.1615\n",
      "Epoch [7/10], Loss: 0.1611\n",
      "Epoch [7/10], Loss: 0.1666\n",
      "Epoch [7/10], Loss: 0.1661\n",
      "Epoch [7/10], Loss: 0.1679\n",
      "Epoch [7/10], Loss: 0.1690\n",
      "Epoch [7/10], Valid Accuracy: 94.8000, Valid Loss: 0.2628\n",
      "Epoch [8/10], Loss: 0.1553\n",
      "Epoch [8/10], Loss: 0.1561\n",
      "Epoch [8/10], Loss: 0.1575\n",
      "Epoch [8/10], Loss: 0.1607\n",
      "Epoch [8/10], Loss: 0.1619\n",
      "Epoch [8/10], Loss: 0.1619\n",
      "Epoch [8/10], Loss: 0.1641\n",
      "Epoch [8/10], Loss: 0.1635\n",
      "Epoch [8/10], Loss: 0.1652\n",
      "Epoch [8/10], Loss: 0.1668\n",
      "Epoch [8/10], Valid Accuracy: 94.8300, Valid Loss: 0.2642\n",
      "Epoch [9/10], Loss: 0.1408\n",
      "Epoch [9/10], Loss: 0.1292\n",
      "Epoch [9/10], Loss: 0.1272\n",
      "Epoch [9/10], Loss: 0.1335\n",
      "Epoch [9/10], Loss: 0.1318\n",
      "Epoch [9/10], Loss: 0.1403\n",
      "Epoch [9/10], Loss: 0.1446\n",
      "Epoch [9/10], Loss: 0.1472\n",
      "Epoch [9/10], Loss: 0.1510\n",
      "Epoch [9/10], Loss: 0.1521\n",
      "Epoch [9/10], Valid Accuracy: 95.0500, Valid Loss: 0.2615\n",
      "Epoch [10/10], Loss: 0.1250\n",
      "Epoch [10/10], Loss: 0.1287\n",
      "Epoch [10/10], Loss: 0.1425\n",
      "Epoch [10/10], Loss: 0.1438\n",
      "Epoch [10/10], Loss: 0.1467\n",
      "Epoch [10/10], Loss: 0.1485\n",
      "Epoch [10/10], Loss: 0.1500\n",
      "Epoch [10/10], Loss: 0.1524\n",
      "Epoch [10/10], Loss: 0.1549\n",
      "Epoch [10/10], Loss: 0.1538\n",
      "Epoch [10/10], Valid Accuracy: 95.8600, Valid Loss: 0.2418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.0378\n",
      "Epoch [1/10], Loss: 0.6811\n",
      "Epoch [1/10], Loss: 0.5399\n",
      "Epoch [1/10], Loss: 0.4743\n",
      "Epoch [1/10], Loss: 0.4265\n",
      "Epoch [1/10], Loss: 0.3991\n",
      "Epoch [1/10], Loss: 0.3798\n",
      "Epoch [1/10], Loss: 0.3673\n",
      "Epoch [1/10], Loss: 0.3572\n",
      "Epoch [1/10], Loss: 0.3535\n",
      "Epoch [1/10], Valid Accuracy: 93.0700, Valid Loss: 0.2346\n",
      "Epoch [2/10], Loss: 0.1985\n",
      "Epoch [2/10], Loss: 0.2281\n",
      "Epoch [2/10], Loss: 0.2237\n",
      "Epoch [2/10], Loss: 0.2217\n",
      "Epoch [2/10], Loss: 0.2165\n",
      "Epoch [2/10], Loss: 0.2209\n",
      "Epoch [2/10], Loss: 0.2172\n",
      "Epoch [2/10], Loss: 0.2152\n",
      "Epoch [2/10], Loss: 0.2171\n",
      "Epoch [2/10], Loss: 0.2160\n",
      "Epoch [2/10], Valid Accuracy: 95.0300, Valid Loss: 0.1900\n",
      "Epoch [3/10], Loss: 0.1861\n",
      "Epoch [3/10], Loss: 0.2008\n",
      "Epoch [3/10], Loss: 0.1973\n",
      "Epoch [3/10], Loss: 0.2066\n",
      "Epoch [3/10], Loss: 0.2002\n",
      "Epoch [3/10], Loss: 0.1984\n",
      "Epoch [3/10], Loss: 0.1953\n",
      "Epoch [3/10], Loss: 0.1972\n",
      "Epoch [3/10], Loss: 0.2002\n",
      "Epoch [3/10], Loss: 0.2011\n",
      "Epoch [3/10], Valid Accuracy: 94.9600, Valid Loss: 0.2160\n",
      "Epoch [4/10], Loss: 0.1756\n",
      "Epoch [4/10], Loss: 0.1774\n",
      "Epoch [4/10], Loss: 0.1776\n",
      "Epoch [4/10], Loss: 0.1817\n",
      "Epoch [4/10], Loss: 0.1833\n",
      "Epoch [4/10], Loss: 0.1798\n",
      "Epoch [4/10], Loss: 0.1847\n",
      "Epoch [4/10], Loss: 0.1862\n",
      "Epoch [4/10], Loss: 0.1843\n",
      "Epoch [4/10], Loss: 0.1842\n",
      "Epoch [4/10], Valid Accuracy: 94.4100, Valid Loss: 0.2451\n",
      "Epoch [5/10], Loss: 0.1531\n",
      "Epoch [5/10], Loss: 0.1739\n",
      "Epoch [5/10], Loss: 0.1875\n",
      "Epoch [5/10], Loss: 0.1855\n",
      "Epoch [5/10], Loss: 0.1858\n",
      "Epoch [5/10], Loss: 0.1861\n",
      "Epoch [5/10], Loss: 0.1820\n",
      "Epoch [5/10], Loss: 0.1812\n",
      "Epoch [5/10], Loss: 0.1799\n",
      "Epoch [5/10], Loss: 0.1796\n",
      "Epoch [5/10], Valid Accuracy: 95.0900, Valid Loss: 0.2268\n",
      "Epoch [6/10], Loss: 0.1485\n",
      "Epoch [6/10], Loss: 0.1413\n",
      "Epoch [6/10], Loss: 0.1535\n",
      "Epoch [6/10], Loss: 0.1576\n",
      "Epoch [6/10], Loss: 0.1619\n",
      "Epoch [6/10], Loss: 0.1630\n",
      "Epoch [6/10], Loss: 0.1629\n",
      "Epoch [6/10], Loss: 0.1640\n",
      "Epoch [6/10], Loss: 0.1635\n",
      "Epoch [6/10], Loss: 0.1643\n",
      "Epoch [6/10], Valid Accuracy: 93.7800, Valid Loss: 0.2963\n",
      "Epoch [7/10], Loss: 0.1609\n",
      "Epoch [7/10], Loss: 0.1682\n",
      "Epoch [7/10], Loss: 0.1700\n",
      "Epoch [7/10], Loss: 0.1703\n",
      "Epoch [7/10], Loss: 0.1652\n",
      "Epoch [7/10], Loss: 0.1610\n",
      "Epoch [7/10], Loss: 0.1639\n",
      "Epoch [7/10], Loss: 0.1661\n",
      "Epoch [7/10], Loss: 0.1684\n",
      "Epoch [7/10], Loss: 0.1700\n",
      "Epoch [7/10], Valid Accuracy: 94.9900, Valid Loss: 0.2470\n",
      "Epoch [8/10], Loss: 0.1504\n",
      "Epoch [8/10], Loss: 0.1595\n",
      "Epoch [8/10], Loss: 0.1604\n",
      "Epoch [8/10], Loss: 0.1592\n",
      "Epoch [8/10], Loss: 0.1604\n",
      "Epoch [8/10], Loss: 0.1625\n",
      "Epoch [8/10], Loss: 0.1616\n",
      "Epoch [8/10], Loss: 0.1620\n",
      "Epoch [8/10], Loss: 0.1610\n",
      "Epoch [8/10], Loss: 0.1617\n",
      "Epoch [8/10], Valid Accuracy: 95.2900, Valid Loss: 0.2749\n",
      "Epoch [9/10], Loss: 0.1374\n",
      "Epoch [9/10], Loss: 0.1433\n",
      "Epoch [9/10], Loss: 0.1537\n",
      "Epoch [9/10], Loss: 0.1543\n",
      "Epoch [9/10], Loss: 0.1568\n",
      "Epoch [9/10], Loss: 0.1531\n",
      "Epoch [9/10], Loss: 0.1511\n",
      "Epoch [9/10], Loss: 0.1522\n",
      "Epoch [9/10], Loss: 0.1582\n",
      "Epoch [9/10], Loss: 0.1580\n",
      "Epoch [9/10], Valid Accuracy: 94.6800, Valid Loss: 0.2993\n",
      "Epoch [10/10], Loss: 0.1528\n",
      "Epoch [10/10], Loss: 0.1441\n",
      "Epoch [10/10], Loss: 0.1403\n",
      "Epoch [10/10], Loss: 0.1380\n",
      "Epoch [10/10], Loss: 0.1401\n",
      "Epoch [10/10], Loss: 0.1404\n",
      "Epoch [10/10], Loss: 0.1443\n",
      "Epoch [10/10], Loss: 0.1463\n",
      "Epoch [10/10], Loss: 0.1513\n",
      "Epoch [10/10], Loss: 0.1528\n",
      "Epoch [10/10], Valid Accuracy: 95.1100, Valid Loss: 0.2531\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = [10, 50, 100, 300, 1000, 2000]\n",
    "lst_val_acc2 = []\n",
    "lst_val_loss2 = []\n",
    "lst_train_loss2 = []\n",
    "for hls in hidden_layer_size:\n",
    "    net = get_model(M=hls)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, num_epochs=10, model=net, optimizer=optimizer)\n",
    "    lst_val_acc2.append(val_acc)\n",
    "    lst_val_loss2.append(val_loss)\n",
    "    lst_train_loss2.append(train_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>89.52</td>\n",
       "      <td>0.360955</td>\n",
       "      <td>0.351216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>94.66</td>\n",
       "      <td>0.289197</td>\n",
       "      <td>0.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>93.92</td>\n",
       "      <td>0.315142</td>\n",
       "      <td>0.147479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>95.28</td>\n",
       "      <td>0.280959</td>\n",
       "      <td>0.137389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>95.86</td>\n",
       "      <td>0.241802</td>\n",
       "      <td>0.153777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>95.11</td>\n",
       "      <td>0.253072</td>\n",
       "      <td>0.152805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hidden Layer Size  Validation Accuracy  Validation Loss  Training Loss\n",
       "0                 10                89.52         0.360955       0.351216\n",
       "1                 50                94.66         0.289197       0.157500\n",
       "2                100                93.92         0.315142       0.147479\n",
       "3                300                95.28         0.280959       0.137389\n",
       "4               1000                95.86         0.241802       0.153777\n",
       "5               2000                95.11         0.253072       0.152805"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        'Hidden Layer Size': hidden_layer_size,\n",
    "        'Validation Accuracy': lst_val_acc2,\n",
    "        'Validation Loss': lst_val_loss2,\n",
    "        'Training Loss': lst_train_loss2\n",
    "    },\n",
    "    columns = ['Hidden Layer Size', 'Validation Accuracy', 'Validation Loss', 'Training Loss']\n",
    ")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Loss')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f804c68d0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df2['Hidden Layer Size'], df2['Training Loss'])\n",
    "plt.plot(df2['Hidden Layer Size'], df2['Validation Loss'])\n",
    "plt.xticks(df2['Hidden Layer Size'])\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='center right', bbox_to_anchor=(1.0, 0.3), ncol=1)\n",
    "plt.xlabel('Hidden Layer Size')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When M = 1000, the neural network has best validation accuracy 95.86% and lowest validation loss. The model overfits at M = 2000, because the validation loss increases and training loss decreases approaching this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Tuning weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.5545\n",
      "Epoch [1/20], Loss: 0.4192\n",
      "Epoch [1/20], Loss: 0.3539\n",
      "Epoch [1/20], Loss: 0.3144\n",
      "Epoch [1/20], Loss: 0.2890\n",
      "Epoch [1/20], Loss: 0.2678\n",
      "Epoch [1/20], Loss: 0.2507\n",
      "Epoch [1/20], Loss: 0.2360\n",
      "Epoch [1/20], Loss: 0.2241\n",
      "Epoch [1/20], Loss: 0.2203\n",
      "Epoch [1/20], Valid Accuracy: 95.8900, Valid Loss: 0.1293\n",
      "Epoch [2/20], Loss: 0.0955\n",
      "Epoch [2/20], Loss: 0.0954\n",
      "Epoch [2/20], Loss: 0.0999\n",
      "Epoch [2/20], Loss: 0.0962\n",
      "Epoch [2/20], Loss: 0.0957\n",
      "Epoch [2/20], Loss: 0.0942\n",
      "Epoch [2/20], Loss: 0.0936\n",
      "Epoch [2/20], Loss: 0.0932\n",
      "Epoch [2/20], Loss: 0.0927\n",
      "Epoch [2/20], Loss: 0.0924\n",
      "Epoch [2/20], Valid Accuracy: 97.7100, Valid Loss: 0.0784\n",
      "Epoch [3/20], Loss: 0.0474\n",
      "Epoch [3/20], Loss: 0.0542\n",
      "Epoch [3/20], Loss: 0.0563\n",
      "Epoch [3/20], Loss: 0.0579\n",
      "Epoch [3/20], Loss: 0.0585\n",
      "Epoch [3/20], Loss: 0.0590\n",
      "Epoch [3/20], Loss: 0.0586\n",
      "Epoch [3/20], Loss: 0.0599\n",
      "Epoch [3/20], Loss: 0.0608\n",
      "Epoch [3/20], Loss: 0.0607\n",
      "Epoch [3/20], Valid Accuracy: 97.7800, Valid Loss: 0.0726\n",
      "Epoch [4/20], Loss: 0.0400\n",
      "Epoch [4/20], Loss: 0.0445\n",
      "Epoch [4/20], Loss: 0.0432\n",
      "Epoch [4/20], Loss: 0.0446\n",
      "Epoch [4/20], Loss: 0.0432\n",
      "Epoch [4/20], Loss: 0.0425\n",
      "Epoch [4/20], Loss: 0.0433\n",
      "Epoch [4/20], Loss: 0.0440\n",
      "Epoch [4/20], Loss: 0.0450\n",
      "Epoch [4/20], Loss: 0.0451\n",
      "Epoch [4/20], Valid Accuracy: 97.3500, Valid Loss: 0.0836\n",
      "Epoch [5/20], Loss: 0.0369\n",
      "Epoch [5/20], Loss: 0.0371\n",
      "Epoch [5/20], Loss: 0.0340\n",
      "Epoch [5/20], Loss: 0.0333\n",
      "Epoch [5/20], Loss: 0.0326\n",
      "Epoch [5/20], Loss: 0.0338\n",
      "Epoch [5/20], Loss: 0.0343\n",
      "Epoch [5/20], Loss: 0.0352\n",
      "Epoch [5/20], Loss: 0.0357\n",
      "Epoch [5/20], Loss: 0.0358\n",
      "Epoch [5/20], Valid Accuracy: 97.8500, Valid Loss: 0.0728\n",
      "Epoch [6/20], Loss: 0.0263\n",
      "Epoch [6/20], Loss: 0.0252\n",
      "Epoch [6/20], Loss: 0.0256\n",
      "Epoch [6/20], Loss: 0.0252\n",
      "Epoch [6/20], Loss: 0.0255\n",
      "Epoch [6/20], Loss: 0.0272\n",
      "Epoch [6/20], Loss: 0.0281\n",
      "Epoch [6/20], Loss: 0.0287\n",
      "Epoch [6/20], Loss: 0.0283\n",
      "Epoch [6/20], Loss: 0.0292\n",
      "Epoch [6/20], Valid Accuracy: 97.8500, Valid Loss: 0.0764\n",
      "Epoch [7/20], Loss: 0.0182\n",
      "Epoch [7/20], Loss: 0.0192\n",
      "Epoch [7/20], Loss: 0.0179\n",
      "Epoch [7/20], Loss: 0.0190\n",
      "Epoch [7/20], Loss: 0.0199\n",
      "Epoch [7/20], Loss: 0.0196\n",
      "Epoch [7/20], Loss: 0.0208\n",
      "Epoch [7/20], Loss: 0.0213\n",
      "Epoch [7/20], Loss: 0.0219\n",
      "Epoch [7/20], Loss: 0.0224\n",
      "Epoch [7/20], Valid Accuracy: 97.6700, Valid Loss: 0.0849\n",
      "Epoch [8/20], Loss: 0.0194\n",
      "Epoch [8/20], Loss: 0.0171\n",
      "Epoch [8/20], Loss: 0.0175\n",
      "Epoch [8/20], Loss: 0.0198\n",
      "Epoch [8/20], Loss: 0.0202\n",
      "Epoch [8/20], Loss: 0.0205\n",
      "Epoch [8/20], Loss: 0.0215\n",
      "Epoch [8/20], Loss: 0.0231\n",
      "Epoch [8/20], Loss: 0.0233\n",
      "Epoch [8/20], Loss: 0.0235\n",
      "Epoch [8/20], Valid Accuracy: 98.0000, Valid Loss: 0.0859\n",
      "Epoch [9/20], Loss: 0.0172\n",
      "Epoch [9/20], Loss: 0.0156\n",
      "Epoch [9/20], Loss: 0.0143\n",
      "Epoch [9/20], Loss: 0.0142\n",
      "Epoch [9/20], Loss: 0.0150\n",
      "Epoch [9/20], Loss: 0.0145\n",
      "Epoch [9/20], Loss: 0.0152\n",
      "Epoch [9/20], Loss: 0.0164\n",
      "Epoch [9/20], Loss: 0.0164\n",
      "Epoch [9/20], Loss: 0.0165\n",
      "Epoch [9/20], Valid Accuracy: 98.0100, Valid Loss: 0.0830\n",
      "Epoch [10/20], Loss: 0.0123\n",
      "Epoch [10/20], Loss: 0.0113\n",
      "Epoch [10/20], Loss: 0.0136\n",
      "Epoch [10/20], Loss: 0.0143\n",
      "Epoch [10/20], Loss: 0.0144\n",
      "Epoch [10/20], Loss: 0.0145\n",
      "Epoch [10/20], Loss: 0.0148\n",
      "Epoch [10/20], Loss: 0.0154\n",
      "Epoch [10/20], Loss: 0.0160\n",
      "Epoch [10/20], Loss: 0.0164\n",
      "Epoch [10/20], Valid Accuracy: 98.2100, Valid Loss: 0.0769\n",
      "Epoch [11/20], Loss: 0.0186\n",
      "Epoch [11/20], Loss: 0.0150\n",
      "Epoch [11/20], Loss: 0.0138\n",
      "Epoch [11/20], Loss: 0.0136\n",
      "Epoch [11/20], Loss: 0.0139\n",
      "Epoch [11/20], Loss: 0.0143\n",
      "Epoch [11/20], Loss: 0.0145\n",
      "Epoch [11/20], Loss: 0.0141\n",
      "Epoch [11/20], Loss: 0.0139\n",
      "Epoch [11/20], Loss: 0.0143\n",
      "Epoch [11/20], Valid Accuracy: 97.9100, Valid Loss: 0.0947\n",
      "Epoch [12/20], Loss: 0.0160\n",
      "Epoch [12/20], Loss: 0.0145\n",
      "Epoch [12/20], Loss: 0.0144\n",
      "Epoch [12/20], Loss: 0.0139\n",
      "Epoch [12/20], Loss: 0.0134\n",
      "Epoch [12/20], Loss: 0.0141\n",
      "Epoch [12/20], Loss: 0.0141\n",
      "Epoch [12/20], Loss: 0.0141\n",
      "Epoch [12/20], Loss: 0.0148\n",
      "Epoch [12/20], Loss: 0.0152\n",
      "Epoch [12/20], Valid Accuracy: 98.0200, Valid Loss: 0.0942\n",
      "Epoch [13/20], Loss: 0.0087\n",
      "Epoch [13/20], Loss: 0.0095\n",
      "Epoch [13/20], Loss: 0.0106\n",
      "Epoch [13/20], Loss: 0.0102\n",
      "Epoch [13/20], Loss: 0.0104\n",
      "Epoch [13/20], Loss: 0.0103\n",
      "Epoch [13/20], Loss: 0.0108\n",
      "Epoch [13/20], Loss: 0.0114\n",
      "Epoch [13/20], Loss: 0.0121\n",
      "Epoch [13/20], Loss: 0.0123\n",
      "Epoch [13/20], Valid Accuracy: 98.0200, Valid Loss: 0.0935\n",
      "Epoch [14/20], Loss: 0.0093\n",
      "Epoch [14/20], Loss: 0.0118\n",
      "Epoch [14/20], Loss: 0.0112\n",
      "Epoch [14/20], Loss: 0.0098\n",
      "Epoch [14/20], Loss: 0.0087\n",
      "Epoch [14/20], Loss: 0.0096\n",
      "Epoch [14/20], Loss: 0.0111\n",
      "Epoch [14/20], Loss: 0.0117\n",
      "Epoch [14/20], Loss: 0.0118\n",
      "Epoch [14/20], Loss: 0.0125\n",
      "Epoch [14/20], Valid Accuracy: 97.7600, Valid Loss: 0.1120\n",
      "Epoch [15/20], Loss: 0.0122\n",
      "Epoch [15/20], Loss: 0.0130\n",
      "Epoch [15/20], Loss: 0.0124\n",
      "Epoch [15/20], Loss: 0.0120\n",
      "Epoch [15/20], Loss: 0.0119\n",
      "Epoch [15/20], Loss: 0.0126\n",
      "Epoch [15/20], Loss: 0.0142\n",
      "Epoch [15/20], Loss: 0.0154\n",
      "Epoch [15/20], Loss: 0.0154\n",
      "Epoch [15/20], Loss: 0.0154\n",
      "Epoch [15/20], Valid Accuracy: 98.0400, Valid Loss: 0.0989\n",
      "Epoch [16/20], Loss: 0.0132\n",
      "Epoch [16/20], Loss: 0.0089\n",
      "Epoch [16/20], Loss: 0.0090\n",
      "Epoch [16/20], Loss: 0.0086\n",
      "Epoch [16/20], Loss: 0.0089\n",
      "Epoch [16/20], Loss: 0.0083\n",
      "Epoch [16/20], Loss: 0.0078\n",
      "Epoch [16/20], Loss: 0.0083\n",
      "Epoch [16/20], Loss: 0.0092\n",
      "Epoch [16/20], Loss: 0.0093\n",
      "Epoch [16/20], Valid Accuracy: 98.1000, Valid Loss: 0.1067\n",
      "Epoch [17/20], Loss: 0.0114\n",
      "Epoch [17/20], Loss: 0.0098\n",
      "Epoch [17/20], Loss: 0.0090\n",
      "Epoch [17/20], Loss: 0.0093\n",
      "Epoch [17/20], Loss: 0.0095\n",
      "Epoch [17/20], Loss: 0.0099\n",
      "Epoch [17/20], Loss: 0.0102\n",
      "Epoch [17/20], Loss: 0.0100\n",
      "Epoch [17/20], Loss: 0.0106\n",
      "Epoch [17/20], Loss: 0.0109\n",
      "Epoch [17/20], Valid Accuracy: 98.0300, Valid Loss: 0.1049\n",
      "Epoch [18/20], Loss: 0.0132\n",
      "Epoch [18/20], Loss: 0.0135\n",
      "Epoch [18/20], Loss: 0.0100\n",
      "Epoch [18/20], Loss: 0.0100\n",
      "Epoch [18/20], Loss: 0.0098\n",
      "Epoch [18/20], Loss: 0.0102\n",
      "Epoch [18/20], Loss: 0.0100\n",
      "Epoch [18/20], Loss: 0.0101\n",
      "Epoch [18/20], Loss: 0.0098\n",
      "Epoch [18/20], Loss: 0.0100\n",
      "Epoch [18/20], Valid Accuracy: 98.1700, Valid Loss: 0.1021\n",
      "Epoch [19/20], Loss: 0.0059\n",
      "Epoch [19/20], Loss: 0.0055\n",
      "Epoch [19/20], Loss: 0.0056\n",
      "Epoch [19/20], Loss: 0.0056\n",
      "Epoch [19/20], Loss: 0.0059\n",
      "Epoch [19/20], Loss: 0.0069\n",
      "Epoch [19/20], Loss: 0.0072\n",
      "Epoch [19/20], Loss: 0.0071\n",
      "Epoch [19/20], Loss: 0.0073\n",
      "Epoch [19/20], Loss: 0.0077\n",
      "Epoch [19/20], Valid Accuracy: 98.1900, Valid Loss: 0.1090\n",
      "Epoch [20/20], Loss: 0.0122\n",
      "Epoch [20/20], Loss: 0.0136\n",
      "Epoch [20/20], Loss: 0.0117\n",
      "Epoch [20/20], Loss: 0.0099\n",
      "Epoch [20/20], Loss: 0.0099\n",
      "Epoch [20/20], Loss: 0.0093\n",
      "Epoch [20/20], Loss: 0.0092\n",
      "Epoch [20/20], Loss: 0.0104\n",
      "Epoch [20/20], Loss: 0.0098\n",
      "Epoch [20/20], Loss: 0.0100\n",
      "Epoch [20/20], Valid Accuracy: 98.0800, Valid Loss: 0.1096\n",
      "Epoch [1/20], Loss: 0.5483\n",
      "Epoch [1/20], Loss: 0.4203\n",
      "Epoch [1/20], Loss: 0.3628\n",
      "Epoch [1/20], Loss: 0.3246\n",
      "Epoch [1/20], Loss: 0.2983\n",
      "Epoch [1/20], Loss: 0.2744\n",
      "Epoch [1/20], Loss: 0.2576\n",
      "Epoch [1/20], Loss: 0.2414\n",
      "Epoch [1/20], Loss: 0.2275\n",
      "Epoch [1/20], Loss: 0.2224\n",
      "Epoch [1/20], Valid Accuracy: 96.5100, Valid Loss: 0.1118\n",
      "Epoch [2/20], Loss: 0.1176\n",
      "Epoch [2/20], Loss: 0.1067\n",
      "Epoch [2/20], Loss: 0.1001\n",
      "Epoch [2/20], Loss: 0.0998\n",
      "Epoch [2/20], Loss: 0.0954\n",
      "Epoch [2/20], Loss: 0.0951\n",
      "Epoch [2/20], Loss: 0.0944\n",
      "Epoch [2/20], Loss: 0.0944\n",
      "Epoch [2/20], Loss: 0.0937\n",
      "Epoch [2/20], Loss: 0.0936\n",
      "Epoch [2/20], Valid Accuracy: 97.2700, Valid Loss: 0.0861\n",
      "Epoch [3/20], Loss: 0.0704\n",
      "Epoch [3/20], Loss: 0.0664\n",
      "Epoch [3/20], Loss: 0.0667\n",
      "Epoch [3/20], Loss: 0.0648\n",
      "Epoch [3/20], Loss: 0.0645\n",
      "Epoch [3/20], Loss: 0.0644\n",
      "Epoch [3/20], Loss: 0.0637\n",
      "Epoch [3/20], Loss: 0.0638\n",
      "Epoch [3/20], Loss: 0.0647\n",
      "Epoch [3/20], Loss: 0.0653\n",
      "Epoch [3/20], Valid Accuracy: 97.4100, Valid Loss: 0.0864\n",
      "Epoch [4/20], Loss: 0.0474\n",
      "Epoch [4/20], Loss: 0.0480\n",
      "Epoch [4/20], Loss: 0.0475\n",
      "Epoch [4/20], Loss: 0.0486\n",
      "Epoch [4/20], Loss: 0.0491\n",
      "Epoch [4/20], Loss: 0.0494\n",
      "Epoch [4/20], Loss: 0.0487\n",
      "Epoch [4/20], Loss: 0.0500\n",
      "Epoch [4/20], Loss: 0.0499\n",
      "Epoch [4/20], Loss: 0.0506\n",
      "Epoch [4/20], Valid Accuracy: 97.9600, Valid Loss: 0.0657\n",
      "Epoch [5/20], Loss: 0.0336\n",
      "Epoch [5/20], Loss: 0.0333\n",
      "Epoch [5/20], Loss: 0.0352\n",
      "Epoch [5/20], Loss: 0.0365\n",
      "Epoch [5/20], Loss: 0.0367\n",
      "Epoch [5/20], Loss: 0.0367\n",
      "Epoch [5/20], Loss: 0.0373\n",
      "Epoch [5/20], Loss: 0.0385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.0410\n",
      "Epoch [5/20], Loss: 0.0413\n",
      "Epoch [5/20], Valid Accuracy: 97.7100, Valid Loss: 0.0771\n",
      "Epoch [6/20], Loss: 0.0251\n",
      "Epoch [6/20], Loss: 0.0296\n",
      "Epoch [6/20], Loss: 0.0310\n",
      "Epoch [6/20], Loss: 0.0310\n",
      "Epoch [6/20], Loss: 0.0300\n",
      "Epoch [6/20], Loss: 0.0310\n",
      "Epoch [6/20], Loss: 0.0322\n",
      "Epoch [6/20], Loss: 0.0333\n",
      "Epoch [6/20], Loss: 0.0341\n",
      "Epoch [6/20], Loss: 0.0342\n",
      "Epoch [6/20], Valid Accuracy: 97.8200, Valid Loss: 0.0718\n",
      "Epoch [7/20], Loss: 0.0251\n",
      "Epoch [7/20], Loss: 0.0235\n",
      "Epoch [7/20], Loss: 0.0263\n",
      "Epoch [7/20], Loss: 0.0265\n",
      "Epoch [7/20], Loss: 0.0270\n",
      "Epoch [7/20], Loss: 0.0276\n",
      "Epoch [7/20], Loss: 0.0277\n",
      "Epoch [7/20], Loss: 0.0292\n",
      "Epoch [7/20], Loss: 0.0308\n",
      "Epoch [7/20], Loss: 0.0309\n",
      "Epoch [7/20], Valid Accuracy: 97.9800, Valid Loss: 0.0709\n",
      "Epoch [8/20], Loss: 0.0235\n",
      "Epoch [8/20], Loss: 0.0252\n",
      "Epoch [8/20], Loss: 0.0239\n",
      "Epoch [8/20], Loss: 0.0263\n",
      "Epoch [8/20], Loss: 0.0255\n",
      "Epoch [8/20], Loss: 0.0260\n",
      "Epoch [8/20], Loss: 0.0264\n",
      "Epoch [8/20], Loss: 0.0271\n",
      "Epoch [8/20], Loss: 0.0285\n",
      "Epoch [8/20], Loss: 0.0281\n",
      "Epoch [8/20], Valid Accuracy: 97.8700, Valid Loss: 0.0709\n",
      "Epoch [9/20], Loss: 0.0170\n",
      "Epoch [9/20], Loss: 0.0178\n",
      "Epoch [9/20], Loss: 0.0177\n",
      "Epoch [9/20], Loss: 0.0192\n",
      "Epoch [9/20], Loss: 0.0196\n",
      "Epoch [9/20], Loss: 0.0206\n",
      "Epoch [9/20], Loss: 0.0220\n",
      "Epoch [9/20], Loss: 0.0229\n",
      "Epoch [9/20], Loss: 0.0238\n",
      "Epoch [9/20], Loss: 0.0242\n",
      "Epoch [9/20], Valid Accuracy: 97.5900, Valid Loss: 0.0844\n",
      "Epoch [10/20], Loss: 0.0211\n",
      "Epoch [10/20], Loss: 0.0200\n",
      "Epoch [10/20], Loss: 0.0215\n",
      "Epoch [10/20], Loss: 0.0226\n",
      "Epoch [10/20], Loss: 0.0232\n",
      "Epoch [10/20], Loss: 0.0242\n",
      "Epoch [10/20], Loss: 0.0238\n",
      "Epoch [10/20], Loss: 0.0254\n",
      "Epoch [10/20], Loss: 0.0251\n",
      "Epoch [10/20], Loss: 0.0251\n",
      "Epoch [10/20], Valid Accuracy: 97.9400, Valid Loss: 0.0776\n",
      "Epoch [11/20], Loss: 0.0140\n",
      "Epoch [11/20], Loss: 0.0183\n",
      "Epoch [11/20], Loss: 0.0176\n",
      "Epoch [11/20], Loss: 0.0175\n",
      "Epoch [11/20], Loss: 0.0189\n",
      "Epoch [11/20], Loss: 0.0205\n",
      "Epoch [11/20], Loss: 0.0218\n",
      "Epoch [11/20], Loss: 0.0225\n",
      "Epoch [11/20], Loss: 0.0223\n",
      "Epoch [11/20], Loss: 0.0225\n",
      "Epoch [11/20], Valid Accuracy: 98.1500, Valid Loss: 0.0746\n",
      "Epoch [12/20], Loss: 0.0187\n",
      "Epoch [12/20], Loss: 0.0185\n",
      "Epoch [12/20], Loss: 0.0177\n",
      "Epoch [12/20], Loss: 0.0177\n",
      "Epoch [12/20], Loss: 0.0181\n",
      "Epoch [12/20], Loss: 0.0189\n",
      "Epoch [12/20], Loss: 0.0196\n",
      "Epoch [12/20], Loss: 0.0200\n",
      "Epoch [12/20], Loss: 0.0200\n",
      "Epoch [12/20], Loss: 0.0202\n",
      "Epoch [12/20], Valid Accuracy: 98.1200, Valid Loss: 0.0741\n",
      "Epoch [13/20], Loss: 0.0151\n",
      "Epoch [13/20], Loss: 0.0164\n",
      "Epoch [13/20], Loss: 0.0176\n",
      "Epoch [13/20], Loss: 0.0166\n",
      "Epoch [13/20], Loss: 0.0162\n",
      "Epoch [13/20], Loss: 0.0190\n",
      "Epoch [13/20], Loss: 0.0190\n",
      "Epoch [13/20], Loss: 0.0192\n",
      "Epoch [13/20], Loss: 0.0211\n",
      "Epoch [13/20], Loss: 0.0214\n",
      "Epoch [13/20], Valid Accuracy: 97.7300, Valid Loss: 0.0848\n",
      "Epoch [14/20], Loss: 0.0194\n",
      "Epoch [14/20], Loss: 0.0192\n",
      "Epoch [14/20], Loss: 0.0194\n",
      "Epoch [14/20], Loss: 0.0178\n",
      "Epoch [14/20], Loss: 0.0196\n",
      "Epoch [14/20], Loss: 0.0195\n",
      "Epoch [14/20], Loss: 0.0198\n",
      "Epoch [14/20], Loss: 0.0191\n",
      "Epoch [14/20], Loss: 0.0195\n",
      "Epoch [14/20], Loss: 0.0196\n",
      "Epoch [14/20], Valid Accuracy: 97.9700, Valid Loss: 0.0848\n",
      "Epoch [15/20], Loss: 0.0107\n",
      "Epoch [15/20], Loss: 0.0122\n",
      "Epoch [15/20], Loss: 0.0126\n",
      "Epoch [15/20], Loss: 0.0119\n",
      "Epoch [15/20], Loss: 0.0119\n",
      "Epoch [15/20], Loss: 0.0127\n",
      "Epoch [15/20], Loss: 0.0137\n",
      "Epoch [15/20], Loss: 0.0146\n",
      "Epoch [15/20], Loss: 0.0161\n",
      "Epoch [15/20], Loss: 0.0165\n",
      "Epoch [15/20], Valid Accuracy: 98.1200, Valid Loss: 0.0707\n",
      "Epoch [16/20], Loss: 0.0150\n",
      "Epoch [16/20], Loss: 0.0210\n",
      "Epoch [16/20], Loss: 0.0209\n",
      "Epoch [16/20], Loss: 0.0205\n",
      "Epoch [16/20], Loss: 0.0192\n",
      "Epoch [16/20], Loss: 0.0191\n",
      "Epoch [16/20], Loss: 0.0190\n",
      "Epoch [16/20], Loss: 0.0196\n",
      "Epoch [16/20], Loss: 0.0195\n",
      "Epoch [16/20], Loss: 0.0197\n",
      "Epoch [16/20], Valid Accuracy: 97.9300, Valid Loss: 0.0729\n",
      "Epoch [17/20], Loss: 0.0147\n",
      "Epoch [17/20], Loss: 0.0135\n",
      "Epoch [17/20], Loss: 0.0137\n",
      "Epoch [17/20], Loss: 0.0136\n",
      "Epoch [17/20], Loss: 0.0142\n",
      "Epoch [17/20], Loss: 0.0149\n",
      "Epoch [17/20], Loss: 0.0148\n",
      "Epoch [17/20], Loss: 0.0163\n",
      "Epoch [17/20], Loss: 0.0162\n",
      "Epoch [17/20], Loss: 0.0163\n",
      "Epoch [17/20], Valid Accuracy: 98.0300, Valid Loss: 0.0734\n",
      "Epoch [18/20], Loss: 0.0166\n",
      "Epoch [18/20], Loss: 0.0151\n",
      "Epoch [18/20], Loss: 0.0148\n",
      "Epoch [18/20], Loss: 0.0148\n",
      "Epoch [18/20], Loss: 0.0167\n",
      "Epoch [18/20], Loss: 0.0174\n",
      "Epoch [18/20], Loss: 0.0173\n",
      "Epoch [18/20], Loss: 0.0172\n",
      "Epoch [18/20], Loss: 0.0174\n",
      "Epoch [18/20], Loss: 0.0173\n",
      "Epoch [18/20], Valid Accuracy: 97.8000, Valid Loss: 0.0776\n",
      "Epoch [19/20], Loss: 0.0124\n",
      "Epoch [19/20], Loss: 0.0139\n",
      "Epoch [19/20], Loss: 0.0155\n",
      "Epoch [19/20], Loss: 0.0155\n",
      "Epoch [19/20], Loss: 0.0156\n",
      "Epoch [19/20], Loss: 0.0155\n",
      "Epoch [19/20], Loss: 0.0161\n",
      "Epoch [19/20], Loss: 0.0164\n",
      "Epoch [19/20], Loss: 0.0171\n",
      "Epoch [19/20], Loss: 0.0171\n",
      "Epoch [19/20], Valid Accuracy: 98.0200, Valid Loss: 0.0793\n",
      "Epoch [20/20], Loss: 0.0120\n",
      "Epoch [20/20], Loss: 0.0114\n",
      "Epoch [20/20], Loss: 0.0112\n",
      "Epoch [20/20], Loss: 0.0132\n",
      "Epoch [20/20], Loss: 0.0144\n",
      "Epoch [20/20], Loss: 0.0155\n",
      "Epoch [20/20], Loss: 0.0159\n",
      "Epoch [20/20], Loss: 0.0163\n",
      "Epoch [20/20], Loss: 0.0163\n",
      "Epoch [20/20], Loss: 0.0163\n",
      "Epoch [20/20], Valid Accuracy: 97.9200, Valid Loss: 0.0801\n",
      "Epoch [1/20], Loss: 0.5579\n",
      "Epoch [1/20], Loss: 0.4259\n",
      "Epoch [1/20], Loss: 0.3625\n",
      "Epoch [1/20], Loss: 0.3195\n",
      "Epoch [1/20], Loss: 0.2924\n",
      "Epoch [1/20], Loss: 0.2704\n",
      "Epoch [1/20], Loss: 0.2543\n",
      "Epoch [1/20], Loss: 0.2409\n",
      "Epoch [1/20], Loss: 0.2288\n",
      "Epoch [1/20], Loss: 0.2241\n",
      "Epoch [1/20], Valid Accuracy: 96.2000, Valid Loss: 0.1280\n",
      "Epoch [2/20], Loss: 0.1102\n",
      "Epoch [2/20], Loss: 0.1108\n",
      "Epoch [2/20], Loss: 0.1077\n",
      "Epoch [2/20], Loss: 0.1089\n",
      "Epoch [2/20], Loss: 0.1078\n",
      "Epoch [2/20], Loss: 0.1080\n",
      "Epoch [2/20], Loss: 0.1075\n",
      "Epoch [2/20], Loss: 0.1076\n",
      "Epoch [2/20], Loss: 0.1084\n",
      "Epoch [2/20], Loss: 0.1078\n",
      "Epoch [2/20], Valid Accuracy: 96.8600, Valid Loss: 0.1028\n",
      "Epoch [3/20], Loss: 0.0847\n",
      "Epoch [3/20], Loss: 0.0830\n",
      "Epoch [3/20], Loss: 0.0844\n",
      "Epoch [3/20], Loss: 0.0868\n",
      "Epoch [3/20], Loss: 0.0861\n",
      "Epoch [3/20], Loss: 0.0849\n",
      "Epoch [3/20], Loss: 0.0859\n",
      "Epoch [3/20], Loss: 0.0872\n",
      "Epoch [3/20], Loss: 0.0873\n",
      "Epoch [3/20], Loss: 0.0877\n",
      "Epoch [3/20], Valid Accuracy: 97.3100, Valid Loss: 0.0889\n",
      "Epoch [4/20], Loss: 0.0710\n",
      "Epoch [4/20], Loss: 0.0736\n",
      "Epoch [4/20], Loss: 0.0722\n",
      "Epoch [4/20], Loss: 0.0735\n",
      "Epoch [4/20], Loss: 0.0754\n",
      "Epoch [4/20], Loss: 0.0755\n",
      "Epoch [4/20], Loss: 0.0770\n",
      "Epoch [4/20], Loss: 0.0783\n",
      "Epoch [4/20], Loss: 0.0786\n",
      "Epoch [4/20], Loss: 0.0786\n",
      "Epoch [4/20], Valid Accuracy: 97.5700, Valid Loss: 0.0796\n",
      "Epoch [5/20], Loss: 0.0679\n",
      "Epoch [5/20], Loss: 0.0668\n",
      "Epoch [5/20], Loss: 0.0675\n",
      "Epoch [5/20], Loss: 0.0675\n",
      "Epoch [5/20], Loss: 0.0691\n",
      "Epoch [5/20], Loss: 0.0691\n",
      "Epoch [5/20], Loss: 0.0695\n",
      "Epoch [5/20], Loss: 0.0700\n",
      "Epoch [5/20], Loss: 0.0714\n",
      "Epoch [5/20], Loss: 0.0716\n",
      "Epoch [5/20], Valid Accuracy: 97.0400, Valid Loss: 0.0954\n",
      "Epoch [6/20], Loss: 0.0610\n",
      "Epoch [6/20], Loss: 0.0606\n",
      "Epoch [6/20], Loss: 0.0619\n",
      "Epoch [6/20], Loss: 0.0662\n",
      "Epoch [6/20], Loss: 0.0676\n",
      "Epoch [6/20], Loss: 0.0678\n",
      "Epoch [6/20], Loss: 0.0685\n",
      "Epoch [6/20], Loss: 0.0691\n",
      "Epoch [6/20], Loss: 0.0696\n",
      "Epoch [6/20], Loss: 0.0697\n",
      "Epoch [6/20], Valid Accuracy: 97.3000, Valid Loss: 0.0855\n",
      "Epoch [7/20], Loss: 0.0509\n",
      "Epoch [7/20], Loss: 0.0566\n",
      "Epoch [7/20], Loss: 0.0606\n",
      "Epoch [7/20], Loss: 0.0601\n",
      "Epoch [7/20], Loss: 0.0611\n",
      "Epoch [7/20], Loss: 0.0641\n",
      "Epoch [7/20], Loss: 0.0646\n",
      "Epoch [7/20], Loss: 0.0638\n",
      "Epoch [7/20], Loss: 0.0653\n",
      "Epoch [7/20], Loss: 0.0657\n",
      "Epoch [7/20], Valid Accuracy: 97.1500, Valid Loss: 0.0907\n",
      "Epoch [8/20], Loss: 0.0487\n",
      "Epoch [8/20], Loss: 0.0519\n",
      "Epoch [8/20], Loss: 0.0534\n",
      "Epoch [8/20], Loss: 0.0563\n",
      "Epoch [8/20], Loss: 0.0577\n",
      "Epoch [8/20], Loss: 0.0577\n",
      "Epoch [8/20], Loss: 0.0587\n",
      "Epoch [8/20], Loss: 0.0609\n",
      "Epoch [8/20], Loss: 0.0612\n",
      "Epoch [8/20], Loss: 0.0613\n",
      "Epoch [8/20], Valid Accuracy: 96.6500, Valid Loss: 0.1071\n",
      "Epoch [9/20], Loss: 0.0520\n",
      "Epoch [9/20], Loss: 0.0525\n",
      "Epoch [9/20], Loss: 0.0538\n",
      "Epoch [9/20], Loss: 0.0539\n",
      "Epoch [9/20], Loss: 0.0551\n",
      "Epoch [9/20], Loss: 0.0569\n",
      "Epoch [9/20], Loss: 0.0589\n",
      "Epoch [9/20], Loss: 0.0603\n",
      "Epoch [9/20], Loss: 0.0613\n",
      "Epoch [9/20], Loss: 0.0620\n",
      "Epoch [9/20], Valid Accuracy: 97.5100, Valid Loss: 0.0762\n",
      "Epoch [10/20], Loss: 0.0495\n",
      "Epoch [10/20], Loss: 0.0493\n",
      "Epoch [10/20], Loss: 0.0491\n",
      "Epoch [10/20], Loss: 0.0502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.0517\n",
      "Epoch [10/20], Loss: 0.0539\n",
      "Epoch [10/20], Loss: 0.0554\n",
      "Epoch [10/20], Loss: 0.0563\n",
      "Epoch [10/20], Loss: 0.0582\n",
      "Epoch [10/20], Loss: 0.0585\n",
      "Epoch [10/20], Valid Accuracy: 97.6500, Valid Loss: 0.0797\n",
      "Epoch [11/20], Loss: 0.0462\n",
      "Epoch [11/20], Loss: 0.0507\n",
      "Epoch [11/20], Loss: 0.0527\n",
      "Epoch [11/20], Loss: 0.0545\n",
      "Epoch [11/20], Loss: 0.0541\n",
      "Epoch [11/20], Loss: 0.0549\n",
      "Epoch [11/20], Loss: 0.0552\n",
      "Epoch [11/20], Loss: 0.0559\n",
      "Epoch [11/20], Loss: 0.0566\n",
      "Epoch [11/20], Loss: 0.0572\n",
      "Epoch [11/20], Valid Accuracy: 97.7100, Valid Loss: 0.0759\n",
      "Epoch [12/20], Loss: 0.0448\n",
      "Epoch [12/20], Loss: 0.0466\n",
      "Epoch [12/20], Loss: 0.0486\n",
      "Epoch [12/20], Loss: 0.0496\n",
      "Epoch [12/20], Loss: 0.0518\n",
      "Epoch [12/20], Loss: 0.0533\n",
      "Epoch [12/20], Loss: 0.0556\n",
      "Epoch [12/20], Loss: 0.0565\n",
      "Epoch [12/20], Loss: 0.0571\n",
      "Epoch [12/20], Loss: 0.0572\n",
      "Epoch [12/20], Valid Accuracy: 97.8200, Valid Loss: 0.0686\n",
      "Epoch [13/20], Loss: 0.0487\n",
      "Epoch [13/20], Loss: 0.0484\n",
      "Epoch [13/20], Loss: 0.0501\n",
      "Epoch [13/20], Loss: 0.0516\n",
      "Epoch [13/20], Loss: 0.0513\n",
      "Epoch [13/20], Loss: 0.0513\n",
      "Epoch [13/20], Loss: 0.0524\n",
      "Epoch [13/20], Loss: 0.0543\n",
      "Epoch [13/20], Loss: 0.0544\n",
      "Epoch [13/20], Loss: 0.0544\n",
      "Epoch [13/20], Valid Accuracy: 97.6500, Valid Loss: 0.0749\n",
      "Epoch [14/20], Loss: 0.0422\n",
      "Epoch [14/20], Loss: 0.0453\n",
      "Epoch [14/20], Loss: 0.0457\n",
      "Epoch [14/20], Loss: 0.0458\n",
      "Epoch [14/20], Loss: 0.0488\n",
      "Epoch [14/20], Loss: 0.0501\n",
      "Epoch [14/20], Loss: 0.0520\n",
      "Epoch [14/20], Loss: 0.0540\n",
      "Epoch [14/20], Loss: 0.0549\n",
      "Epoch [14/20], Loss: 0.0551\n",
      "Epoch [14/20], Valid Accuracy: 97.6400, Valid Loss: 0.0780\n",
      "Epoch [15/20], Loss: 0.0456\n",
      "Epoch [15/20], Loss: 0.0485\n",
      "Epoch [15/20], Loss: 0.0477\n",
      "Epoch [15/20], Loss: 0.0468\n",
      "Epoch [15/20], Loss: 0.0478\n",
      "Epoch [15/20], Loss: 0.0497\n",
      "Epoch [15/20], Loss: 0.0499\n",
      "Epoch [15/20], Loss: 0.0509\n",
      "Epoch [15/20], Loss: 0.0522\n",
      "Epoch [15/20], Loss: 0.0524\n",
      "Epoch [15/20], Valid Accuracy: 97.6300, Valid Loss: 0.0748\n",
      "Epoch [16/20], Loss: 0.0398\n",
      "Epoch [16/20], Loss: 0.0455\n",
      "Epoch [16/20], Loss: 0.0475\n",
      "Epoch [16/20], Loss: 0.0486\n",
      "Epoch [16/20], Loss: 0.0497\n",
      "Epoch [16/20], Loss: 0.0514\n",
      "Epoch [16/20], Loss: 0.0518\n",
      "Epoch [16/20], Loss: 0.0526\n",
      "Epoch [16/20], Loss: 0.0536\n",
      "Epoch [16/20], Loss: 0.0538\n",
      "Epoch [16/20], Valid Accuracy: 97.3800, Valid Loss: 0.0838\n",
      "Epoch [17/20], Loss: 0.0437\n",
      "Epoch [17/20], Loss: 0.0417\n",
      "Epoch [17/20], Loss: 0.0448\n",
      "Epoch [17/20], Loss: 0.0448\n",
      "Epoch [17/20], Loss: 0.0463\n",
      "Epoch [17/20], Loss: 0.0477\n",
      "Epoch [17/20], Loss: 0.0499\n",
      "Epoch [17/20], Loss: 0.0507\n",
      "Epoch [17/20], Loss: 0.0517\n",
      "Epoch [17/20], Loss: 0.0517\n",
      "Epoch [17/20], Valid Accuracy: 97.9000, Valid Loss: 0.0685\n",
      "Epoch [18/20], Loss: 0.0465\n",
      "Epoch [18/20], Loss: 0.0425\n",
      "Epoch [18/20], Loss: 0.0433\n",
      "Epoch [18/20], Loss: 0.0442\n",
      "Epoch [18/20], Loss: 0.0466\n",
      "Epoch [18/20], Loss: 0.0471\n",
      "Epoch [18/20], Loss: 0.0493\n",
      "Epoch [18/20], Loss: 0.0506\n",
      "Epoch [18/20], Loss: 0.0514\n",
      "Epoch [18/20], Loss: 0.0517\n",
      "Epoch [18/20], Valid Accuracy: 98.0400, Valid Loss: 0.0638\n",
      "Epoch [19/20], Loss: 0.0395\n",
      "Epoch [19/20], Loss: 0.0408\n",
      "Epoch [19/20], Loss: 0.0439\n",
      "Epoch [19/20], Loss: 0.0447\n",
      "Epoch [19/20], Loss: 0.0461\n",
      "Epoch [19/20], Loss: 0.0480\n",
      "Epoch [19/20], Loss: 0.0493\n",
      "Epoch [19/20], Loss: 0.0510\n",
      "Epoch [19/20], Loss: 0.0514\n",
      "Epoch [19/20], Loss: 0.0519\n",
      "Epoch [19/20], Valid Accuracy: 97.5500, Valid Loss: 0.0796\n",
      "Epoch [20/20], Loss: 0.0455\n",
      "Epoch [20/20], Loss: 0.0434\n",
      "Epoch [20/20], Loss: 0.0427\n",
      "Epoch [20/20], Loss: 0.0453\n",
      "Epoch [20/20], Loss: 0.0483\n",
      "Epoch [20/20], Loss: 0.0484\n",
      "Epoch [20/20], Loss: 0.0497\n",
      "Epoch [20/20], Loss: 0.0512\n",
      "Epoch [20/20], Loss: 0.0514\n",
      "Epoch [20/20], Loss: 0.0514\n",
      "Epoch [20/20], Valid Accuracy: 97.8000, Valid Loss: 0.0688\n",
      "Epoch [1/20], Loss: 0.5583\n",
      "Epoch [1/20], Loss: 0.4354\n",
      "Epoch [1/20], Loss: 0.3785\n",
      "Epoch [1/20], Loss: 0.3491\n",
      "Epoch [1/20], Loss: 0.3277\n",
      "Epoch [1/20], Loss: 0.3134\n",
      "Epoch [1/20], Loss: 0.3022\n",
      "Epoch [1/20], Loss: 0.2902\n",
      "Epoch [1/20], Loss: 0.2813\n",
      "Epoch [1/20], Loss: 0.2770\n",
      "Epoch [1/20], Valid Accuracy: 94.1500, Valid Loss: 0.2048\n",
      "Epoch [2/20], Loss: 0.1939\n",
      "Epoch [2/20], Loss: 0.1942\n",
      "Epoch [2/20], Loss: 0.1956\n",
      "Epoch [2/20], Loss: 0.1973\n",
      "Epoch [2/20], Loss: 0.1983\n",
      "Epoch [2/20], Loss: 0.1974\n",
      "Epoch [2/20], Loss: 0.1963\n",
      "Epoch [2/20], Loss: 0.1952\n",
      "Epoch [2/20], Loss: 0.1948\n",
      "Epoch [2/20], Loss: 0.1943\n",
      "Epoch [2/20], Valid Accuracy: 94.6700, Valid Loss: 0.1858\n",
      "Epoch [3/20], Loss: 0.1824\n",
      "Epoch [3/20], Loss: 0.1764\n",
      "Epoch [3/20], Loss: 0.1740\n",
      "Epoch [3/20], Loss: 0.1752\n",
      "Epoch [3/20], Loss: 0.1794\n",
      "Epoch [3/20], Loss: 0.1800\n",
      "Epoch [3/20], Loss: 0.1807\n",
      "Epoch [3/20], Loss: 0.1807\n",
      "Epoch [3/20], Loss: 0.1802\n",
      "Epoch [3/20], Loss: 0.1807\n",
      "Epoch [3/20], Valid Accuracy: 94.9000, Valid Loss: 0.1747\n",
      "Epoch [4/20], Loss: 0.1756\n",
      "Epoch [4/20], Loss: 0.1755\n",
      "Epoch [4/20], Loss: 0.1753\n",
      "Epoch [4/20], Loss: 0.1732\n",
      "Epoch [4/20], Loss: 0.1747\n",
      "Epoch [4/20], Loss: 0.1755\n",
      "Epoch [4/20], Loss: 0.1737\n",
      "Epoch [4/20], Loss: 0.1739\n",
      "Epoch [4/20], Loss: 0.1746\n",
      "Epoch [4/20], Loss: 0.1752\n",
      "Epoch [4/20], Valid Accuracy: 95.9600, Valid Loss: 0.1536\n",
      "Epoch [5/20], Loss: 0.1588\n",
      "Epoch [5/20], Loss: 0.1681\n",
      "Epoch [5/20], Loss: 0.1677\n",
      "Epoch [5/20], Loss: 0.1673\n",
      "Epoch [5/20], Loss: 0.1687\n",
      "Epoch [5/20], Loss: 0.1689\n",
      "Epoch [5/20], Loss: 0.1689\n",
      "Epoch [5/20], Loss: 0.1692\n",
      "Epoch [5/20], Loss: 0.1692\n",
      "Epoch [5/20], Loss: 0.1690\n",
      "Epoch [5/20], Valid Accuracy: 95.5600, Valid Loss: 0.1603\n",
      "Epoch [6/20], Loss: 0.1715\n",
      "Epoch [6/20], Loss: 0.1692\n",
      "Epoch [6/20], Loss: 0.1684\n",
      "Epoch [6/20], Loss: 0.1662\n",
      "Epoch [6/20], Loss: 0.1667\n",
      "Epoch [6/20], Loss: 0.1660\n",
      "Epoch [6/20], Loss: 0.1676\n",
      "Epoch [6/20], Loss: 0.1680\n",
      "Epoch [6/20], Loss: 0.1675\n",
      "Epoch [6/20], Loss: 0.1672\n",
      "Epoch [6/20], Valid Accuracy: 96.0400, Valid Loss: 0.1481\n",
      "Epoch [7/20], Loss: 0.1639\n",
      "Epoch [7/20], Loss: 0.1670\n",
      "Epoch [7/20], Loss: 0.1665\n",
      "Epoch [7/20], Loss: 0.1676\n",
      "Epoch [7/20], Loss: 0.1668\n",
      "Epoch [7/20], Loss: 0.1664\n",
      "Epoch [7/20], Loss: 0.1684\n",
      "Epoch [7/20], Loss: 0.1674\n",
      "Epoch [7/20], Loss: 0.1659\n",
      "Epoch [7/20], Loss: 0.1662\n",
      "Epoch [7/20], Valid Accuracy: 96.0700, Valid Loss: 0.1509\n",
      "Epoch [8/20], Loss: 0.1503\n",
      "Epoch [8/20], Loss: 0.1555\n",
      "Epoch [8/20], Loss: 0.1553\n",
      "Epoch [8/20], Loss: 0.1555\n",
      "Epoch [8/20], Loss: 0.1599\n",
      "Epoch [8/20], Loss: 0.1609\n",
      "Epoch [8/20], Loss: 0.1610\n",
      "Epoch [8/20], Loss: 0.1633\n",
      "Epoch [8/20], Loss: 0.1633\n",
      "Epoch [8/20], Loss: 0.1632\n",
      "Epoch [8/20], Valid Accuracy: 95.8100, Valid Loss: 0.1516\n",
      "Epoch [9/20], Loss: 0.1517\n",
      "Epoch [9/20], Loss: 0.1502\n",
      "Epoch [9/20], Loss: 0.1558\n",
      "Epoch [9/20], Loss: 0.1550\n",
      "Epoch [9/20], Loss: 0.1578\n",
      "Epoch [9/20], Loss: 0.1593\n",
      "Epoch [9/20], Loss: 0.1599\n",
      "Epoch [9/20], Loss: 0.1592\n",
      "Epoch [9/20], Loss: 0.1615\n",
      "Epoch [9/20], Loss: 0.1607\n",
      "Epoch [9/20], Valid Accuracy: 95.4500, Valid Loss: 0.1561\n",
      "Epoch [10/20], Loss: 0.1563\n",
      "Epoch [10/20], Loss: 0.1586\n",
      "Epoch [10/20], Loss: 0.1578\n",
      "Epoch [10/20], Loss: 0.1569\n",
      "Epoch [10/20], Loss: 0.1582\n",
      "Epoch [10/20], Loss: 0.1591\n",
      "Epoch [10/20], Loss: 0.1580\n",
      "Epoch [10/20], Loss: 0.1598\n",
      "Epoch [10/20], Loss: 0.1598\n",
      "Epoch [10/20], Loss: 0.1597\n",
      "Epoch [10/20], Valid Accuracy: 95.6800, Valid Loss: 0.1531\n",
      "Epoch [11/20], Loss: 0.1510\n",
      "Epoch [11/20], Loss: 0.1555\n",
      "Epoch [11/20], Loss: 0.1621\n",
      "Epoch [11/20], Loss: 0.1614\n",
      "Epoch [11/20], Loss: 0.1606\n",
      "Epoch [11/20], Loss: 0.1593\n",
      "Epoch [11/20], Loss: 0.1596\n",
      "Epoch [11/20], Loss: 0.1602\n",
      "Epoch [11/20], Loss: 0.1594\n",
      "Epoch [11/20], Loss: 0.1595\n",
      "Epoch [11/20], Valid Accuracy: 95.9100, Valid Loss: 0.1499\n",
      "Epoch [12/20], Loss: 0.1569\n",
      "Epoch [12/20], Loss: 0.1584\n",
      "Epoch [12/20], Loss: 0.1568\n",
      "Epoch [12/20], Loss: 0.1605\n",
      "Epoch [12/20], Loss: 0.1595\n",
      "Epoch [12/20], Loss: 0.1591\n",
      "Epoch [12/20], Loss: 0.1581\n",
      "Epoch [12/20], Loss: 0.1582\n",
      "Epoch [12/20], Loss: 0.1582\n",
      "Epoch [12/20], Loss: 0.1586\n",
      "Epoch [12/20], Valid Accuracy: 95.5300, Valid Loss: 0.1565\n",
      "Epoch [13/20], Loss: 0.1474\n",
      "Epoch [13/20], Loss: 0.1533\n",
      "Epoch [13/20], Loss: 0.1555\n",
      "Epoch [13/20], Loss: 0.1550\n",
      "Epoch [13/20], Loss: 0.1556\n",
      "Epoch [13/20], Loss: 0.1550\n",
      "Epoch [13/20], Loss: 0.1572\n",
      "Epoch [13/20], Loss: 0.1578\n",
      "Epoch [13/20], Loss: 0.1572\n",
      "Epoch [13/20], Loss: 0.1570\n",
      "Epoch [13/20], Valid Accuracy: 96.0500, Valid Loss: 0.1520\n",
      "Epoch [14/20], Loss: 0.1583\n",
      "Epoch [14/20], Loss: 0.1552\n",
      "Epoch [14/20], Loss: 0.1542\n",
      "Epoch [14/20], Loss: 0.1544\n",
      "Epoch [14/20], Loss: 0.1529\n",
      "Epoch [14/20], Loss: 0.1533\n",
      "Epoch [14/20], Loss: 0.1544\n",
      "Epoch [14/20], Loss: 0.1560\n",
      "Epoch [14/20], Loss: 0.1564\n",
      "Epoch [14/20], Loss: 0.1569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Valid Accuracy: 96.3400, Valid Loss: 0.1409\n",
      "Epoch [15/20], Loss: 0.1612\n",
      "Epoch [15/20], Loss: 0.1583\n",
      "Epoch [15/20], Loss: 0.1539\n",
      "Epoch [15/20], Loss: 0.1547\n",
      "Epoch [15/20], Loss: 0.1557\n",
      "Epoch [15/20], Loss: 0.1551\n",
      "Epoch [15/20], Loss: 0.1565\n",
      "Epoch [15/20], Loss: 0.1567\n",
      "Epoch [15/20], Loss: 0.1576\n",
      "Epoch [15/20], Loss: 0.1573\n",
      "Epoch [15/20], Valid Accuracy: 96.0800, Valid Loss: 0.1508\n",
      "Epoch [16/20], Loss: 0.1456\n",
      "Epoch [16/20], Loss: 0.1471\n",
      "Epoch [16/20], Loss: 0.1505\n",
      "Epoch [16/20], Loss: 0.1520\n",
      "Epoch [16/20], Loss: 0.1534\n",
      "Epoch [16/20], Loss: 0.1549\n",
      "Epoch [16/20], Loss: 0.1563\n",
      "Epoch [16/20], Loss: 0.1569\n",
      "Epoch [16/20], Loss: 0.1576\n",
      "Epoch [16/20], Loss: 0.1578\n",
      "Epoch [16/20], Valid Accuracy: 96.1200, Valid Loss: 0.1424\n",
      "Epoch [17/20], Loss: 0.1530\n",
      "Epoch [17/20], Loss: 0.1537\n",
      "Epoch [17/20], Loss: 0.1560\n",
      "Epoch [17/20], Loss: 0.1550\n",
      "Epoch [17/20], Loss: 0.1557\n",
      "Epoch [17/20], Loss: 0.1551\n",
      "Epoch [17/20], Loss: 0.1546\n",
      "Epoch [17/20], Loss: 0.1545\n",
      "Epoch [17/20], Loss: 0.1561\n",
      "Epoch [17/20], Loss: 0.1558\n",
      "Epoch [17/20], Valid Accuracy: 96.3800, Valid Loss: 0.1413\n",
      "Epoch [18/20], Loss: 0.1477\n",
      "Epoch [18/20], Loss: 0.1510\n",
      "Epoch [18/20], Loss: 0.1535\n",
      "Epoch [18/20], Loss: 0.1541\n",
      "Epoch [18/20], Loss: 0.1553\n",
      "Epoch [18/20], Loss: 0.1542\n",
      "Epoch [18/20], Loss: 0.1576\n",
      "Epoch [18/20], Loss: 0.1571\n",
      "Epoch [18/20], Loss: 0.1566\n",
      "Epoch [18/20], Loss: 0.1570\n",
      "Epoch [18/20], Valid Accuracy: 96.1500, Valid Loss: 0.1453\n",
      "Epoch [19/20], Loss: 0.1467\n",
      "Epoch [19/20], Loss: 0.1507\n",
      "Epoch [19/20], Loss: 0.1545\n",
      "Epoch [19/20], Loss: 0.1553\n",
      "Epoch [19/20], Loss: 0.1529\n",
      "Epoch [19/20], Loss: 0.1551\n",
      "Epoch [19/20], Loss: 0.1537\n",
      "Epoch [19/20], Loss: 0.1561\n",
      "Epoch [19/20], Loss: 0.1554\n",
      "Epoch [19/20], Loss: 0.1564\n",
      "Epoch [19/20], Valid Accuracy: 96.0300, Valid Loss: 0.1513\n",
      "Epoch [20/20], Loss: 0.1627\n",
      "Epoch [20/20], Loss: 0.1565\n",
      "Epoch [20/20], Loss: 0.1531\n",
      "Epoch [20/20], Loss: 0.1557\n",
      "Epoch [20/20], Loss: 0.1556\n",
      "Epoch [20/20], Loss: 0.1551\n",
      "Epoch [20/20], Loss: 0.1556\n",
      "Epoch [20/20], Loss: 0.1560\n",
      "Epoch [20/20], Loss: 0.1558\n",
      "Epoch [20/20], Loss: 0.1557\n",
      "Epoch [20/20], Valid Accuracy: 96.1900, Valid Loss: 0.1462\n",
      "Epoch [1/20], Loss: 0.6969\n",
      "Epoch [1/20], Loss: 0.6157\n",
      "Epoch [1/20], Loss: 0.5807\n",
      "Epoch [1/20], Loss: 0.5632\n",
      "Epoch [1/20], Loss: 0.5522\n",
      "Epoch [1/20], Loss: 0.5437\n",
      "Epoch [1/20], Loss: 0.5372\n",
      "Epoch [1/20], Loss: 0.5339\n",
      "Epoch [1/20], Loss: 0.5292\n",
      "Epoch [1/20], Loss: 0.5283\n",
      "Epoch [1/20], Valid Accuracy: 88.2400, Valid Loss: 0.4864\n",
      "Epoch [2/20], Loss: 0.4971\n",
      "Epoch [2/20], Loss: 0.4967\n",
      "Epoch [2/20], Loss: 0.4982\n",
      "Epoch [2/20], Loss: 0.4961\n",
      "Epoch [2/20], Loss: 0.4950\n",
      "Epoch [2/20], Loss: 0.4935\n",
      "Epoch [2/20], Loss: 0.4939\n",
      "Epoch [2/20], Loss: 0.4929\n",
      "Epoch [2/20], Loss: 0.4921\n",
      "Epoch [2/20], Loss: 0.4914\n",
      "Epoch [2/20], Valid Accuracy: 89.5500, Valid Loss: 0.4637\n",
      "Epoch [3/20], Loss: 0.4891\n",
      "Epoch [3/20], Loss: 0.4859\n",
      "Epoch [3/20], Loss: 0.4847\n",
      "Epoch [3/20], Loss: 0.4856\n",
      "Epoch [3/20], Loss: 0.4840\n",
      "Epoch [3/20], Loss: 0.4843\n",
      "Epoch [3/20], Loss: 0.4851\n",
      "Epoch [3/20], Loss: 0.4839\n",
      "Epoch [3/20], Loss: 0.4832\n",
      "Epoch [3/20], Loss: 0.4830\n",
      "Epoch [3/20], Valid Accuracy: 88.0100, Valid Loss: 0.4711\n",
      "Epoch [4/20], Loss: 0.4727\n",
      "Epoch [4/20], Loss: 0.4776\n",
      "Epoch [4/20], Loss: 0.4819\n",
      "Epoch [4/20], Loss: 0.4833\n",
      "Epoch [4/20], Loss: 0.4806\n",
      "Epoch [4/20], Loss: 0.4811\n",
      "Epoch [4/20], Loss: 0.4824\n",
      "Epoch [4/20], Loss: 0.4807\n",
      "Epoch [4/20], Loss: 0.4791\n",
      "Epoch [4/20], Loss: 0.4778\n",
      "Epoch [4/20], Valid Accuracy: 89.3600, Valid Loss: 0.4509\n",
      "Epoch [5/20], Loss: 0.4641\n",
      "Epoch [5/20], Loss: 0.4692\n",
      "Epoch [5/20], Loss: 0.4716\n",
      "Epoch [5/20], Loss: 0.4713\n",
      "Epoch [5/20], Loss: 0.4701\n",
      "Epoch [5/20], Loss: 0.4695\n",
      "Epoch [5/20], Loss: 0.4698\n",
      "Epoch [5/20], Loss: 0.4704\n",
      "Epoch [5/20], Loss: 0.4722\n",
      "Epoch [5/20], Loss: 0.4728\n",
      "Epoch [5/20], Valid Accuracy: 89.3600, Valid Loss: 0.4463\n",
      "Epoch [6/20], Loss: 0.4595\n",
      "Epoch [6/20], Loss: 0.4695\n",
      "Epoch [6/20], Loss: 0.4712\n",
      "Epoch [6/20], Loss: 0.4721\n",
      "Epoch [6/20], Loss: 0.4726\n",
      "Epoch [6/20], Loss: 0.4715\n",
      "Epoch [6/20], Loss: 0.4727\n",
      "Epoch [6/20], Loss: 0.4728\n",
      "Epoch [6/20], Loss: 0.4725\n",
      "Epoch [6/20], Loss: 0.4718\n",
      "Epoch [6/20], Valid Accuracy: 88.8600, Valid Loss: 0.4598\n",
      "Epoch [7/20], Loss: 0.4709\n",
      "Epoch [7/20], Loss: 0.4708\n",
      "Epoch [7/20], Loss: 0.4726\n",
      "Epoch [7/20], Loss: 0.4698\n",
      "Epoch [7/20], Loss: 0.4715\n",
      "Epoch [7/20], Loss: 0.4705\n",
      "Epoch [7/20], Loss: 0.4700\n",
      "Epoch [7/20], Loss: 0.4684\n",
      "Epoch [7/20], Loss: 0.4687\n",
      "Epoch [7/20], Loss: 0.4686\n",
      "Epoch [7/20], Valid Accuracy: 90.0000, Valid Loss: 0.4450\n",
      "Epoch [8/20], Loss: 0.4517\n",
      "Epoch [8/20], Loss: 0.4614\n",
      "Epoch [8/20], Loss: 0.4638\n",
      "Epoch [8/20], Loss: 0.4691\n",
      "Epoch [8/20], Loss: 0.4672\n",
      "Epoch [8/20], Loss: 0.4688\n",
      "Epoch [8/20], Loss: 0.4691\n",
      "Epoch [8/20], Loss: 0.4687\n",
      "Epoch [8/20], Loss: 0.4683\n",
      "Epoch [8/20], Loss: 0.4683\n",
      "Epoch [8/20], Valid Accuracy: 89.7700, Valid Loss: 0.4437\n",
      "Epoch [9/20], Loss: 0.4740\n",
      "Epoch [9/20], Loss: 0.4691\n",
      "Epoch [9/20], Loss: 0.4676\n",
      "Epoch [9/20], Loss: 0.4676\n",
      "Epoch [9/20], Loss: 0.4683\n",
      "Epoch [9/20], Loss: 0.4691\n",
      "Epoch [9/20], Loss: 0.4684\n",
      "Epoch [9/20], Loss: 0.4683\n",
      "Epoch [9/20], Loss: 0.4679\n",
      "Epoch [9/20], Loss: 0.4671\n",
      "Epoch [9/20], Valid Accuracy: 89.2300, Valid Loss: 0.4550\n",
      "Epoch [10/20], Loss: 0.4585\n",
      "Epoch [10/20], Loss: 0.4663\n",
      "Epoch [10/20], Loss: 0.4671\n",
      "Epoch [10/20], Loss: 0.4635\n",
      "Epoch [10/20], Loss: 0.4639\n",
      "Epoch [10/20], Loss: 0.4660\n",
      "Epoch [10/20], Loss: 0.4655\n",
      "Epoch [10/20], Loss: 0.4657\n",
      "Epoch [10/20], Loss: 0.4655\n",
      "Epoch [10/20], Loss: 0.4653\n",
      "Epoch [10/20], Valid Accuracy: 89.4200, Valid Loss: 0.4646\n",
      "Epoch [11/20], Loss: 0.4765\n",
      "Epoch [11/20], Loss: 0.4712\n",
      "Epoch [11/20], Loss: 0.4708\n",
      "Epoch [11/20], Loss: 0.4711\n",
      "Epoch [11/20], Loss: 0.4675\n",
      "Epoch [11/20], Loss: 0.4671\n",
      "Epoch [11/20], Loss: 0.4660\n",
      "Epoch [11/20], Loss: 0.4667\n",
      "Epoch [11/20], Loss: 0.4655\n",
      "Epoch [11/20], Loss: 0.4657\n",
      "Epoch [11/20], Valid Accuracy: 89.6500, Valid Loss: 0.4463\n",
      "Epoch [12/20], Loss: 0.4622\n",
      "Epoch [12/20], Loss: 0.4665\n",
      "Epoch [12/20], Loss: 0.4663\n",
      "Epoch [12/20], Loss: 0.4631\n",
      "Epoch [12/20], Loss: 0.4650\n",
      "Epoch [12/20], Loss: 0.4642\n",
      "Epoch [12/20], Loss: 0.4637\n",
      "Epoch [12/20], Loss: 0.4647\n",
      "Epoch [12/20], Loss: 0.4652\n",
      "Epoch [12/20], Loss: 0.4649\n",
      "Epoch [12/20], Valid Accuracy: 89.4900, Valid Loss: 0.4388\n",
      "Epoch [13/20], Loss: 0.4780\n",
      "Epoch [13/20], Loss: 0.4631\n",
      "Epoch [13/20], Loss: 0.4626\n",
      "Epoch [13/20], Loss: 0.4646\n",
      "Epoch [13/20], Loss: 0.4633\n",
      "Epoch [13/20], Loss: 0.4626\n",
      "Epoch [13/20], Loss: 0.4626\n",
      "Epoch [13/20], Loss: 0.4629\n",
      "Epoch [13/20], Loss: 0.4635\n",
      "Epoch [13/20], Loss: 0.4637\n",
      "Epoch [13/20], Valid Accuracy: 90.0300, Valid Loss: 0.4424\n",
      "Epoch [14/20], Loss: 0.4524\n",
      "Epoch [14/20], Loss: 0.4563\n",
      "Epoch [14/20], Loss: 0.4598\n",
      "Epoch [14/20], Loss: 0.4621\n",
      "Epoch [14/20], Loss: 0.4620\n",
      "Epoch [14/20], Loss: 0.4627\n",
      "Epoch [14/20], Loss: 0.4636\n",
      "Epoch [14/20], Loss: 0.4635\n",
      "Epoch [14/20], Loss: 0.4630\n",
      "Epoch [14/20], Loss: 0.4626\n",
      "Epoch [14/20], Valid Accuracy: 90.2200, Valid Loss: 0.4358\n",
      "Epoch [15/20], Loss: 0.4747\n",
      "Epoch [15/20], Loss: 0.4648\n",
      "Epoch [15/20], Loss: 0.4650\n",
      "Epoch [15/20], Loss: 0.4637\n",
      "Epoch [15/20], Loss: 0.4624\n",
      "Epoch [15/20], Loss: 0.4655\n",
      "Epoch [15/20], Loss: 0.4640\n",
      "Epoch [15/20], Loss: 0.4639\n",
      "Epoch [15/20], Loss: 0.4638\n",
      "Epoch [15/20], Loss: 0.4630\n",
      "Epoch [15/20], Valid Accuracy: 89.8500, Valid Loss: 0.4359\n",
      "Epoch [16/20], Loss: 0.4666\n",
      "Epoch [16/20], Loss: 0.4574\n",
      "Epoch [16/20], Loss: 0.4564\n",
      "Epoch [16/20], Loss: 0.4608\n",
      "Epoch [16/20], Loss: 0.4629\n",
      "Epoch [16/20], Loss: 0.4621\n",
      "Epoch [16/20], Loss: 0.4630\n",
      "Epoch [16/20], Loss: 0.4624\n",
      "Epoch [16/20], Loss: 0.4619\n",
      "Epoch [16/20], Loss: 0.4615\n",
      "Epoch [16/20], Valid Accuracy: 89.5500, Valid Loss: 0.4398\n",
      "Epoch [17/20], Loss: 0.4550\n",
      "Epoch [17/20], Loss: 0.4559\n",
      "Epoch [17/20], Loss: 0.4583\n",
      "Epoch [17/20], Loss: 0.4574\n",
      "Epoch [17/20], Loss: 0.4590\n",
      "Epoch [17/20], Loss: 0.4592\n",
      "Epoch [17/20], Loss: 0.4596\n",
      "Epoch [17/20], Loss: 0.4604\n",
      "Epoch [17/20], Loss: 0.4620\n",
      "Epoch [17/20], Loss: 0.4616\n",
      "Epoch [17/20], Valid Accuracy: 89.9900, Valid Loss: 0.4371\n",
      "Epoch [18/20], Loss: 0.4595\n",
      "Epoch [18/20], Loss: 0.4516\n",
      "Epoch [18/20], Loss: 0.4544\n",
      "Epoch [18/20], Loss: 0.4570\n",
      "Epoch [18/20], Loss: 0.4578\n",
      "Epoch [18/20], Loss: 0.4604\n",
      "Epoch [18/20], Loss: 0.4624\n",
      "Epoch [18/20], Loss: 0.4632\n",
      "Epoch [18/20], Loss: 0.4621\n",
      "Epoch [18/20], Loss: 0.4614\n",
      "Epoch [18/20], Valid Accuracy: 90.0200, Valid Loss: 0.4362\n",
      "Epoch [19/20], Loss: 0.4509\n",
      "Epoch [19/20], Loss: 0.4525\n",
      "Epoch [19/20], Loss: 0.4539\n",
      "Epoch [19/20], Loss: 0.4537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.4551\n",
      "Epoch [19/20], Loss: 0.4571\n",
      "Epoch [19/20], Loss: 0.4590\n",
      "Epoch [19/20], Loss: 0.4596\n",
      "Epoch [19/20], Loss: 0.4613\n",
      "Epoch [19/20], Loss: 0.4608\n",
      "Epoch [19/20], Valid Accuracy: 89.9600, Valid Loss: 0.4368\n",
      "Epoch [20/20], Loss: 0.4712\n",
      "Epoch [20/20], Loss: 0.4728\n",
      "Epoch [20/20], Loss: 0.4654\n",
      "Epoch [20/20], Loss: 0.4638\n",
      "Epoch [20/20], Loss: 0.4645\n",
      "Epoch [20/20], Loss: 0.4629\n",
      "Epoch [20/20], Loss: 0.4637\n",
      "Epoch [20/20], Loss: 0.4634\n",
      "Epoch [20/20], Loss: 0.4619\n",
      "Epoch [20/20], Loss: 0.4610\n",
      "Epoch [20/20], Valid Accuracy: 89.3100, Valid Loss: 0.4520\n",
      "Epoch [1/20], Loss: 1.0034\n",
      "Epoch [1/20], Loss: 0.9186\n",
      "Epoch [1/20], Loss: 0.9023\n",
      "Epoch [1/20], Loss: 0.8898\n",
      "Epoch [1/20], Loss: 0.8820\n",
      "Epoch [1/20], Loss: 0.8767\n",
      "Epoch [1/20], Loss: 0.8712\n",
      "Epoch [1/20], Loss: 0.8677\n",
      "Epoch [1/20], Loss: 0.8648\n",
      "Epoch [1/20], Loss: 0.8634\n",
      "Epoch [1/20], Valid Accuracy: 80.6500, Valid Loss: 0.8440\n",
      "Epoch [2/20], Loss: 0.8545\n",
      "Epoch [2/20], Loss: 0.8492\n",
      "Epoch [2/20], Loss: 0.8456\n",
      "Epoch [2/20], Loss: 0.8405\n",
      "Epoch [2/20], Loss: 0.8396\n",
      "Epoch [2/20], Loss: 0.8389\n",
      "Epoch [2/20], Loss: 0.8395\n",
      "Epoch [2/20], Loss: 0.8386\n",
      "Epoch [2/20], Loss: 0.8389\n",
      "Epoch [2/20], Loss: 0.8385\n",
      "Epoch [2/20], Valid Accuracy: 81.7200, Valid Loss: 0.8367\n",
      "Epoch [3/20], Loss: 0.8410\n",
      "Epoch [3/20], Loss: 0.8305\n",
      "Epoch [3/20], Loss: 0.8359\n",
      "Epoch [3/20], Loss: 0.8354\n",
      "Epoch [3/20], Loss: 0.8373\n",
      "Epoch [3/20], Loss: 0.8343\n",
      "Epoch [3/20], Loss: 0.8326\n",
      "Epoch [3/20], Loss: 0.8327\n",
      "Epoch [3/20], Loss: 0.8315\n",
      "Epoch [3/20], Loss: 0.8320\n",
      "Epoch [3/20], Valid Accuracy: 85.4300, Valid Loss: 0.7997\n",
      "Epoch [4/20], Loss: 0.8194\n",
      "Epoch [4/20], Loss: 0.8251\n",
      "Epoch [4/20], Loss: 0.8294\n",
      "Epoch [4/20], Loss: 0.8300\n",
      "Epoch [4/20], Loss: 0.8288\n",
      "Epoch [4/20], Loss: 0.8261\n",
      "Epoch [4/20], Loss: 0.8255\n",
      "Epoch [4/20], Loss: 0.8249\n",
      "Epoch [4/20], Loss: 0.8250\n",
      "Epoch [4/20], Loss: 0.8245\n",
      "Epoch [4/20], Valid Accuracy: 83.2900, Valid Loss: 0.8015\n",
      "Epoch [5/20], Loss: 0.8301\n",
      "Epoch [5/20], Loss: 0.8353\n",
      "Epoch [5/20], Loss: 0.8342\n",
      "Epoch [5/20], Loss: 0.8276\n",
      "Epoch [5/20], Loss: 0.8299\n",
      "Epoch [5/20], Loss: 0.8277\n",
      "Epoch [5/20], Loss: 0.8254\n",
      "Epoch [5/20], Loss: 0.8259\n",
      "Epoch [5/20], Loss: 0.8229\n",
      "Epoch [5/20], Loss: 0.8226\n",
      "Epoch [5/20], Valid Accuracy: 85.1900, Valid Loss: 0.7888\n",
      "Epoch [6/20], Loss: 0.8126\n",
      "Epoch [6/20], Loss: 0.8162\n",
      "Epoch [6/20], Loss: 0.8194\n",
      "Epoch [6/20], Loss: 0.8186\n",
      "Epoch [6/20], Loss: 0.8169\n",
      "Epoch [6/20], Loss: 0.8148\n",
      "Epoch [6/20], Loss: 0.8159\n",
      "Epoch [6/20], Loss: 0.8171\n",
      "Epoch [6/20], Loss: 0.8161\n",
      "Epoch [6/20], Loss: 0.8177\n",
      "Epoch [6/20], Valid Accuracy: 86.8500, Valid Loss: 0.7873\n",
      "Epoch [7/20], Loss: 0.8110\n",
      "Epoch [7/20], Loss: 0.8171\n",
      "Epoch [7/20], Loss: 0.8178\n",
      "Epoch [7/20], Loss: 0.8140\n",
      "Epoch [7/20], Loss: 0.8151\n",
      "Epoch [7/20], Loss: 0.8140\n",
      "Epoch [7/20], Loss: 0.8142\n",
      "Epoch [7/20], Loss: 0.8150\n",
      "Epoch [7/20], Loss: 0.8151\n",
      "Epoch [7/20], Loss: 0.8149\n",
      "Epoch [7/20], Valid Accuracy: 85.7400, Valid Loss: 0.7873\n",
      "Epoch [8/20], Loss: 0.8134\n",
      "Epoch [8/20], Loss: 0.8127\n",
      "Epoch [8/20], Loss: 0.8086\n",
      "Epoch [8/20], Loss: 0.8148\n",
      "Epoch [8/20], Loss: 0.8143\n",
      "Epoch [8/20], Loss: 0.8161\n",
      "Epoch [8/20], Loss: 0.8150\n",
      "Epoch [8/20], Loss: 0.8151\n",
      "Epoch [8/20], Loss: 0.8157\n",
      "Epoch [8/20], Loss: 0.8155\n",
      "Epoch [8/20], Valid Accuracy: 85.2200, Valid Loss: 0.7924\n",
      "Epoch [9/20], Loss: 0.8338\n",
      "Epoch [9/20], Loss: 0.8261\n",
      "Epoch [9/20], Loss: 0.8206\n",
      "Epoch [9/20], Loss: 0.8171\n",
      "Epoch [9/20], Loss: 0.8171\n",
      "Epoch [9/20], Loss: 0.8163\n",
      "Epoch [9/20], Loss: 0.8163\n",
      "Epoch [9/20], Loss: 0.8159\n",
      "Epoch [9/20], Loss: 0.8139\n",
      "Epoch [9/20], Loss: 0.8141\n",
      "Epoch [9/20], Valid Accuracy: 86.2600, Valid Loss: 0.7874\n",
      "Epoch [10/20], Loss: 0.8065\n",
      "Epoch [10/20], Loss: 0.8135\n",
      "Epoch [10/20], Loss: 0.8108\n",
      "Epoch [10/20], Loss: 0.8100\n",
      "Epoch [10/20], Loss: 0.8125\n",
      "Epoch [10/20], Loss: 0.8139\n",
      "Epoch [10/20], Loss: 0.8129\n",
      "Epoch [10/20], Loss: 0.8133\n",
      "Epoch [10/20], Loss: 0.8124\n",
      "Epoch [10/20], Loss: 0.8122\n",
      "Epoch [10/20], Valid Accuracy: 85.4700, Valid Loss: 0.7854\n",
      "Epoch [11/20], Loss: 0.8144\n",
      "Epoch [11/20], Loss: 0.8155\n",
      "Epoch [11/20], Loss: 0.8144\n",
      "Epoch [11/20], Loss: 0.8178\n",
      "Epoch [11/20], Loss: 0.8164\n",
      "Epoch [11/20], Loss: 0.8161\n",
      "Epoch [11/20], Loss: 0.8156\n",
      "Epoch [11/20], Loss: 0.8136\n",
      "Epoch [11/20], Loss: 0.8131\n",
      "Epoch [11/20], Loss: 0.8128\n",
      "Epoch [11/20], Valid Accuracy: 85.6900, Valid Loss: 0.7875\n",
      "Epoch [12/20], Loss: 0.8002\n",
      "Epoch [12/20], Loss: 0.8081\n",
      "Epoch [12/20], Loss: 0.8111\n",
      "Epoch [12/20], Loss: 0.8115\n",
      "Epoch [12/20], Loss: 0.8100\n",
      "Epoch [12/20], Loss: 0.8123\n",
      "Epoch [12/20], Loss: 0.8137\n",
      "Epoch [12/20], Loss: 0.8097\n",
      "Epoch [12/20], Loss: 0.8094\n",
      "Epoch [12/20], Loss: 0.8100\n",
      "Epoch [12/20], Valid Accuracy: 85.6700, Valid Loss: 0.7907\n",
      "Epoch [13/20], Loss: 0.8205\n",
      "Epoch [13/20], Loss: 0.8150\n",
      "Epoch [13/20], Loss: 0.8088\n",
      "Epoch [13/20], Loss: 0.8073\n",
      "Epoch [13/20], Loss: 0.8126\n",
      "Epoch [13/20], Loss: 0.8131\n",
      "Epoch [13/20], Loss: 0.8141\n",
      "Epoch [13/20], Loss: 0.8152\n",
      "Epoch [13/20], Loss: 0.8142\n",
      "Epoch [13/20], Loss: 0.8134\n",
      "Epoch [13/20], Valid Accuracy: 85.0400, Valid Loss: 0.7790\n",
      "Epoch [14/20], Loss: 0.8080\n",
      "Epoch [14/20], Loss: 0.8153\n",
      "Epoch [14/20], Loss: 0.8201\n",
      "Epoch [14/20], Loss: 0.8172\n",
      "Epoch [14/20], Loss: 0.8160\n",
      "Epoch [14/20], Loss: 0.8146\n",
      "Epoch [14/20], Loss: 0.8128\n",
      "Epoch [14/20], Loss: 0.8125\n",
      "Epoch [14/20], Loss: 0.8121\n",
      "Epoch [14/20], Loss: 0.8122\n",
      "Epoch [14/20], Valid Accuracy: 84.2200, Valid Loss: 0.7861\n",
      "Epoch [15/20], Loss: 0.8278\n",
      "Epoch [15/20], Loss: 0.8227\n",
      "Epoch [15/20], Loss: 0.8166\n",
      "Epoch [15/20], Loss: 0.8139\n",
      "Epoch [15/20], Loss: 0.8140\n",
      "Epoch [15/20], Loss: 0.8142\n",
      "Epoch [15/20], Loss: 0.8136\n",
      "Epoch [15/20], Loss: 0.8119\n",
      "Epoch [15/20], Loss: 0.8113\n",
      "Epoch [15/20], Loss: 0.8118\n",
      "Epoch [15/20], Valid Accuracy: 84.2100, Valid Loss: 0.7842\n",
      "Epoch [16/20], Loss: 0.8130\n",
      "Epoch [16/20], Loss: 0.8126\n",
      "Epoch [16/20], Loss: 0.8088\n",
      "Epoch [16/20], Loss: 0.8085\n",
      "Epoch [16/20], Loss: 0.8093\n",
      "Epoch [16/20], Loss: 0.8105\n",
      "Epoch [16/20], Loss: 0.8123\n",
      "Epoch [16/20], Loss: 0.8114\n",
      "Epoch [16/20], Loss: 0.8119\n",
      "Epoch [16/20], Loss: 0.8112\n",
      "Epoch [16/20], Valid Accuracy: 85.3900, Valid Loss: 0.7914\n",
      "Epoch [17/20], Loss: 0.8164\n",
      "Epoch [17/20], Loss: 0.8099\n",
      "Epoch [17/20], Loss: 0.8082\n",
      "Epoch [17/20], Loss: 0.8117\n",
      "Epoch [17/20], Loss: 0.8122\n",
      "Epoch [17/20], Loss: 0.8146\n",
      "Epoch [17/20], Loss: 0.8143\n",
      "Epoch [17/20], Loss: 0.8132\n",
      "Epoch [17/20], Loss: 0.8119\n",
      "Epoch [17/20], Loss: 0.8122\n",
      "Epoch [17/20], Valid Accuracy: 86.0100, Valid Loss: 0.7912\n",
      "Epoch [18/20], Loss: 0.8192\n",
      "Epoch [18/20], Loss: 0.8140\n",
      "Epoch [18/20], Loss: 0.8077\n",
      "Epoch [18/20], Loss: 0.8042\n",
      "Epoch [18/20], Loss: 0.8080\n",
      "Epoch [18/20], Loss: 0.8108\n",
      "Epoch [18/20], Loss: 0.8087\n",
      "Epoch [18/20], Loss: 0.8091\n",
      "Epoch [18/20], Loss: 0.8100\n",
      "Epoch [18/20], Loss: 0.8098\n",
      "Epoch [18/20], Valid Accuracy: 85.9200, Valid Loss: 0.7821\n",
      "Epoch [19/20], Loss: 0.7958\n",
      "Epoch [19/20], Loss: 0.8036\n",
      "Epoch [19/20], Loss: 0.8050\n",
      "Epoch [19/20], Loss: 0.8040\n",
      "Epoch [19/20], Loss: 0.8043\n",
      "Epoch [19/20], Loss: 0.8053\n",
      "Epoch [19/20], Loss: 0.8079\n",
      "Epoch [19/20], Loss: 0.8097\n",
      "Epoch [19/20], Loss: 0.8100\n",
      "Epoch [19/20], Loss: 0.8106\n",
      "Epoch [19/20], Valid Accuracy: 83.4900, Valid Loss: 0.8013\n",
      "Epoch [20/20], Loss: 0.8124\n",
      "Epoch [20/20], Loss: 0.8245\n",
      "Epoch [20/20], Loss: 0.8200\n",
      "Epoch [20/20], Loss: 0.8198\n",
      "Epoch [20/20], Loss: 0.8160\n",
      "Epoch [20/20], Loss: 0.8137\n",
      "Epoch [20/20], Loss: 0.8137\n",
      "Epoch [20/20], Loss: 0.8126\n",
      "Epoch [20/20], Loss: 0.8113\n",
      "Epoch [20/20], Loss: 0.8113\n",
      "Epoch [20/20], Valid Accuracy: 85.6800, Valid Loss: 0.8010\n"
     ]
    }
   ],
   "source": [
    "weight_decay = [0, 0.0001, 0.001, 0.01, 0.1, 0.3]\n",
    "lst_val_acc3 = []\n",
    "lst_val_loss3 = []\n",
    "lst_train_loss3 = []\n",
    "for wd in weight_decay:\n",
    "    net = get_model()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay = wd)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, num_epochs=20, model=net, optimizer=optimizer)\n",
    "    lst_val_acc3.append(val_acc)\n",
    "    lst_val_loss3.append(val_loss)\n",
    "    lst_train_loss3.append(train_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight decay</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>98.08</td>\n",
       "      <td>0.109553</td>\n",
       "      <td>0.010023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>97.92</td>\n",
       "      <td>0.080104</td>\n",
       "      <td>0.016318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>97.80</td>\n",
       "      <td>0.068751</td>\n",
       "      <td>0.051359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>96.19</td>\n",
       "      <td>0.146237</td>\n",
       "      <td>0.155705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>89.31</td>\n",
       "      <td>0.452039</td>\n",
       "      <td>0.461021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>85.68</td>\n",
       "      <td>0.800991</td>\n",
       "      <td>0.811295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight decay  Validation Accuracy  Validation Loss  Training Loss\n",
       "0        0.0000                98.08         0.109553       0.010023\n",
       "1        0.0001                97.92         0.080104       0.016318\n",
       "2        0.0010                97.80         0.068751       0.051359\n",
       "3        0.0100                96.19         0.146237       0.155705\n",
       "4        0.1000                89.31         0.452039       0.461021\n",
       "5        0.3000                85.68         0.800991       0.811295"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(\n",
    "    {\n",
    "        'Weight decay': weight_decay,\n",
    "        'Validation Accuracy': lst_val_acc3,\n",
    "        'Validation Loss': lst_val_loss3,\n",
    "        'Training Loss': lst_train_loss3\n",
    "    },\n",
    "    columns = ['Weight decay', 'Validation Accuracy', 'Validation Loss', 'Training Loss']\n",
    ")\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_v2(M = 300, p=0):\n",
    "    modules = []\n",
    "    modules.append(nn.Linear(28*28, M))\n",
    "    modules.append(nn.ReLU())\n",
    "    if p > 0:\n",
    "        modules.append(nn.Dropout(p))\n",
    "    modules.append(nn.Linear(M, 10))\n",
    "    return nn.Sequential(*modules).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.5544\n",
      "Epoch [1/20], Loss: 0.4237\n",
      "Epoch [1/20], Loss: 0.3618\n",
      "Epoch [1/20], Loss: 0.3256\n",
      "Epoch [1/20], Loss: 0.2933\n",
      "Epoch [1/20], Loss: 0.2711\n",
      "Epoch [1/20], Loss: 0.2536\n",
      "Epoch [1/20], Loss: 0.2391\n",
      "Epoch [1/20], Loss: 0.2274\n",
      "Epoch [1/20], Loss: 0.2228\n",
      "Epoch [1/20], Valid Accuracy: 96.6000, Valid Loss: 0.1095\n",
      "Epoch [2/20], Loss: 0.0935\n",
      "Epoch [2/20], Loss: 0.1017\n",
      "Epoch [2/20], Loss: 0.0995\n",
      "Epoch [2/20], Loss: 0.0990\n",
      "Epoch [2/20], Loss: 0.0967\n",
      "Epoch [2/20], Loss: 0.0975\n",
      "Epoch [2/20], Loss: 0.0957\n",
      "Epoch [2/20], Loss: 0.0948\n",
      "Epoch [2/20], Loss: 0.0928\n",
      "Epoch [2/20], Loss: 0.0932\n",
      "Epoch [2/20], Valid Accuracy: 97.1900, Valid Loss: 0.0881\n",
      "Epoch [3/20], Loss: 0.0580\n",
      "Epoch [3/20], Loss: 0.0610\n",
      "Epoch [3/20], Loss: 0.0644\n",
      "Epoch [3/20], Loss: 0.0641\n",
      "Epoch [3/20], Loss: 0.0628\n",
      "Epoch [3/20], Loss: 0.0623\n",
      "Epoch [3/20], Loss: 0.0638\n",
      "Epoch [3/20], Loss: 0.0646\n",
      "Epoch [3/20], Loss: 0.0637\n",
      "Epoch [3/20], Loss: 0.0638\n",
      "Epoch [3/20], Valid Accuracy: 97.3700, Valid Loss: 0.0811\n",
      "Epoch [4/20], Loss: 0.0365\n",
      "Epoch [4/20], Loss: 0.0372\n",
      "Epoch [4/20], Loss: 0.0390\n",
      "Epoch [4/20], Loss: 0.0387\n",
      "Epoch [4/20], Loss: 0.0396\n",
      "Epoch [4/20], Loss: 0.0407\n",
      "Epoch [4/20], Loss: 0.0429\n",
      "Epoch [4/20], Loss: 0.0441\n",
      "Epoch [4/20], Loss: 0.0450\n",
      "Epoch [4/20], Loss: 0.0454\n",
      "Epoch [4/20], Valid Accuracy: 97.8800, Valid Loss: 0.0730\n",
      "Epoch [5/20], Loss: 0.0328\n",
      "Epoch [5/20], Loss: 0.0296\n",
      "Epoch [5/20], Loss: 0.0335\n",
      "Epoch [5/20], Loss: 0.0328\n",
      "Epoch [5/20], Loss: 0.0324\n",
      "Epoch [5/20], Loss: 0.0335\n",
      "Epoch [5/20], Loss: 0.0342\n",
      "Epoch [5/20], Loss: 0.0344\n",
      "Epoch [5/20], Loss: 0.0360\n",
      "Epoch [5/20], Loss: 0.0364\n",
      "Epoch [5/20], Valid Accuracy: 97.7700, Valid Loss: 0.0746\n",
      "Epoch [6/20], Loss: 0.0214\n",
      "Epoch [6/20], Loss: 0.0221\n",
      "Epoch [6/20], Loss: 0.0223\n",
      "Epoch [6/20], Loss: 0.0243\n",
      "Epoch [6/20], Loss: 0.0254\n",
      "Epoch [6/20], Loss: 0.0282\n",
      "Epoch [6/20], Loss: 0.0293\n",
      "Epoch [6/20], Loss: 0.0285\n",
      "Epoch [6/20], Loss: 0.0285\n",
      "Epoch [6/20], Loss: 0.0285\n",
      "Epoch [6/20], Valid Accuracy: 97.8000, Valid Loss: 0.0850\n",
      "Epoch [7/20], Loss: 0.0166\n",
      "Epoch [7/20], Loss: 0.0196\n",
      "Epoch [7/20], Loss: 0.0208\n",
      "Epoch [7/20], Loss: 0.0215\n",
      "Epoch [7/20], Loss: 0.0217\n",
      "Epoch [7/20], Loss: 0.0218\n",
      "Epoch [7/20], Loss: 0.0227\n",
      "Epoch [7/20], Loss: 0.0237\n",
      "Epoch [7/20], Loss: 0.0238\n",
      "Epoch [7/20], Loss: 0.0242\n",
      "Epoch [7/20], Valid Accuracy: 97.5600, Valid Loss: 0.0900\n",
      "Epoch [8/20], Loss: 0.0140\n",
      "Epoch [8/20], Loss: 0.0141\n",
      "Epoch [8/20], Loss: 0.0153\n",
      "Epoch [8/20], Loss: 0.0148\n",
      "Epoch [8/20], Loss: 0.0161\n",
      "Epoch [8/20], Loss: 0.0165\n",
      "Epoch [8/20], Loss: 0.0192\n",
      "Epoch [8/20], Loss: 0.0202\n",
      "Epoch [8/20], Loss: 0.0201\n",
      "Epoch [8/20], Loss: 0.0203\n",
      "Epoch [8/20], Valid Accuracy: 97.9800, Valid Loss: 0.0847\n",
      "Epoch [9/20], Loss: 0.0169\n",
      "Epoch [9/20], Loss: 0.0170\n",
      "Epoch [9/20], Loss: 0.0167\n",
      "Epoch [9/20], Loss: 0.0164\n",
      "Epoch [9/20], Loss: 0.0169\n",
      "Epoch [9/20], Loss: 0.0173\n",
      "Epoch [9/20], Loss: 0.0174\n",
      "Epoch [9/20], Loss: 0.0177\n",
      "Epoch [9/20], Loss: 0.0173\n",
      "Epoch [9/20], Loss: 0.0175\n",
      "Epoch [9/20], Valid Accuracy: 97.6700, Valid Loss: 0.0990\n",
      "Epoch [10/20], Loss: 0.0127\n",
      "Epoch [10/20], Loss: 0.0137\n",
      "Epoch [10/20], Loss: 0.0124\n",
      "Epoch [10/20], Loss: 0.0124\n",
      "Epoch [10/20], Loss: 0.0134\n",
      "Epoch [10/20], Loss: 0.0137\n",
      "Epoch [10/20], Loss: 0.0144\n",
      "Epoch [10/20], Loss: 0.0152\n",
      "Epoch [10/20], Loss: 0.0161\n",
      "Epoch [10/20], Loss: 0.0164\n",
      "Epoch [10/20], Valid Accuracy: 97.7400, Valid Loss: 0.0979\n",
      "Epoch [11/20], Loss: 0.0115\n",
      "Epoch [11/20], Loss: 0.0106\n",
      "Epoch [11/20], Loss: 0.0112\n",
      "Epoch [11/20], Loss: 0.0113\n",
      "Epoch [11/20], Loss: 0.0128\n",
      "Epoch [11/20], Loss: 0.0134\n",
      "Epoch [11/20], Loss: 0.0138\n",
      "Epoch [11/20], Loss: 0.0150\n",
      "Epoch [11/20], Loss: 0.0155\n",
      "Epoch [11/20], Loss: 0.0158\n",
      "Epoch [11/20], Valid Accuracy: 97.8800, Valid Loss: 0.0987\n",
      "Epoch [12/20], Loss: 0.0096\n",
      "Epoch [12/20], Loss: 0.0081\n",
      "Epoch [12/20], Loss: 0.0090\n",
      "Epoch [12/20], Loss: 0.0102\n",
      "Epoch [12/20], Loss: 0.0117\n",
      "Epoch [12/20], Loss: 0.0122\n",
      "Epoch [12/20], Loss: 0.0123\n",
      "Epoch [12/20], Loss: 0.0122\n",
      "Epoch [12/20], Loss: 0.0122\n",
      "Epoch [12/20], Loss: 0.0125\n",
      "Epoch [12/20], Valid Accuracy: 97.3800, Valid Loss: 0.1138\n",
      "Epoch [13/20], Loss: 0.0195\n",
      "Epoch [13/20], Loss: 0.0162\n",
      "Epoch [13/20], Loss: 0.0145\n",
      "Epoch [13/20], Loss: 0.0131\n",
      "Epoch [13/20], Loss: 0.0133\n",
      "Epoch [13/20], Loss: 0.0129\n",
      "Epoch [13/20], Loss: 0.0129\n",
      "Epoch [13/20], Loss: 0.0132\n",
      "Epoch [13/20], Loss: 0.0133\n",
      "Epoch [13/20], Loss: 0.0136\n",
      "Epoch [13/20], Valid Accuracy: 97.8800, Valid Loss: 0.1015\n",
      "Epoch [14/20], Loss: 0.0143\n",
      "Epoch [14/20], Loss: 0.0093\n",
      "Epoch [14/20], Loss: 0.0082\n",
      "Epoch [14/20], Loss: 0.0073\n",
      "Epoch [14/20], Loss: 0.0071\n",
      "Epoch [14/20], Loss: 0.0086\n",
      "Epoch [14/20], Loss: 0.0090\n",
      "Epoch [14/20], Loss: 0.0095\n",
      "Epoch [14/20], Loss: 0.0106\n",
      "Epoch [14/20], Loss: 0.0111\n",
      "Epoch [14/20], Valid Accuracy: 97.8000, Valid Loss: 0.1230\n",
      "Epoch [15/20], Loss: 0.0183\n",
      "Epoch [15/20], Loss: 0.0130\n",
      "Epoch [15/20], Loss: 0.0122\n",
      "Epoch [15/20], Loss: 0.0104\n",
      "Epoch [15/20], Loss: 0.0101\n",
      "Epoch [15/20], Loss: 0.0099\n",
      "Epoch [15/20], Loss: 0.0097\n",
      "Epoch [15/20], Loss: 0.0103\n",
      "Epoch [15/20], Loss: 0.0105\n",
      "Epoch [15/20], Loss: 0.0108\n",
      "Epoch [15/20], Valid Accuracy: 97.7700, Valid Loss: 0.1134\n",
      "Epoch [16/20], Loss: 0.0078\n",
      "Epoch [16/20], Loss: 0.0102\n",
      "Epoch [16/20], Loss: 0.0109\n",
      "Epoch [16/20], Loss: 0.0116\n",
      "Epoch [16/20], Loss: 0.0110\n",
      "Epoch [16/20], Loss: 0.0101\n",
      "Epoch [16/20], Loss: 0.0101\n",
      "Epoch [16/20], Loss: 0.0102\n",
      "Epoch [16/20], Loss: 0.0106\n",
      "Epoch [16/20], Loss: 0.0104\n",
      "Epoch [16/20], Valid Accuracy: 98.0300, Valid Loss: 0.1009\n",
      "Epoch [17/20], Loss: 0.0050\n",
      "Epoch [17/20], Loss: 0.0067\n",
      "Epoch [17/20], Loss: 0.0062\n",
      "Epoch [17/20], Loss: 0.0074\n",
      "Epoch [17/20], Loss: 0.0078\n",
      "Epoch [17/20], Loss: 0.0091\n",
      "Epoch [17/20], Loss: 0.0101\n",
      "Epoch [17/20], Loss: 0.0101\n",
      "Epoch [17/20], Loss: 0.0101\n",
      "Epoch [17/20], Loss: 0.0101\n",
      "Epoch [17/20], Valid Accuracy: 97.5900, Valid Loss: 0.1268\n",
      "Epoch [18/20], Loss: 0.0103\n",
      "Epoch [18/20], Loss: 0.0085\n",
      "Epoch [18/20], Loss: 0.0097\n",
      "Epoch [18/20], Loss: 0.0099\n",
      "Epoch [18/20], Loss: 0.0093\n",
      "Epoch [18/20], Loss: 0.0097\n",
      "Epoch [18/20], Loss: 0.0106\n",
      "Epoch [18/20], Loss: 0.0108\n",
      "Epoch [18/20], Loss: 0.0110\n",
      "Epoch [18/20], Loss: 0.0107\n",
      "Epoch [18/20], Valid Accuracy: 97.9700, Valid Loss: 0.1078\n",
      "Epoch [19/20], Loss: 0.0050\n",
      "Epoch [19/20], Loss: 0.0039\n",
      "Epoch [19/20], Loss: 0.0033\n",
      "Epoch [19/20], Loss: 0.0042\n",
      "Epoch [19/20], Loss: 0.0043\n",
      "Epoch [19/20], Loss: 0.0053\n",
      "Epoch [19/20], Loss: 0.0057\n",
      "Epoch [19/20], Loss: 0.0060\n",
      "Epoch [19/20], Loss: 0.0064\n",
      "Epoch [19/20], Loss: 0.0065\n",
      "Epoch [19/20], Valid Accuracy: 97.6400, Valid Loss: 0.1339\n",
      "Epoch [20/20], Loss: 0.0150\n",
      "Epoch [20/20], Loss: 0.0112\n",
      "Epoch [20/20], Loss: 0.0128\n",
      "Epoch [20/20], Loss: 0.0116\n",
      "Epoch [20/20], Loss: 0.0123\n",
      "Epoch [20/20], Loss: 0.0125\n",
      "Epoch [20/20], Loss: 0.0118\n",
      "Epoch [20/20], Loss: 0.0116\n",
      "Epoch [20/20], Loss: 0.0116\n",
      "Epoch [20/20], Loss: 0.0118\n",
      "Epoch [20/20], Valid Accuracy: 97.8300, Valid Loss: 0.1407\n",
      "Epoch [1/20], Loss: 0.5807\n",
      "Epoch [1/20], Loss: 0.4427\n",
      "Epoch [1/20], Loss: 0.3862\n",
      "Epoch [1/20], Loss: 0.3450\n",
      "Epoch [1/20], Loss: 0.3113\n",
      "Epoch [1/20], Loss: 0.2918\n",
      "Epoch [1/20], Loss: 0.2746\n",
      "Epoch [1/20], Loss: 0.2596\n",
      "Epoch [1/20], Loss: 0.2467\n",
      "Epoch [1/20], Loss: 0.2432\n",
      "Epoch [1/20], Valid Accuracy: 96.3300, Valid Loss: 0.1174\n",
      "Epoch [2/20], Loss: 0.1192\n",
      "Epoch [2/20], Loss: 0.1231\n",
      "Epoch [2/20], Loss: 0.1211\n",
      "Epoch [2/20], Loss: 0.1196\n",
      "Epoch [2/20], Loss: 0.1180\n",
      "Epoch [2/20], Loss: 0.1174\n",
      "Epoch [2/20], Loss: 0.1164\n",
      "Epoch [2/20], Loss: 0.1147\n",
      "Epoch [2/20], Loss: 0.1131\n",
      "Epoch [2/20], Loss: 0.1131\n",
      "Epoch [2/20], Valid Accuracy: 97.4400, Valid Loss: 0.0812\n",
      "Epoch [3/20], Loss: 0.0865\n",
      "Epoch [3/20], Loss: 0.0877\n",
      "Epoch [3/20], Loss: 0.0887\n",
      "Epoch [3/20], Loss: 0.0879\n",
      "Epoch [3/20], Loss: 0.0879\n",
      "Epoch [3/20], Loss: 0.0873\n",
      "Epoch [3/20], Loss: 0.0858\n",
      "Epoch [3/20], Loss: 0.0845\n",
      "Epoch [3/20], Loss: 0.0841\n",
      "Epoch [3/20], Loss: 0.0836\n",
      "Epoch [3/20], Valid Accuracy: 97.4400, Valid Loss: 0.0819\n",
      "Epoch [4/20], Loss: 0.0648\n",
      "Epoch [4/20], Loss: 0.0709\n",
      "Epoch [4/20], Loss: 0.0678\n",
      "Epoch [4/20], Loss: 0.0672\n",
      "Epoch [4/20], Loss: 0.0653\n",
      "Epoch [4/20], Loss: 0.0667\n",
      "Epoch [4/20], Loss: 0.0685\n",
      "Epoch [4/20], Loss: 0.0680\n",
      "Epoch [4/20], Loss: 0.0690\n",
      "Epoch [4/20], Loss: 0.0686\n",
      "Epoch [4/20], Valid Accuracy: 97.7100, Valid Loss: 0.0772\n",
      "Epoch [5/20], Loss: 0.0529\n",
      "Epoch [5/20], Loss: 0.0500\n",
      "Epoch [5/20], Loss: 0.0531\n",
      "Epoch [5/20], Loss: 0.0539\n",
      "Epoch [5/20], Loss: 0.0546\n",
      "Epoch [5/20], Loss: 0.0560\n",
      "Epoch [5/20], Loss: 0.0562\n",
      "Epoch [5/20], Loss: 0.0574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.0579\n",
      "Epoch [5/20], Loss: 0.0576\n",
      "Epoch [5/20], Valid Accuracy: 98.0200, Valid Loss: 0.0714\n",
      "Epoch [6/20], Loss: 0.0453\n",
      "Epoch [6/20], Loss: 0.0453\n",
      "Epoch [6/20], Loss: 0.0463\n",
      "Epoch [6/20], Loss: 0.0483\n",
      "Epoch [6/20], Loss: 0.0506\n",
      "Epoch [6/20], Loss: 0.0505\n",
      "Epoch [6/20], Loss: 0.0497\n",
      "Epoch [6/20], Loss: 0.0506\n",
      "Epoch [6/20], Loss: 0.0517\n",
      "Epoch [6/20], Loss: 0.0514\n",
      "Epoch [6/20], Valid Accuracy: 98.1600, Valid Loss: 0.0667\n",
      "Epoch [7/20], Loss: 0.0389\n",
      "Epoch [7/20], Loss: 0.0390\n",
      "Epoch [7/20], Loss: 0.0405\n",
      "Epoch [7/20], Loss: 0.0410\n",
      "Epoch [7/20], Loss: 0.0448\n",
      "Epoch [7/20], Loss: 0.0435\n",
      "Epoch [7/20], Loss: 0.0438\n",
      "Epoch [7/20], Loss: 0.0439\n",
      "Epoch [7/20], Loss: 0.0436\n",
      "Epoch [7/20], Loss: 0.0443\n",
      "Epoch [7/20], Valid Accuracy: 98.1300, Valid Loss: 0.0671\n",
      "Epoch [8/20], Loss: 0.0365\n",
      "Epoch [8/20], Loss: 0.0387\n",
      "Epoch [8/20], Loss: 0.0392\n",
      "Epoch [8/20], Loss: 0.0384\n",
      "Epoch [8/20], Loss: 0.0386\n",
      "Epoch [8/20], Loss: 0.0388\n",
      "Epoch [8/20], Loss: 0.0398\n",
      "Epoch [8/20], Loss: 0.0397\n",
      "Epoch [8/20], Loss: 0.0399\n",
      "Epoch [8/20], Loss: 0.0403\n",
      "Epoch [8/20], Valid Accuracy: 97.9600, Valid Loss: 0.0753\n",
      "Epoch [9/20], Loss: 0.0307\n",
      "Epoch [9/20], Loss: 0.0319\n",
      "Epoch [9/20], Loss: 0.0319\n",
      "Epoch [9/20], Loss: 0.0314\n",
      "Epoch [9/20], Loss: 0.0329\n",
      "Epoch [9/20], Loss: 0.0345\n",
      "Epoch [9/20], Loss: 0.0355\n",
      "Epoch [9/20], Loss: 0.0353\n",
      "Epoch [9/20], Loss: 0.0359\n",
      "Epoch [9/20], Loss: 0.0358\n",
      "Epoch [9/20], Valid Accuracy: 98.1800, Valid Loss: 0.0703\n",
      "Epoch [10/20], Loss: 0.0328\n",
      "Epoch [10/20], Loss: 0.0324\n",
      "Epoch [10/20], Loss: 0.0317\n",
      "Epoch [10/20], Loss: 0.0330\n",
      "Epoch [10/20], Loss: 0.0328\n",
      "Epoch [10/20], Loss: 0.0325\n",
      "Epoch [10/20], Loss: 0.0338\n",
      "Epoch [10/20], Loss: 0.0341\n",
      "Epoch [10/20], Loss: 0.0347\n",
      "Epoch [10/20], Loss: 0.0348\n",
      "Epoch [10/20], Valid Accuracy: 97.9700, Valid Loss: 0.0786\n",
      "Epoch [11/20], Loss: 0.0305\n",
      "Epoch [11/20], Loss: 0.0283\n",
      "Epoch [11/20], Loss: 0.0287\n",
      "Epoch [11/20], Loss: 0.0283\n",
      "Epoch [11/20], Loss: 0.0301\n",
      "Epoch [11/20], Loss: 0.0303\n",
      "Epoch [11/20], Loss: 0.0312\n",
      "Epoch [11/20], Loss: 0.0321\n",
      "Epoch [11/20], Loss: 0.0327\n",
      "Epoch [11/20], Loss: 0.0329\n",
      "Epoch [11/20], Valid Accuracy: 98.0600, Valid Loss: 0.0735\n",
      "Epoch [12/20], Loss: 0.0276\n",
      "Epoch [12/20], Loss: 0.0291\n",
      "Epoch [12/20], Loss: 0.0281\n",
      "Epoch [12/20], Loss: 0.0270\n",
      "Epoch [12/20], Loss: 0.0275\n",
      "Epoch [12/20], Loss: 0.0290\n",
      "Epoch [12/20], Loss: 0.0308\n",
      "Epoch [12/20], Loss: 0.0312\n",
      "Epoch [12/20], Loss: 0.0310\n",
      "Epoch [12/20], Loss: 0.0313\n",
      "Epoch [12/20], Valid Accuracy: 97.4400, Valid Loss: 0.1009\n",
      "Epoch [13/20], Loss: 0.0322\n",
      "Epoch [13/20], Loss: 0.0274\n",
      "Epoch [13/20], Loss: 0.0274\n",
      "Epoch [13/20], Loss: 0.0273\n",
      "Epoch [13/20], Loss: 0.0271\n",
      "Epoch [13/20], Loss: 0.0271\n",
      "Epoch [13/20], Loss: 0.0287\n",
      "Epoch [13/20], Loss: 0.0288\n",
      "Epoch [13/20], Loss: 0.0294\n",
      "Epoch [13/20], Loss: 0.0292\n",
      "Epoch [13/20], Valid Accuracy: 98.2300, Valid Loss: 0.0726\n",
      "Epoch [14/20], Loss: 0.0193\n",
      "Epoch [14/20], Loss: 0.0228\n",
      "Epoch [14/20], Loss: 0.0223\n",
      "Epoch [14/20], Loss: 0.0227\n",
      "Epoch [14/20], Loss: 0.0244\n",
      "Epoch [14/20], Loss: 0.0247\n",
      "Epoch [14/20], Loss: 0.0253\n",
      "Epoch [14/20], Loss: 0.0255\n",
      "Epoch [14/20], Loss: 0.0252\n",
      "Epoch [14/20], Loss: 0.0253\n",
      "Epoch [14/20], Valid Accuracy: 98.1200, Valid Loss: 0.0919\n",
      "Epoch [15/20], Loss: 0.0164\n",
      "Epoch [15/20], Loss: 0.0167\n",
      "Epoch [15/20], Loss: 0.0186\n",
      "Epoch [15/20], Loss: 0.0208\n",
      "Epoch [15/20], Loss: 0.0215\n",
      "Epoch [15/20], Loss: 0.0233\n",
      "Epoch [15/20], Loss: 0.0241\n",
      "Epoch [15/20], Loss: 0.0240\n",
      "Epoch [15/20], Loss: 0.0241\n",
      "Epoch [15/20], Loss: 0.0240\n",
      "Epoch [15/20], Valid Accuracy: 98.2400, Valid Loss: 0.0881\n",
      "Epoch [16/20], Loss: 0.0230\n",
      "Epoch [16/20], Loss: 0.0221\n",
      "Epoch [16/20], Loss: 0.0219\n",
      "Epoch [16/20], Loss: 0.0240\n",
      "Epoch [16/20], Loss: 0.0237\n",
      "Epoch [16/20], Loss: 0.0240\n",
      "Epoch [16/20], Loss: 0.0257\n",
      "Epoch [16/20], Loss: 0.0257\n",
      "Epoch [16/20], Loss: 0.0252\n",
      "Epoch [16/20], Loss: 0.0252\n",
      "Epoch [16/20], Valid Accuracy: 98.2100, Valid Loss: 0.0846\n",
      "Epoch [17/20], Loss: 0.0231\n",
      "Epoch [17/20], Loss: 0.0236\n",
      "Epoch [17/20], Loss: 0.0236\n",
      "Epoch [17/20], Loss: 0.0248\n",
      "Epoch [17/20], Loss: 0.0258\n",
      "Epoch [17/20], Loss: 0.0242\n",
      "Epoch [17/20], Loss: 0.0237\n",
      "Epoch [17/20], Loss: 0.0234\n",
      "Epoch [17/20], Loss: 0.0227\n",
      "Epoch [17/20], Loss: 0.0233\n",
      "Epoch [17/20], Valid Accuracy: 98.2100, Valid Loss: 0.0890\n",
      "Epoch [18/20], Loss: 0.0182\n",
      "Epoch [18/20], Loss: 0.0185\n",
      "Epoch [18/20], Loss: 0.0193\n",
      "Epoch [18/20], Loss: 0.0206\n",
      "Epoch [18/20], Loss: 0.0225\n",
      "Epoch [18/20], Loss: 0.0230\n",
      "Epoch [18/20], Loss: 0.0240\n",
      "Epoch [18/20], Loss: 0.0233\n",
      "Epoch [18/20], Loss: 0.0235\n",
      "Epoch [18/20], Loss: 0.0235\n",
      "Epoch [18/20], Valid Accuracy: 98.2700, Valid Loss: 0.0827\n",
      "Epoch [19/20], Loss: 0.0153\n",
      "Epoch [19/20], Loss: 0.0166\n",
      "Epoch [19/20], Loss: 0.0185\n",
      "Epoch [19/20], Loss: 0.0178\n",
      "Epoch [19/20], Loss: 0.0178\n",
      "Epoch [19/20], Loss: 0.0182\n",
      "Epoch [19/20], Loss: 0.0185\n",
      "Epoch [19/20], Loss: 0.0191\n",
      "Epoch [19/20], Loss: 0.0196\n",
      "Epoch [19/20], Loss: 0.0209\n",
      "Epoch [19/20], Valid Accuracy: 98.0400, Valid Loss: 0.0943\n",
      "Epoch [20/20], Loss: 0.0222\n",
      "Epoch [20/20], Loss: 0.0246\n",
      "Epoch [20/20], Loss: 0.0261\n",
      "Epoch [20/20], Loss: 0.0253\n",
      "Epoch [20/20], Loss: 0.0259\n",
      "Epoch [20/20], Loss: 0.0247\n",
      "Epoch [20/20], Loss: 0.0245\n",
      "Epoch [20/20], Loss: 0.0241\n",
      "Epoch [20/20], Loss: 0.0238\n",
      "Epoch [20/20], Loss: 0.0238\n",
      "Epoch [20/20], Valid Accuracy: 98.3400, Valid Loss: 0.0825\n",
      "Epoch [1/20], Loss: 0.6306\n",
      "Epoch [1/20], Loss: 0.4873\n",
      "Epoch [1/20], Loss: 0.4200\n",
      "Epoch [1/20], Loss: 0.3801\n",
      "Epoch [1/20], Loss: 0.3529\n",
      "Epoch [1/20], Loss: 0.3282\n",
      "Epoch [1/20], Loss: 0.3092\n",
      "Epoch [1/20], Loss: 0.2935\n",
      "Epoch [1/20], Loss: 0.2804\n",
      "Epoch [1/20], Loss: 0.2771\n",
      "Epoch [1/20], Valid Accuracy: 95.7500, Valid Loss: 0.1390\n",
      "Epoch [2/20], Loss: 0.1620\n",
      "Epoch [2/20], Loss: 0.1570\n",
      "Epoch [2/20], Loss: 0.1520\n",
      "Epoch [2/20], Loss: 0.1493\n",
      "Epoch [2/20], Loss: 0.1490\n",
      "Epoch [2/20], Loss: 0.1493\n",
      "Epoch [2/20], Loss: 0.1479\n",
      "Epoch [2/20], Loss: 0.1456\n",
      "Epoch [2/20], Loss: 0.1443\n",
      "Epoch [2/20], Loss: 0.1437\n",
      "Epoch [2/20], Valid Accuracy: 97.2300, Valid Loss: 0.0881\n",
      "Epoch [3/20], Loss: 0.1117\n",
      "Epoch [3/20], Loss: 0.1122\n",
      "Epoch [3/20], Loss: 0.1154\n",
      "Epoch [3/20], Loss: 0.1157\n",
      "Epoch [3/20], Loss: 0.1137\n",
      "Epoch [3/20], Loss: 0.1158\n",
      "Epoch [3/20], Loss: 0.1143\n",
      "Epoch [3/20], Loss: 0.1130\n",
      "Epoch [3/20], Loss: 0.1123\n",
      "Epoch [3/20], Loss: 0.1123\n",
      "Epoch [3/20], Valid Accuracy: 97.3400, Valid Loss: 0.0857\n",
      "Epoch [4/20], Loss: 0.0937\n",
      "Epoch [4/20], Loss: 0.0924\n",
      "Epoch [4/20], Loss: 0.0929\n",
      "Epoch [4/20], Loss: 0.0956\n",
      "Epoch [4/20], Loss: 0.0958\n",
      "Epoch [4/20], Loss: 0.0964\n",
      "Epoch [4/20], Loss: 0.0979\n",
      "Epoch [4/20], Loss: 0.0977\n",
      "Epoch [4/20], Loss: 0.0969\n",
      "Epoch [4/20], Loss: 0.0976\n",
      "Epoch [4/20], Valid Accuracy: 97.8300, Valid Loss: 0.0716\n",
      "Epoch [5/20], Loss: 0.0850\n",
      "Epoch [5/20], Loss: 0.0835\n",
      "Epoch [5/20], Loss: 0.0829\n",
      "Epoch [5/20], Loss: 0.0848\n",
      "Epoch [5/20], Loss: 0.0840\n",
      "Epoch [5/20], Loss: 0.0844\n",
      "Epoch [5/20], Loss: 0.0849\n",
      "Epoch [5/20], Loss: 0.0848\n",
      "Epoch [5/20], Loss: 0.0853\n",
      "Epoch [5/20], Loss: 0.0857\n",
      "Epoch [5/20], Valid Accuracy: 97.6500, Valid Loss: 0.0746\n",
      "Epoch [6/20], Loss: 0.0776\n",
      "Epoch [6/20], Loss: 0.0748\n",
      "Epoch [6/20], Loss: 0.0729\n",
      "Epoch [6/20], Loss: 0.0776\n",
      "Epoch [6/20], Loss: 0.0784\n",
      "Epoch [6/20], Loss: 0.0779\n",
      "Epoch [6/20], Loss: 0.0784\n",
      "Epoch [6/20], Loss: 0.0791\n",
      "Epoch [6/20], Loss: 0.0786\n",
      "Epoch [6/20], Loss: 0.0779\n",
      "Epoch [6/20], Valid Accuracy: 98.0800, Valid Loss: 0.0687\n",
      "Epoch [7/20], Loss: 0.0756\n",
      "Epoch [7/20], Loss: 0.0705\n",
      "Epoch [7/20], Loss: 0.0720\n",
      "Epoch [7/20], Loss: 0.0711\n",
      "Epoch [7/20], Loss: 0.0717\n",
      "Epoch [7/20], Loss: 0.0728\n",
      "Epoch [7/20], Loss: 0.0728\n",
      "Epoch [7/20], Loss: 0.0731\n",
      "Epoch [7/20], Loss: 0.0736\n",
      "Epoch [7/20], Loss: 0.0737\n",
      "Epoch [7/20], Valid Accuracy: 97.8500, Valid Loss: 0.0768\n",
      "Epoch [8/20], Loss: 0.0734\n",
      "Epoch [8/20], Loss: 0.0658\n",
      "Epoch [8/20], Loss: 0.0687\n",
      "Epoch [8/20], Loss: 0.0667\n",
      "Epoch [8/20], Loss: 0.0681\n",
      "Epoch [8/20], Loss: 0.0689\n",
      "Epoch [8/20], Loss: 0.0697\n",
      "Epoch [8/20], Loss: 0.0705\n",
      "Epoch [8/20], Loss: 0.0721\n",
      "Epoch [8/20], Loss: 0.0719\n",
      "Epoch [8/20], Valid Accuracy: 98.2100, Valid Loss: 0.0633\n",
      "Epoch [9/20], Loss: 0.0583\n",
      "Epoch [9/20], Loss: 0.0625\n",
      "Epoch [9/20], Loss: 0.0609\n",
      "Epoch [9/20], Loss: 0.0599\n",
      "Epoch [9/20], Loss: 0.0642\n",
      "Epoch [9/20], Loss: 0.0651\n",
      "Epoch [9/20], Loss: 0.0650\n",
      "Epoch [9/20], Loss: 0.0649\n",
      "Epoch [9/20], Loss: 0.0651\n",
      "Epoch [9/20], Loss: 0.0646\n",
      "Epoch [9/20], Valid Accuracy: 97.9200, Valid Loss: 0.0770\n",
      "Epoch [10/20], Loss: 0.0459\n",
      "Epoch [10/20], Loss: 0.0536\n",
      "Epoch [10/20], Loss: 0.0534\n",
      "Epoch [10/20], Loss: 0.0563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.0590\n",
      "Epoch [10/20], Loss: 0.0606\n",
      "Epoch [10/20], Loss: 0.0612\n",
      "Epoch [10/20], Loss: 0.0614\n",
      "Epoch [10/20], Loss: 0.0621\n",
      "Epoch [10/20], Loss: 0.0616\n",
      "Epoch [10/20], Valid Accuracy: 97.9400, Valid Loss: 0.0714\n",
      "Epoch [11/20], Loss: 0.0481\n",
      "Epoch [11/20], Loss: 0.0511\n",
      "Epoch [11/20], Loss: 0.0526\n",
      "Epoch [11/20], Loss: 0.0523\n",
      "Epoch [11/20], Loss: 0.0532\n",
      "Epoch [11/20], Loss: 0.0557\n",
      "Epoch [11/20], Loss: 0.0569\n",
      "Epoch [11/20], Loss: 0.0583\n",
      "Epoch [11/20], Loss: 0.0587\n",
      "Epoch [11/20], Loss: 0.0596\n",
      "Epoch [11/20], Valid Accuracy: 98.0600, Valid Loss: 0.0726\n",
      "Epoch [12/20], Loss: 0.0494\n",
      "Epoch [12/20], Loss: 0.0518\n",
      "Epoch [12/20], Loss: 0.0510\n",
      "Epoch [12/20], Loss: 0.0510\n",
      "Epoch [12/20], Loss: 0.0524\n",
      "Epoch [12/20], Loss: 0.0526\n",
      "Epoch [12/20], Loss: 0.0528\n",
      "Epoch [12/20], Loss: 0.0535\n",
      "Epoch [12/20], Loss: 0.0536\n",
      "Epoch [12/20], Loss: 0.0541\n",
      "Epoch [12/20], Valid Accuracy: 98.3400, Valid Loss: 0.0644\n",
      "Epoch [13/20], Loss: 0.0526\n",
      "Epoch [13/20], Loss: 0.0479\n",
      "Epoch [13/20], Loss: 0.0479\n",
      "Epoch [13/20], Loss: 0.0493\n",
      "Epoch [13/20], Loss: 0.0491\n",
      "Epoch [13/20], Loss: 0.0520\n",
      "Epoch [13/20], Loss: 0.0515\n",
      "Epoch [13/20], Loss: 0.0513\n",
      "Epoch [13/20], Loss: 0.0515\n",
      "Epoch [13/20], Loss: 0.0527\n",
      "Epoch [13/20], Valid Accuracy: 98.3400, Valid Loss: 0.0698\n",
      "Epoch [14/20], Loss: 0.0455\n",
      "Epoch [14/20], Loss: 0.0510\n",
      "Epoch [14/20], Loss: 0.0499\n",
      "Epoch [14/20], Loss: 0.0503\n",
      "Epoch [14/20], Loss: 0.0515\n",
      "Epoch [14/20], Loss: 0.0523\n",
      "Epoch [14/20], Loss: 0.0525\n",
      "Epoch [14/20], Loss: 0.0522\n",
      "Epoch [14/20], Loss: 0.0528\n",
      "Epoch [14/20], Loss: 0.0527\n",
      "Epoch [14/20], Valid Accuracy: 98.3700, Valid Loss: 0.0674\n",
      "Epoch [15/20], Loss: 0.0488\n",
      "Epoch [15/20], Loss: 0.0464\n",
      "Epoch [15/20], Loss: 0.0448\n",
      "Epoch [15/20], Loss: 0.0451\n",
      "Epoch [15/20], Loss: 0.0468\n",
      "Epoch [15/20], Loss: 0.0483\n",
      "Epoch [15/20], Loss: 0.0484\n",
      "Epoch [15/20], Loss: 0.0479\n",
      "Epoch [15/20], Loss: 0.0478\n",
      "Epoch [15/20], Loss: 0.0481\n",
      "Epoch [15/20], Valid Accuracy: 98.2100, Valid Loss: 0.0803\n",
      "Epoch [16/20], Loss: 0.0421\n",
      "Epoch [16/20], Loss: 0.0438\n",
      "Epoch [16/20], Loss: 0.0444\n",
      "Epoch [16/20], Loss: 0.0431\n",
      "Epoch [16/20], Loss: 0.0439\n",
      "Epoch [16/20], Loss: 0.0444\n",
      "Epoch [16/20], Loss: 0.0450\n",
      "Epoch [16/20], Loss: 0.0456\n",
      "Epoch [16/20], Loss: 0.0466\n",
      "Epoch [16/20], Loss: 0.0468\n",
      "Epoch [16/20], Valid Accuracy: 98.1600, Valid Loss: 0.0759\n",
      "Epoch [17/20], Loss: 0.0407\n",
      "Epoch [17/20], Loss: 0.0439\n",
      "Epoch [17/20], Loss: 0.0455\n",
      "Epoch [17/20], Loss: 0.0445\n",
      "Epoch [17/20], Loss: 0.0446\n",
      "Epoch [17/20], Loss: 0.0461\n",
      "Epoch [17/20], Loss: 0.0472\n",
      "Epoch [17/20], Loss: 0.0470\n",
      "Epoch [17/20], Loss: 0.0465\n",
      "Epoch [17/20], Loss: 0.0462\n",
      "Epoch [17/20], Valid Accuracy: 98.2900, Valid Loss: 0.0836\n",
      "Epoch [18/20], Loss: 0.0400\n",
      "Epoch [18/20], Loss: 0.0402\n",
      "Epoch [18/20], Loss: 0.0423\n",
      "Epoch [18/20], Loss: 0.0448\n",
      "Epoch [18/20], Loss: 0.0456\n",
      "Epoch [18/20], Loss: 0.0464\n",
      "Epoch [18/20], Loss: 0.0460\n",
      "Epoch [18/20], Loss: 0.0459\n",
      "Epoch [18/20], Loss: 0.0469\n",
      "Epoch [18/20], Loss: 0.0474\n",
      "Epoch [18/20], Valid Accuracy: 98.1900, Valid Loss: 0.0790\n",
      "Epoch [19/20], Loss: 0.0338\n",
      "Epoch [19/20], Loss: 0.0375\n",
      "Epoch [19/20], Loss: 0.0377\n",
      "Epoch [19/20], Loss: 0.0394\n",
      "Epoch [19/20], Loss: 0.0394\n",
      "Epoch [19/20], Loss: 0.0402\n",
      "Epoch [19/20], Loss: 0.0409\n",
      "Epoch [19/20], Loss: 0.0406\n",
      "Epoch [19/20], Loss: 0.0414\n",
      "Epoch [19/20], Loss: 0.0414\n",
      "Epoch [19/20], Valid Accuracy: 98.3600, Valid Loss: 0.0722\n",
      "Epoch [20/20], Loss: 0.0458\n",
      "Epoch [20/20], Loss: 0.0400\n",
      "Epoch [20/20], Loss: 0.0406\n",
      "Epoch [20/20], Loss: 0.0396\n",
      "Epoch [20/20], Loss: 0.0395\n",
      "Epoch [20/20], Loss: 0.0388\n",
      "Epoch [20/20], Loss: 0.0404\n",
      "Epoch [20/20], Loss: 0.0403\n",
      "Epoch [20/20], Loss: 0.0421\n",
      "Epoch [20/20], Loss: 0.0425\n",
      "Epoch [20/20], Valid Accuracy: 98.3900, Valid Loss: 0.0772\n",
      "Epoch [1/20], Loss: 0.7358\n",
      "Epoch [1/20], Loss: 0.5744\n",
      "Epoch [1/20], Loss: 0.4950\n",
      "Epoch [1/20], Loss: 0.4470\n",
      "Epoch [1/20], Loss: 0.4147\n",
      "Epoch [1/20], Loss: 0.3943\n",
      "Epoch [1/20], Loss: 0.3758\n",
      "Epoch [1/20], Loss: 0.3591\n",
      "Epoch [1/20], Loss: 0.3468\n",
      "Epoch [1/20], Loss: 0.3429\n",
      "Epoch [1/20], Valid Accuracy: 95.6900, Valid Loss: 0.1470\n",
      "Epoch [2/20], Loss: 0.2021\n",
      "Epoch [2/20], Loss: 0.2086\n",
      "Epoch [2/20], Loss: 0.2083\n",
      "Epoch [2/20], Loss: 0.2085\n",
      "Epoch [2/20], Loss: 0.2053\n",
      "Epoch [2/20], Loss: 0.2086\n",
      "Epoch [2/20], Loss: 0.2051\n",
      "Epoch [2/20], Loss: 0.2050\n",
      "Epoch [2/20], Loss: 0.2033\n",
      "Epoch [2/20], Loss: 0.2030\n",
      "Epoch [2/20], Valid Accuracy: 96.3100, Valid Loss: 0.1145\n",
      "Epoch [3/20], Loss: 0.1784\n",
      "Epoch [3/20], Loss: 0.1754\n",
      "Epoch [3/20], Loss: 0.1764\n",
      "Epoch [3/20], Loss: 0.1760\n",
      "Epoch [3/20], Loss: 0.1760\n",
      "Epoch [3/20], Loss: 0.1737\n",
      "Epoch [3/20], Loss: 0.1738\n",
      "Epoch [3/20], Loss: 0.1742\n",
      "Epoch [3/20], Loss: 0.1730\n",
      "Epoch [3/20], Loss: 0.1727\n",
      "Epoch [3/20], Valid Accuracy: 97.0300, Valid Loss: 0.0933\n",
      "Epoch [4/20], Loss: 0.1552\n",
      "Epoch [4/20], Loss: 0.1454\n",
      "Epoch [4/20], Loss: 0.1479\n",
      "Epoch [4/20], Loss: 0.1516\n",
      "Epoch [4/20], Loss: 0.1503\n",
      "Epoch [4/20], Loss: 0.1532\n",
      "Epoch [4/20], Loss: 0.1548\n",
      "Epoch [4/20], Loss: 0.1538\n",
      "Epoch [4/20], Loss: 0.1549\n",
      "Epoch [4/20], Loss: 0.1547\n",
      "Epoch [4/20], Valid Accuracy: 97.5000, Valid Loss: 0.0845\n",
      "Epoch [5/20], Loss: 0.1486\n",
      "Epoch [5/20], Loss: 0.1478\n",
      "Epoch [5/20], Loss: 0.1437\n",
      "Epoch [5/20], Loss: 0.1425\n",
      "Epoch [5/20], Loss: 0.1444\n",
      "Epoch [5/20], Loss: 0.1449\n",
      "Epoch [5/20], Loss: 0.1436\n",
      "Epoch [5/20], Loss: 0.1431\n",
      "Epoch [5/20], Loss: 0.1419\n",
      "Epoch [5/20], Loss: 0.1417\n",
      "Epoch [5/20], Valid Accuracy: 97.4800, Valid Loss: 0.0825\n",
      "Epoch [6/20], Loss: 0.1286\n",
      "Epoch [6/20], Loss: 0.1281\n",
      "Epoch [6/20], Loss: 0.1316\n",
      "Epoch [6/20], Loss: 0.1298\n",
      "Epoch [6/20], Loss: 0.1299\n",
      "Epoch [6/20], Loss: 0.1304\n",
      "Epoch [6/20], Loss: 0.1309\n",
      "Epoch [6/20], Loss: 0.1317\n",
      "Epoch [6/20], Loss: 0.1336\n",
      "Epoch [6/20], Loss: 0.1336\n",
      "Epoch [6/20], Valid Accuracy: 97.5500, Valid Loss: 0.0812\n",
      "Epoch [7/20], Loss: 0.1242\n",
      "Epoch [7/20], Loss: 0.1266\n",
      "Epoch [7/20], Loss: 0.1340\n",
      "Epoch [7/20], Loss: 0.1337\n",
      "Epoch [7/20], Loss: 0.1310\n",
      "Epoch [7/20], Loss: 0.1298\n",
      "Epoch [7/20], Loss: 0.1287\n",
      "Epoch [7/20], Loss: 0.1268\n",
      "Epoch [7/20], Loss: 0.1272\n",
      "Epoch [7/20], Loss: 0.1276\n",
      "Epoch [7/20], Valid Accuracy: 97.7300, Valid Loss: 0.0772\n",
      "Epoch [8/20], Loss: 0.1263\n",
      "Epoch [8/20], Loss: 0.1342\n",
      "Epoch [8/20], Loss: 0.1337\n",
      "Epoch [8/20], Loss: 0.1287\n",
      "Epoch [8/20], Loss: 0.1249\n",
      "Epoch [8/20], Loss: 0.1225\n",
      "Epoch [8/20], Loss: 0.1240\n",
      "Epoch [8/20], Loss: 0.1240\n",
      "Epoch [8/20], Loss: 0.1259\n",
      "Epoch [8/20], Loss: 0.1260\n",
      "Epoch [8/20], Valid Accuracy: 97.9300, Valid Loss: 0.0734\n",
      "Epoch [9/20], Loss: 0.1054\n",
      "Epoch [9/20], Loss: 0.1019\n",
      "Epoch [9/20], Loss: 0.1082\n",
      "Epoch [9/20], Loss: 0.1089\n",
      "Epoch [9/20], Loss: 0.1103\n",
      "Epoch [9/20], Loss: 0.1119\n",
      "Epoch [9/20], Loss: 0.1135\n",
      "Epoch [9/20], Loss: 0.1144\n",
      "Epoch [9/20], Loss: 0.1150\n",
      "Epoch [9/20], Loss: 0.1151\n",
      "Epoch [9/20], Valid Accuracy: 97.7600, Valid Loss: 0.0809\n",
      "Epoch [10/20], Loss: 0.1024\n",
      "Epoch [10/20], Loss: 0.1059\n",
      "Epoch [10/20], Loss: 0.1062\n",
      "Epoch [10/20], Loss: 0.1067\n",
      "Epoch [10/20], Loss: 0.1083\n",
      "Epoch [10/20], Loss: 0.1064\n",
      "Epoch [10/20], Loss: 0.1071\n",
      "Epoch [10/20], Loss: 0.1083\n",
      "Epoch [10/20], Loss: 0.1095\n",
      "Epoch [10/20], Loss: 0.1091\n",
      "Epoch [10/20], Valid Accuracy: 97.9400, Valid Loss: 0.0749\n",
      "Epoch [11/20], Loss: 0.1068\n",
      "Epoch [11/20], Loss: 0.1109\n",
      "Epoch [11/20], Loss: 0.1074\n",
      "Epoch [11/20], Loss: 0.1081\n",
      "Epoch [11/20], Loss: 0.1074\n",
      "Epoch [11/20], Loss: 0.1075\n",
      "Epoch [11/20], Loss: 0.1083\n",
      "Epoch [11/20], Loss: 0.1097\n",
      "Epoch [11/20], Loss: 0.1092\n",
      "Epoch [11/20], Loss: 0.1097\n",
      "Epoch [11/20], Valid Accuracy: 97.9200, Valid Loss: 0.0724\n",
      "Epoch [12/20], Loss: 0.1001\n",
      "Epoch [12/20], Loss: 0.1013\n",
      "Epoch [12/20], Loss: 0.0992\n",
      "Epoch [12/20], Loss: 0.0996\n",
      "Epoch [12/20], Loss: 0.1014\n",
      "Epoch [12/20], Loss: 0.1024\n",
      "Epoch [12/20], Loss: 0.1040\n",
      "Epoch [12/20], Loss: 0.1060\n",
      "Epoch [12/20], Loss: 0.1069\n",
      "Epoch [12/20], Loss: 0.1066\n",
      "Epoch [12/20], Valid Accuracy: 98.0700, Valid Loss: 0.0748\n",
      "Epoch [13/20], Loss: 0.1096\n",
      "Epoch [13/20], Loss: 0.1042\n",
      "Epoch [13/20], Loss: 0.0995\n",
      "Epoch [13/20], Loss: 0.0984\n",
      "Epoch [13/20], Loss: 0.0986\n",
      "Epoch [13/20], Loss: 0.1003\n",
      "Epoch [13/20], Loss: 0.1014\n",
      "Epoch [13/20], Loss: 0.1030\n",
      "Epoch [13/20], Loss: 0.1037\n",
      "Epoch [13/20], Loss: 0.1035\n",
      "Epoch [13/20], Valid Accuracy: 98.0400, Valid Loss: 0.0799\n",
      "Epoch [14/20], Loss: 0.1135\n",
      "Epoch [14/20], Loss: 0.1120\n",
      "Epoch [14/20], Loss: 0.1076\n",
      "Epoch [14/20], Loss: 0.1057\n",
      "Epoch [14/20], Loss: 0.1058\n",
      "Epoch [14/20], Loss: 0.1065\n",
      "Epoch [14/20], Loss: 0.1064\n",
      "Epoch [14/20], Loss: 0.1064\n",
      "Epoch [14/20], Loss: 0.1061\n",
      "Epoch [14/20], Loss: 0.1064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Valid Accuracy: 97.9800, Valid Loss: 0.0732\n",
      "Epoch [15/20], Loss: 0.1030\n",
      "Epoch [15/20], Loss: 0.0988\n",
      "Epoch [15/20], Loss: 0.0987\n",
      "Epoch [15/20], Loss: 0.1003\n",
      "Epoch [15/20], Loss: 0.1001\n",
      "Epoch [15/20], Loss: 0.1020\n",
      "Epoch [15/20], Loss: 0.1037\n",
      "Epoch [15/20], Loss: 0.1015\n",
      "Epoch [15/20], Loss: 0.1027\n",
      "Epoch [15/20], Loss: 0.1024\n",
      "Epoch [15/20], Valid Accuracy: 98.0400, Valid Loss: 0.0744\n",
      "Epoch [16/20], Loss: 0.0922\n",
      "Epoch [16/20], Loss: 0.0937\n",
      "Epoch [16/20], Loss: 0.0981\n",
      "Epoch [16/20], Loss: 0.0936\n",
      "Epoch [16/20], Loss: 0.0947\n",
      "Epoch [16/20], Loss: 0.0958\n",
      "Epoch [16/20], Loss: 0.0967\n",
      "Epoch [16/20], Loss: 0.0969\n",
      "Epoch [16/20], Loss: 0.0976\n",
      "Epoch [16/20], Loss: 0.0973\n",
      "Epoch [16/20], Valid Accuracy: 98.1200, Valid Loss: 0.0809\n",
      "Epoch [17/20], Loss: 0.0927\n",
      "Epoch [17/20], Loss: 0.0846\n",
      "Epoch [17/20], Loss: 0.0846\n",
      "Epoch [17/20], Loss: 0.0883\n",
      "Epoch [17/20], Loss: 0.0933\n",
      "Epoch [17/20], Loss: 0.0936\n",
      "Epoch [17/20], Loss: 0.0946\n",
      "Epoch [17/20], Loss: 0.0954\n",
      "Epoch [17/20], Loss: 0.0960\n",
      "Epoch [17/20], Loss: 0.0971\n",
      "Epoch [17/20], Valid Accuracy: 97.9700, Valid Loss: 0.0785\n",
      "Epoch [18/20], Loss: 0.0784\n",
      "Epoch [18/20], Loss: 0.0855\n",
      "Epoch [18/20], Loss: 0.0893\n",
      "Epoch [18/20], Loss: 0.0915\n",
      "Epoch [18/20], Loss: 0.0910\n",
      "Epoch [18/20], Loss: 0.0907\n",
      "Epoch [18/20], Loss: 0.0918\n",
      "Epoch [18/20], Loss: 0.0922\n",
      "Epoch [18/20], Loss: 0.0923\n",
      "Epoch [18/20], Loss: 0.0930\n",
      "Epoch [18/20], Valid Accuracy: 98.1900, Valid Loss: 0.0774\n",
      "Epoch [19/20], Loss: 0.0830\n",
      "Epoch [19/20], Loss: 0.0882\n",
      "Epoch [19/20], Loss: 0.0899\n",
      "Epoch [19/20], Loss: 0.0915\n",
      "Epoch [19/20], Loss: 0.0913\n",
      "Epoch [19/20], Loss: 0.0925\n",
      "Epoch [19/20], Loss: 0.0934\n",
      "Epoch [19/20], Loss: 0.0930\n",
      "Epoch [19/20], Loss: 0.0932\n",
      "Epoch [19/20], Loss: 0.0933\n",
      "Epoch [19/20], Valid Accuracy: 98.0000, Valid Loss: 0.0788\n",
      "Epoch [20/20], Loss: 0.0857\n",
      "Epoch [20/20], Loss: 0.0886\n",
      "Epoch [20/20], Loss: 0.0891\n",
      "Epoch [20/20], Loss: 0.0884\n",
      "Epoch [20/20], Loss: 0.0866\n",
      "Epoch [20/20], Loss: 0.0870\n",
      "Epoch [20/20], Loss: 0.0881\n",
      "Epoch [20/20], Loss: 0.0883\n",
      "Epoch [20/20], Loss: 0.0884\n",
      "Epoch [20/20], Loss: 0.0886\n",
      "Epoch [20/20], Valid Accuracy: 98.1000, Valid Loss: 0.0767\n",
      "Epoch [1/20], Loss: 0.9922\n",
      "Epoch [1/20], Loss: 0.7892\n",
      "Epoch [1/20], Loss: 0.7012\n",
      "Epoch [1/20], Loss: 0.6451\n",
      "Epoch [1/20], Loss: 0.6043\n",
      "Epoch [1/20], Loss: 0.5798\n",
      "Epoch [1/20], Loss: 0.5564\n",
      "Epoch [1/20], Loss: 0.5371\n",
      "Epoch [1/20], Loss: 0.5216\n",
      "Epoch [1/20], Loss: 0.5165\n",
      "Epoch [1/20], Valid Accuracy: 94.2900, Valid Loss: 0.1927\n",
      "Epoch [2/20], Loss: 0.3568\n",
      "Epoch [2/20], Loss: 0.3612\n",
      "Epoch [2/20], Loss: 0.3607\n",
      "Epoch [2/20], Loss: 0.3606\n",
      "Epoch [2/20], Loss: 0.3581\n",
      "Epoch [2/20], Loss: 0.3580\n",
      "Epoch [2/20], Loss: 0.3555\n",
      "Epoch [2/20], Loss: 0.3565\n",
      "Epoch [2/20], Loss: 0.3563\n",
      "Epoch [2/20], Loss: 0.3566\n",
      "Epoch [2/20], Valid Accuracy: 95.3200, Valid Loss: 0.1582\n",
      "Epoch [3/20], Loss: 0.3156\n",
      "Epoch [3/20], Loss: 0.3190\n",
      "Epoch [3/20], Loss: 0.3280\n",
      "Epoch [3/20], Loss: 0.3254\n",
      "Epoch [3/20], Loss: 0.3297\n",
      "Epoch [3/20], Loss: 0.3297\n",
      "Epoch [3/20], Loss: 0.3283\n",
      "Epoch [3/20], Loss: 0.3262\n",
      "Epoch [3/20], Loss: 0.3249\n",
      "Epoch [3/20], Loss: 0.3250\n",
      "Epoch [3/20], Valid Accuracy: 96.0000, Valid Loss: 0.1351\n",
      "Epoch [4/20], Loss: 0.3238\n",
      "Epoch [4/20], Loss: 0.3135\n",
      "Epoch [4/20], Loss: 0.3080\n",
      "Epoch [4/20], Loss: 0.3069\n",
      "Epoch [4/20], Loss: 0.3026\n",
      "Epoch [4/20], Loss: 0.3044\n",
      "Epoch [4/20], Loss: 0.3066\n",
      "Epoch [4/20], Loss: 0.3056\n",
      "Epoch [4/20], Loss: 0.3046\n",
      "Epoch [4/20], Loss: 0.3056\n",
      "Epoch [4/20], Valid Accuracy: 96.3900, Valid Loss: 0.1247\n",
      "Epoch [5/20], Loss: 0.2803\n",
      "Epoch [5/20], Loss: 0.2860\n",
      "Epoch [5/20], Loss: 0.2906\n",
      "Epoch [5/20], Loss: 0.2939\n",
      "Epoch [5/20], Loss: 0.2940\n",
      "Epoch [5/20], Loss: 0.2960\n",
      "Epoch [5/20], Loss: 0.2977\n",
      "Epoch [5/20], Loss: 0.2961\n",
      "Epoch [5/20], Loss: 0.2951\n",
      "Epoch [5/20], Loss: 0.2940\n",
      "Epoch [5/20], Valid Accuracy: 96.4800, Valid Loss: 0.1221\n",
      "Epoch [6/20], Loss: 0.2704\n",
      "Epoch [6/20], Loss: 0.2734\n",
      "Epoch [6/20], Loss: 0.2760\n",
      "Epoch [6/20], Loss: 0.2835\n",
      "Epoch [6/20], Loss: 0.2869\n",
      "Epoch [6/20], Loss: 0.2892\n",
      "Epoch [6/20], Loss: 0.2891\n",
      "Epoch [6/20], Loss: 0.2868\n",
      "Epoch [6/20], Loss: 0.2858\n",
      "Epoch [6/20], Loss: 0.2860\n",
      "Epoch [6/20], Valid Accuracy: 96.5800, Valid Loss: 0.1138\n",
      "Epoch [7/20], Loss: 0.2792\n",
      "Epoch [7/20], Loss: 0.2773\n",
      "Epoch [7/20], Loss: 0.2727\n",
      "Epoch [7/20], Loss: 0.2745\n",
      "Epoch [7/20], Loss: 0.2776\n",
      "Epoch [7/20], Loss: 0.2818\n",
      "Epoch [7/20], Loss: 0.2803\n",
      "Epoch [7/20], Loss: 0.2768\n",
      "Epoch [7/20], Loss: 0.2770\n",
      "Epoch [7/20], Loss: 0.2769\n",
      "Epoch [7/20], Valid Accuracy: 96.5600, Valid Loss: 0.1192\n",
      "Epoch [8/20], Loss: 0.2580\n",
      "Epoch [8/20], Loss: 0.2738\n",
      "Epoch [8/20], Loss: 0.2693\n",
      "Epoch [8/20], Loss: 0.2695\n",
      "Epoch [8/20], Loss: 0.2691\n",
      "Epoch [8/20], Loss: 0.2743\n",
      "Epoch [8/20], Loss: 0.2735\n",
      "Epoch [8/20], Loss: 0.2734\n",
      "Epoch [8/20], Loss: 0.2739\n",
      "Epoch [8/20], Loss: 0.2714\n",
      "Epoch [8/20], Valid Accuracy: 96.8800, Valid Loss: 0.1141\n",
      "Epoch [9/20], Loss: 0.2464\n",
      "Epoch [9/20], Loss: 0.2531\n",
      "Epoch [9/20], Loss: 0.2663\n",
      "Epoch [9/20], Loss: 0.2644\n",
      "Epoch [9/20], Loss: 0.2644\n",
      "Epoch [9/20], Loss: 0.2636\n",
      "Epoch [9/20], Loss: 0.2638\n",
      "Epoch [9/20], Loss: 0.2655\n",
      "Epoch [9/20], Loss: 0.2676\n",
      "Epoch [9/20], Loss: 0.2673\n",
      "Epoch [9/20], Valid Accuracy: 96.7800, Valid Loss: 0.1135\n",
      "Epoch [10/20], Loss: 0.2534\n",
      "Epoch [10/20], Loss: 0.2614\n",
      "Epoch [10/20], Loss: 0.2637\n",
      "Epoch [10/20], Loss: 0.2592\n",
      "Epoch [10/20], Loss: 0.2574\n",
      "Epoch [10/20], Loss: 0.2545\n",
      "Epoch [10/20], Loss: 0.2562\n",
      "Epoch [10/20], Loss: 0.2572\n",
      "Epoch [10/20], Loss: 0.2562\n",
      "Epoch [10/20], Loss: 0.2573\n",
      "Epoch [10/20], Valid Accuracy: 96.9900, Valid Loss: 0.1099\n",
      "Epoch [11/20], Loss: 0.2536\n",
      "Epoch [11/20], Loss: 0.2520\n",
      "Epoch [11/20], Loss: 0.2474\n",
      "Epoch [11/20], Loss: 0.2561\n",
      "Epoch [11/20], Loss: 0.2590\n",
      "Epoch [11/20], Loss: 0.2636\n",
      "Epoch [11/20], Loss: 0.2615\n",
      "Epoch [11/20], Loss: 0.2611\n",
      "Epoch [11/20], Loss: 0.2612\n",
      "Epoch [11/20], Loss: 0.2605\n",
      "Epoch [11/20], Valid Accuracy: 96.9500, Valid Loss: 0.1085\n",
      "Epoch [12/20], Loss: 0.2449\n",
      "Epoch [12/20], Loss: 0.2516\n",
      "Epoch [12/20], Loss: 0.2580\n",
      "Epoch [12/20], Loss: 0.2616\n",
      "Epoch [12/20], Loss: 0.2589\n",
      "Epoch [12/20], Loss: 0.2573\n",
      "Epoch [12/20], Loss: 0.2575\n",
      "Epoch [12/20], Loss: 0.2561\n",
      "Epoch [12/20], Loss: 0.2562\n",
      "Epoch [12/20], Loss: 0.2559\n",
      "Epoch [12/20], Valid Accuracy: 97.1200, Valid Loss: 0.1049\n",
      "Epoch [13/20], Loss: 0.2658\n",
      "Epoch [13/20], Loss: 0.2566\n",
      "Epoch [13/20], Loss: 0.2527\n",
      "Epoch [13/20], Loss: 0.2505\n",
      "Epoch [13/20], Loss: 0.2516\n",
      "Epoch [13/20], Loss: 0.2488\n",
      "Epoch [13/20], Loss: 0.2477\n",
      "Epoch [13/20], Loss: 0.2480\n",
      "Epoch [13/20], Loss: 0.2471\n",
      "Epoch [13/20], Loss: 0.2472\n",
      "Epoch [13/20], Valid Accuracy: 97.0600, Valid Loss: 0.1072\n",
      "Epoch [14/20], Loss: 0.2421\n",
      "Epoch [14/20], Loss: 0.2412\n",
      "Epoch [14/20], Loss: 0.2439\n",
      "Epoch [14/20], Loss: 0.2468\n",
      "Epoch [14/20], Loss: 0.2441\n",
      "Epoch [14/20], Loss: 0.2441\n",
      "Epoch [14/20], Loss: 0.2415\n",
      "Epoch [14/20], Loss: 0.2437\n",
      "Epoch [14/20], Loss: 0.2438\n",
      "Epoch [14/20], Loss: 0.2442\n",
      "Epoch [14/20], Valid Accuracy: 97.0500, Valid Loss: 0.1072\n",
      "Epoch [15/20], Loss: 0.2499\n",
      "Epoch [15/20], Loss: 0.2474\n",
      "Epoch [15/20], Loss: 0.2450\n",
      "Epoch [15/20], Loss: 0.2476\n",
      "Epoch [15/20], Loss: 0.2449\n",
      "Epoch [15/20], Loss: 0.2456\n",
      "Epoch [15/20], Loss: 0.2444\n",
      "Epoch [15/20], Loss: 0.2433\n",
      "Epoch [15/20], Loss: 0.2436\n",
      "Epoch [15/20], Loss: 0.2429\n",
      "Epoch [15/20], Valid Accuracy: 97.1800, Valid Loss: 0.1035\n",
      "Epoch [16/20], Loss: 0.2288\n",
      "Epoch [16/20], Loss: 0.2372\n",
      "Epoch [16/20], Loss: 0.2418\n",
      "Epoch [16/20], Loss: 0.2419\n",
      "Epoch [16/20], Loss: 0.2399\n",
      "Epoch [16/20], Loss: 0.2433\n",
      "Epoch [16/20], Loss: 0.2438\n",
      "Epoch [16/20], Loss: 0.2407\n",
      "Epoch [16/20], Loss: 0.2424\n",
      "Epoch [16/20], Loss: 0.2419\n",
      "Epoch [16/20], Valid Accuracy: 97.3300, Valid Loss: 0.1049\n",
      "Epoch [17/20], Loss: 0.2382\n",
      "Epoch [17/20], Loss: 0.2320\n",
      "Epoch [17/20], Loss: 0.2390\n",
      "Epoch [17/20], Loss: 0.2387\n",
      "Epoch [17/20], Loss: 0.2439\n",
      "Epoch [17/20], Loss: 0.2393\n",
      "Epoch [17/20], Loss: 0.2400\n",
      "Epoch [17/20], Loss: 0.2381\n",
      "Epoch [17/20], Loss: 0.2378\n",
      "Epoch [17/20], Loss: 0.2392\n",
      "Epoch [17/20], Valid Accuracy: 97.2600, Valid Loss: 0.1060\n",
      "Epoch [18/20], Loss: 0.2400\n",
      "Epoch [18/20], Loss: 0.2294\n",
      "Epoch [18/20], Loss: 0.2257\n",
      "Epoch [18/20], Loss: 0.2286\n",
      "Epoch [18/20], Loss: 0.2304\n",
      "Epoch [18/20], Loss: 0.2343\n",
      "Epoch [18/20], Loss: 0.2333\n",
      "Epoch [18/20], Loss: 0.2321\n",
      "Epoch [18/20], Loss: 0.2316\n",
      "Epoch [18/20], Loss: 0.2320\n",
      "Epoch [18/20], Valid Accuracy: 97.1500, Valid Loss: 0.1007\n",
      "Epoch [19/20], Loss: 0.2388\n",
      "Epoch [19/20], Loss: 0.2352\n",
      "Epoch [19/20], Loss: 0.2313\n",
      "Epoch [19/20], Loss: 0.2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.2312\n",
      "Epoch [19/20], Loss: 0.2298\n",
      "Epoch [19/20], Loss: 0.2293\n",
      "Epoch [19/20], Loss: 0.2310\n",
      "Epoch [19/20], Loss: 0.2319\n",
      "Epoch [19/20], Loss: 0.2322\n",
      "Epoch [19/20], Valid Accuracy: 97.1900, Valid Loss: 0.1058\n",
      "Epoch [20/20], Loss: 0.2522\n",
      "Epoch [20/20], Loss: 0.2333\n",
      "Epoch [20/20], Loss: 0.2243\n",
      "Epoch [20/20], Loss: 0.2283\n",
      "Epoch [20/20], Loss: 0.2342\n",
      "Epoch [20/20], Loss: 0.2329\n",
      "Epoch [20/20], Loss: 0.2324\n",
      "Epoch [20/20], Loss: 0.2312\n",
      "Epoch [20/20], Loss: 0.2317\n",
      "Epoch [20/20], Loss: 0.2321\n",
      "Epoch [20/20], Valid Accuracy: 97.1400, Valid Loss: 0.1102\n",
      "Epoch [1/20], Loss: 2.3037\n",
      "Epoch [1/20], Loss: 2.3033\n",
      "Epoch [1/20], Loss: 2.3029\n",
      "Epoch [1/20], Loss: 2.3026\n",
      "Epoch [1/20], Loss: 2.3025\n",
      "Epoch [1/20], Loss: 2.3023\n",
      "Epoch [1/20], Loss: 2.3022\n",
      "Epoch [1/20], Loss: 2.3022\n",
      "Epoch [1/20], Loss: 2.3020\n",
      "Epoch [1/20], Loss: 2.3019\n",
      "Epoch [1/20], Valid Accuracy: 8.6000, Valid Loss: 2.3674\n",
      "Epoch [2/20], Loss: 2.3015\n",
      "Epoch [2/20], Loss: 2.3014\n",
      "Epoch [2/20], Loss: 2.3013\n",
      "Epoch [2/20], Loss: 2.3015\n",
      "Epoch [2/20], Loss: 2.3014\n",
      "Epoch [2/20], Loss: 2.3013\n",
      "Epoch [2/20], Loss: 2.3013\n",
      "Epoch [2/20], Loss: 2.3012\n",
      "Epoch [2/20], Loss: 2.3013\n",
      "Epoch [2/20], Loss: 2.3013\n",
      "Epoch [2/20], Valid Accuracy: 8.2000, Valid Loss: 2.3673\n",
      "Epoch [3/20], Loss: 2.3020\n",
      "Epoch [3/20], Loss: 2.3016\n",
      "Epoch [3/20], Loss: 2.3014\n",
      "Epoch [3/20], Loss: 2.3011\n",
      "Epoch [3/20], Loss: 2.3013\n",
      "Epoch [3/20], Loss: 2.3013\n",
      "Epoch [3/20], Loss: 2.3013\n",
      "Epoch [3/20], Loss: 2.3014\n",
      "Epoch [3/20], Loss: 2.3013\n",
      "Epoch [3/20], Loss: 2.3013\n",
      "Epoch [3/20], Valid Accuracy: 8.3500, Valid Loss: 2.3665\n",
      "Epoch [4/20], Loss: 2.3012\n",
      "Epoch [4/20], Loss: 2.3011\n",
      "Epoch [4/20], Loss: 2.3013\n",
      "Epoch [4/20], Loss: 2.3012\n",
      "Epoch [4/20], Loss: 2.3013\n",
      "Epoch [4/20], Loss: 2.3013\n",
      "Epoch [4/20], Loss: 2.3013\n",
      "Epoch [4/20], Loss: 2.3013\n",
      "Epoch [4/20], Loss: 2.3013\n",
      "Epoch [4/20], Loss: 2.3013\n",
      "Epoch [4/20], Valid Accuracy: 8.3900, Valid Loss: 2.3663\n",
      "Epoch [5/20], Loss: 2.3020\n",
      "Epoch [5/20], Loss: 2.3017\n",
      "Epoch [5/20], Loss: 2.3016\n",
      "Epoch [5/20], Loss: 2.3016\n",
      "Epoch [5/20], Loss: 2.3014\n",
      "Epoch [5/20], Loss: 2.3016\n",
      "Epoch [5/20], Loss: 2.3015\n",
      "Epoch [5/20], Loss: 2.3014\n",
      "Epoch [5/20], Loss: 2.3014\n",
      "Epoch [5/20], Loss: 2.3013\n",
      "Epoch [5/20], Valid Accuracy: 8.4000, Valid Loss: 2.3662\n",
      "Epoch [6/20], Loss: 2.3007\n",
      "Epoch [6/20], Loss: 2.3011\n",
      "Epoch [6/20], Loss: 2.3011\n",
      "Epoch [6/20], Loss: 2.3012\n",
      "Epoch [6/20], Loss: 2.3014\n",
      "Epoch [6/20], Loss: 2.3013\n",
      "Epoch [6/20], Loss: 2.3013\n",
      "Epoch [6/20], Loss: 2.3014\n",
      "Epoch [6/20], Loss: 2.3013\n",
      "Epoch [6/20], Loss: 2.3013\n",
      "Epoch [6/20], Valid Accuracy: 8.3500, Valid Loss: 2.3669\n",
      "Epoch [7/20], Loss: 2.3012\n",
      "Epoch [7/20], Loss: 2.3009\n",
      "Epoch [7/20], Loss: 2.3011\n",
      "Epoch [7/20], Loss: 2.3008\n",
      "Epoch [7/20], Loss: 2.3008\n",
      "Epoch [7/20], Loss: 2.3009\n",
      "Epoch [7/20], Loss: 2.3011\n",
      "Epoch [7/20], Loss: 2.3011\n",
      "Epoch [7/20], Loss: 2.3012\n",
      "Epoch [7/20], Loss: 2.3013\n",
      "Epoch [7/20], Valid Accuracy: 8.2800, Valid Loss: 2.3673\n",
      "Epoch [8/20], Loss: 2.3004\n",
      "Epoch [8/20], Loss: 2.3008\n",
      "Epoch [8/20], Loss: 2.3008\n",
      "Epoch [8/20], Loss: 2.3010\n",
      "Epoch [8/20], Loss: 2.3013\n",
      "Epoch [8/20], Loss: 2.3013\n",
      "Epoch [8/20], Loss: 2.3013\n",
      "Epoch [8/20], Loss: 2.3013\n",
      "Epoch [8/20], Loss: 2.3013\n",
      "Epoch [8/20], Loss: 2.3013\n",
      "Epoch [8/20], Valid Accuracy: 8.4400, Valid Loss: 2.3672\n",
      "Epoch [9/20], Loss: 2.3009\n",
      "Epoch [9/20], Loss: 2.3012\n",
      "Epoch [9/20], Loss: 2.3012\n",
      "Epoch [9/20], Loss: 2.3011\n",
      "Epoch [9/20], Loss: 2.3012\n",
      "Epoch [9/20], Loss: 2.3013\n",
      "Epoch [9/20], Loss: 2.3015\n",
      "Epoch [9/20], Loss: 2.3014\n",
      "Epoch [9/20], Loss: 2.3014\n",
      "Epoch [9/20], Loss: 2.3013\n",
      "Epoch [9/20], Valid Accuracy: 8.2400, Valid Loss: 2.3669\n",
      "Epoch [10/20], Loss: 2.3008\n",
      "Epoch [10/20], Loss: 2.3005\n",
      "Epoch [10/20], Loss: 2.3007\n",
      "Epoch [10/20], Loss: 2.3011\n",
      "Epoch [10/20], Loss: 2.3012\n",
      "Epoch [10/20], Loss: 2.3012\n",
      "Epoch [10/20], Loss: 2.3013\n",
      "Epoch [10/20], Loss: 2.3012\n",
      "Epoch [10/20], Loss: 2.3013\n",
      "Epoch [10/20], Loss: 2.3013\n",
      "Epoch [10/20], Valid Accuracy: 8.3600, Valid Loss: 2.3667\n",
      "Epoch [11/20], Loss: 2.3016\n",
      "Epoch [11/20], Loss: 2.3013\n",
      "Epoch [11/20], Loss: 2.3012\n",
      "Epoch [11/20], Loss: 2.3013\n",
      "Epoch [11/20], Loss: 2.3013\n",
      "Epoch [11/20], Loss: 2.3013\n",
      "Epoch [11/20], Loss: 2.3012\n",
      "Epoch [11/20], Loss: 2.3013\n",
      "Epoch [11/20], Loss: 2.3013\n",
      "Epoch [11/20], Loss: 2.3013\n",
      "Epoch [11/20], Valid Accuracy: 8.4100, Valid Loss: 2.3672\n",
      "Epoch [12/20], Loss: 2.3015\n",
      "Epoch [12/20], Loss: 2.3014\n",
      "Epoch [12/20], Loss: 2.3015\n",
      "Epoch [12/20], Loss: 2.3013\n",
      "Epoch [12/20], Loss: 2.3013\n",
      "Epoch [12/20], Loss: 2.3012\n",
      "Epoch [12/20], Loss: 2.3013\n",
      "Epoch [12/20], Loss: 2.3013\n",
      "Epoch [12/20], Loss: 2.3012\n",
      "Epoch [12/20], Loss: 2.3013\n",
      "Epoch [12/20], Valid Accuracy: 8.2500, Valid Loss: 2.3673\n",
      "Epoch [13/20], Loss: 2.3016\n",
      "Epoch [13/20], Loss: 2.3013\n",
      "Epoch [13/20], Loss: 2.3013\n",
      "Epoch [13/20], Loss: 2.3014\n",
      "Epoch [13/20], Loss: 2.3013\n",
      "Epoch [13/20], Loss: 2.3014\n",
      "Epoch [13/20], Loss: 2.3012\n",
      "Epoch [13/20], Loss: 2.3012\n",
      "Epoch [13/20], Loss: 2.3013\n",
      "Epoch [13/20], Loss: 2.3013\n",
      "Epoch [13/20], Valid Accuracy: 8.3300, Valid Loss: 2.3668\n",
      "Epoch [14/20], Loss: 2.3019\n",
      "Epoch [14/20], Loss: 2.3010\n",
      "Epoch [14/20], Loss: 2.3012\n",
      "Epoch [14/20], Loss: 2.3014\n",
      "Epoch [14/20], Loss: 2.3015\n",
      "Epoch [14/20], Loss: 2.3013\n",
      "Epoch [14/20], Loss: 2.3013\n",
      "Epoch [14/20], Loss: 2.3013\n",
      "Epoch [14/20], Loss: 2.3012\n",
      "Epoch [14/20], Loss: 2.3013\n",
      "Epoch [14/20], Valid Accuracy: 8.2400, Valid Loss: 2.3672\n",
      "Epoch [15/20], Loss: 2.3011\n",
      "Epoch [15/20], Loss: 2.3012\n",
      "Epoch [15/20], Loss: 2.3012\n",
      "Epoch [15/20], Loss: 2.3011\n",
      "Epoch [15/20], Loss: 2.3011\n",
      "Epoch [15/20], Loss: 2.3011\n",
      "Epoch [15/20], Loss: 2.3013\n",
      "Epoch [15/20], Loss: 2.3013\n",
      "Epoch [15/20], Loss: 2.3012\n",
      "Epoch [15/20], Loss: 2.3013\n",
      "Epoch [15/20], Valid Accuracy: 8.5800, Valid Loss: 2.3676\n",
      "Epoch [16/20], Loss: 2.3019\n",
      "Epoch [16/20], Loss: 2.3014\n",
      "Epoch [16/20], Loss: 2.3016\n",
      "Epoch [16/20], Loss: 2.3016\n",
      "Epoch [16/20], Loss: 2.3015\n",
      "Epoch [16/20], Loss: 2.3015\n",
      "Epoch [16/20], Loss: 2.3014\n",
      "Epoch [16/20], Loss: 2.3013\n",
      "Epoch [16/20], Loss: 2.3013\n",
      "Epoch [16/20], Loss: 2.3013\n",
      "Epoch [16/20], Valid Accuracy: 8.2500, Valid Loss: 2.3663\n",
      "Epoch [17/20], Loss: 2.3008\n",
      "Epoch [17/20], Loss: 2.3012\n",
      "Epoch [17/20], Loss: 2.3016\n",
      "Epoch [17/20], Loss: 2.3013\n",
      "Epoch [17/20], Loss: 2.3011\n",
      "Epoch [17/20], Loss: 2.3011\n",
      "Epoch [17/20], Loss: 2.3012\n",
      "Epoch [17/20], Loss: 2.3012\n",
      "Epoch [17/20], Loss: 2.3012\n",
      "Epoch [17/20], Loss: 2.3013\n",
      "Epoch [17/20], Valid Accuracy: 8.5900, Valid Loss: 2.3673\n",
      "Epoch [18/20], Loss: 2.3014\n",
      "Epoch [18/20], Loss: 2.3014\n",
      "Epoch [18/20], Loss: 2.3012\n",
      "Epoch [18/20], Loss: 2.3012\n",
      "Epoch [18/20], Loss: 2.3012\n",
      "Epoch [18/20], Loss: 2.3012\n",
      "Epoch [18/20], Loss: 2.3012\n",
      "Epoch [18/20], Loss: 2.3012\n",
      "Epoch [18/20], Loss: 2.3012\n",
      "Epoch [18/20], Loss: 2.3013\n",
      "Epoch [18/20], Valid Accuracy: 8.3900, Valid Loss: 2.3668\n",
      "Epoch [19/20], Loss: 2.3016\n",
      "Epoch [19/20], Loss: 2.3014\n",
      "Epoch [19/20], Loss: 2.3015\n",
      "Epoch [19/20], Loss: 2.3015\n",
      "Epoch [19/20], Loss: 2.3016\n",
      "Epoch [19/20], Loss: 2.3014\n",
      "Epoch [19/20], Loss: 2.3014\n",
      "Epoch [19/20], Loss: 2.3014\n",
      "Epoch [19/20], Loss: 2.3013\n",
      "Epoch [19/20], Loss: 2.3013\n",
      "Epoch [19/20], Valid Accuracy: 8.3600, Valid Loss: 2.3671\n",
      "Epoch [20/20], Loss: 2.3001\n",
      "Epoch [20/20], Loss: 2.3007\n",
      "Epoch [20/20], Loss: 2.3007\n",
      "Epoch [20/20], Loss: 2.3011\n",
      "Epoch [20/20], Loss: 2.3011\n",
      "Epoch [20/20], Loss: 2.3012\n",
      "Epoch [20/20], Loss: 2.3011\n",
      "Epoch [20/20], Loss: 2.3012\n",
      "Epoch [20/20], Loss: 2.3013\n",
      "Epoch [20/20], Loss: 2.3013\n",
      "Epoch [20/20], Valid Accuracy: 8.5500, Valid Loss: 2.3677\n"
     ]
    }
   ],
   "source": [
    "dropout = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "lst_val_acc4 = []\n",
    "lst_val_loss4 = []\n",
    "lst_train_loss4 = []\n",
    "for do in dropout:\n",
    "    net = get_model_v2(p=do)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, num_epochs=20, model=net, optimizer=optimizer)\n",
    "    lst_val_acc4.append(val_acc)\n",
    "    lst_val_loss4.append(val_loss)\n",
    "    lst_train_loss4.append(train_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>97.83</td>\n",
       "      <td>0.140661</td>\n",
       "      <td>0.011825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>98.34</td>\n",
       "      <td>0.082525</td>\n",
       "      <td>0.023764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>98.39</td>\n",
       "      <td>0.077166</td>\n",
       "      <td>0.042500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>98.10</td>\n",
       "      <td>0.076677</td>\n",
       "      <td>0.088586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>97.14</td>\n",
       "      <td>0.110204</td>\n",
       "      <td>0.232067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.55</td>\n",
       "      <td>2.367744</td>\n",
       "      <td>2.301278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dropout  Validation Accuracy  Validation Loss  Training Loss\n",
       "0      0.0                97.83         0.140661       0.011825\n",
       "1      0.2                98.34         0.082525       0.023764\n",
       "2      0.4                98.39         0.077166       0.042500\n",
       "3      0.6                98.10         0.076677       0.088586\n",
       "4      0.8                97.14         0.110204       0.232067\n",
       "5      1.0                 8.55         2.367744       2.301278"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame(\n",
    "    {\n",
    "        'Dropout': dropout,\n",
    "        'Validation Accuracy': lst_val_acc4,\n",
    "        'Validation Loss': lst_val_loss4,\n",
    "        'Training Loss': lst_train_loss4\n",
    "    },\n",
    "    columns = ['Dropout', 'Validation Accuracy', 'Validation Loss', 'Training Loss']\n",
    ")\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Loss')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f804c549588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df4['Dropout'], df4['Training Loss'])\n",
    "plt.plot(df4['Dropout'], df4['Validation Loss'])\n",
    "plt.xticks(df4['Dropout'])\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='center left', bbox_to_anchor=(0.0, 0.3), ncol=1)\n",
    "plt.xlabel('Dropout')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dropout rate = 0.4, the neural network has the best validation accuracy. As dropout rate increases to 1, validation accuracy plummets after 0.8, meaning too many hidden units are dropped. \n",
    "Comparing to the model with no dropout, models with moderate dropout has a lower validation loss and a higher validation accuracy.\n",
    "Comparing to models with L2 regularization, dropout seems to have a better performance in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-layer nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_v3(M = 300):\n",
    "    net = nn.Sequential(nn.Linear(28*28, M),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M, M),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M, 10))\n",
    "    return net.cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_v2(train_loader, test_loader, num_epochs, model, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            batch = images.shape[0] # size of the batch\n",
    "            # Convert torch tensor to Variable, change shape of the input\n",
    "            images = Variable(images.view(-1, 28*28)).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "        \n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total += batch\n",
    "            sum_loss += batch * loss.data[0]        \n",
    "        train_loss = sum_loss/total\n",
    "        val_acc, val_loss = model_accuracy_loss(model, test_loader)\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:0.0006 | M:500 | Weight decay:0 : Validation Accuracy:97.92 | Validation Loss:0.08773291255235673 | Training Loss:0.015300973655780157\n",
      "Learning rate:0.0006 | M:500 | Weight decay:0.0001 : Validation Accuracy:98.1 | Validation Loss:0.06707664527893066 | Training Loss:0.020199961175521215\n",
      "Learning rate:0.0006 | M:500 | Weight decay:0.0005 : Validation Accuracy:98.11 | Validation Loss:0.06005364141464233 | Training Loss:0.0336373145977656\n",
      "Learning rate:0.0006 | M:1000 | Weight decay:0 : Validation Accuracy:97.61 | Validation Loss:0.11141345298290253 | Training Loss:0.019644404022892317\n",
      "Learning rate:0.0006 | M:1000 | Weight decay:0.0001 : Validation Accuracy:97.74 | Validation Loss:0.08274085282087326 | Training Loss:0.02024154270788034\n",
      "Learning rate:0.0006 | M:1000 | Weight decay:0.0005 : Validation Accuracy:98.08 | Validation Loss:0.06289263942241669 | Training Loss:0.035140036938587825\n",
      "Learning rate:0.0006 | M:1200 | Weight decay:0 : Validation Accuracy:98.01 | Validation Loss:0.08647066822052002 | Training Loss:0.018578976360956827\n",
      "Learning rate:0.0006 | M:1200 | Weight decay:0.0001 : Validation Accuracy:98.03 | Validation Loss:0.07274821734428406 | Training Loss:0.02190916978319486\n",
      "Learning rate:0.0006 | M:1200 | Weight decay:0.0005 : Validation Accuracy:97.95 | Validation Loss:0.06692190628051758 | Training Loss:0.03324890898267428\n",
      "Learning rate:0.0008 | M:500 | Weight decay:0 : Validation Accuracy:97.72 | Validation Loss:0.11126533035039901 | Training Loss:0.019963160479068758\n",
      "Learning rate:0.0008 | M:500 | Weight decay:0.0001 : Validation Accuracy:97.87 | Validation Loss:0.07902059462070465 | Training Loss:0.026021609842777252\n",
      "Learning rate:0.0008 | M:500 | Weight decay:0.0005 : Validation Accuracy:97.74 | Validation Loss:0.08181826668977737 | Training Loss:0.03808212981422742\n",
      "Learning rate:0.0008 | M:1000 | Weight decay:0 : Validation Accuracy:98.18 | Validation Loss:0.08291278368234635 | Training Loss:0.022619703536232313\n",
      "Learning rate:0.0008 | M:1000 | Weight decay:0.0001 : Validation Accuracy:98.02 | Validation Loss:0.07514641727209091 | Training Loss:0.024581898385286332\n",
      "Learning rate:0.0008 | M:1000 | Weight decay:0.0005 : Validation Accuracy:97.83 | Validation Loss:0.07132919288873672 | Training Loss:0.04019826901157697\n",
      "Learning rate:0.0008 | M:1200 | Weight decay:0 : Validation Accuracy:98.35 | Validation Loss:0.07800681456327438 | Training Loss:0.02428985472122828\n",
      "Learning rate:0.0008 | M:1200 | Weight decay:0.0001 : Validation Accuracy:97.86 | Validation Loss:0.08124003229141236 | Training Loss:0.024918115876118342\n",
      "Learning rate:0.0008 | M:1200 | Weight decay:0.0005 : Validation Accuracy:97.71 | Validation Loss:0.07776666781902314 | Training Loss:0.040059153962135316\n",
      "Learning rate:0.001 | M:500 | Weight decay:0 : Validation Accuracy:97.57 | Validation Loss:0.10821609696149825 | Training Loss:0.020683362366755803\n",
      "Learning rate:0.001 | M:500 | Weight decay:0.0001 : Validation Accuracy:98.13 | Validation Loss:0.06877544355988502 | Training Loss:0.027841393983364104\n",
      "Learning rate:0.001 | M:500 | Weight decay:0.0005 : Validation Accuracy:97.82 | Validation Loss:0.07296961399316788 | Training Loss:0.04370834851861\n",
      "Learning rate:0.001 | M:1000 | Weight decay:0 : Validation Accuracy:98.12 | Validation Loss:0.09371903100013733 | Training Loss:0.023091994965076447\n",
      "Learning rate:0.001 | M:1000 | Weight decay:0.0001 : Validation Accuracy:97.77 | Validation Loss:0.07982666810750962 | Training Loss:0.03092280220091343\n",
      "Learning rate:0.001 | M:1000 | Weight decay:0.0005 : Validation Accuracy:97.41 | Validation Loss:0.08247335538864135 | Training Loss:0.043401547559102374\n",
      "Learning rate:0.001 | M:1200 | Weight decay:0 : Validation Accuracy:98.13 | Validation Loss:0.10300283830165863 | Training Loss:0.02439294804930687\n",
      "Learning rate:0.001 | M:1200 | Weight decay:0.0001 : Validation Accuracy:98.07 | Validation Loss:0.07333166935443879 | Training Loss:0.028045231589674948\n",
      "Learning rate:0.001 | M:1200 | Weight decay:0.0005 : Validation Accuracy:97.59 | Validation Loss:0.08178165122270584 | Training Loss:0.04405855459968249\n"
     ]
    }
   ],
   "source": [
    "learning_rate_nn3 = [0.0006, 0.0008, 0.001]\n",
    "hidden_layer_size_nn3 = [500,1000,1200]\n",
    "weight_decay_nn3 = [0, 0.0001, 0.0005]\n",
    "for l_r in learning_rate_nn3:\n",
    "    for hls in hidden_layer_size_nn3:\n",
    "        for wd in weight_decay_nn3:\n",
    "            net = get_model_v3(M=hls)\n",
    "            optimizer = optim.Adam(net.parameters(), lr=l_r, weight_decay=wd)\n",
    "            val_acc, val_loss, train_loss = train_model_v2(train_loader, test_loader, num_epochs=10, model=net, optimizer=optimizer)\n",
    "            print(\"Learning rate:{0} | M:{1} | Weight decay:{2} : Validation Accuracy:{3} | Validation Loss:{4} | Training Loss:{5}\"\\\n",
    "                  .format(l_r, hls, wd, val_acc, val_loss, train_loss)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best hyperparameters\n",
    "Learning rate:0.0008  M:1200  Weight decay:0 : Validation Accuracy:98.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
